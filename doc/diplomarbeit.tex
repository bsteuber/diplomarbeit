\documentclass[a4paper, bibgerm]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{ngerman}
\usepackage{bibgerm}
\usepackage{color}
\usepackage{amssymb,amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{acronym}

\lstloadlanguages{Haskell}
\lstnewenvironment{code}
  {\lstset{}%
    \csname lst@SetFirstLabel\endcsname}
  {\csname lst@SaveFirstLabel\endcsname}
\lstset{
  basicstyle=\small\ttfamily,
  flexiblecolumns=false,
  basewidth={0.5em,0.45em}
% ,
%   literate={+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
%   {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
%   {\\\\}{{\char`\\\char`\\}}1
%   {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
%   {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2
%   {.}{{$\circ$}}2
%   {...}{{$\ldots$}}2
% % {\ .\ }{{$\circ$}}2
%   {>>>}{{$\ggg$}}2
% %  {>>}{{>>}}2 {>>=}{{>>=}}2 %<<
%   {|}{{$\mid$}}1
}

\newcommand\icode[1]{\lstinline?#1?}


\newcommand{\todo}[1]{
  \textcolor{red}{TODO: #1}
}

\newcommand{\defaultscale}{0.3}

\newcommand\lchapter{}
\newcommand\lsection{}
\newcommand\lsubsection{}
\newcommand\lsubsubsection{}
\newcommand\lparagraph{}
\newcommand\cref{}
\newcommand\sref{}
\newcommand\abb{}
\newcommand\fig{}
\newcommand\figs{}
\newcommand\subfig{}
\newcommand\vertfig{}
\newcommand\clipvertfig{}

\newcommand{\project}[1]{%
  \renewcommand\lchapter[2][\LChapterDefault]{%
    \def\LChapterDefault{##2}%
    \chapter{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsection[2][\LSectionDefault]{%
    \def\LSectionDefault{##2}%
    \section{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsubsection[2][\LSubSectionDefault]{%
    \def\LSubSectionDefault{##2}%
    \subsection{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsubsubsection[2][\LSubSubSectionDefault]{%
    \def\LSubSubSectionDefault{##2}%
    \subsubsection{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lparagraph[2][\LParagraphDefault]{%
    \def\LParagraphDefault{##2}%
    \paragraph{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\cref[1]{%
    Kapitel~\ref{#1:sec:##1}%
  }%
  \renewcommand\sref[1]{%
    Abschnitt~\ref{#1:sec:##1}%
  }%
  \renewcommand{\abb}[1]{Abb.\ref{#1:fig:##1}}
  \renewcommand{\fig}[3][\defaultscale]{%
    \begin{figure}[htp]
      \centering
      \includegraphics[scale=##1]{images/##2}
      \caption{##3}
      \label{#1:fig:##2}
  \end{figure}}

  \renewcommand{\figs}[3]{%
    \begin{figure}[htp]
      \centering
      ##3
      \caption{##2}
      \label{#1:fig:##1}
    \end{figure}
  }

  \renewcommand{\subfig}[3][\defaultscale]{%
    \subfloat[##3]{
      \includegraphics[scale=##1]{images/##2}
      \label{#1:fig:##2}
    }
  }

  \renewcommand{\vertfig}[3][\defaultscale]{%
    \begin{sidewaysfigure}[htp]
      \centering
      \includegraphics[scale=##1]{images/##2}
      \caption{##3}
      \label{#1:fig:##2}
    \end{sidewaysfigure}%
  }

  \renewcommand{\clipvertfig}[5]{%
    \begin{sidewaysfigure}[htp]
      \centering
      \includegraphics*[scale=##1, viewport=##2]{images/##3}
      \caption{##5}
      \label{#1:fig:##4}
    \end{sidewaysfigure}%
  }
}

\project{magicl}

\newcommand\ato{\rightarrow} %Morphismen
\newcommand\nto{\Rightarrow} %Natürliche Transformationen

\newtheorem{defini}{Definition}

\newcommand{\defi}[2]{%
  \begin{defini}[#1]
    \label{def:#1}
    #2
  \end{defini}
}

\newcommand{\dref}[1]{Def. \ref{def:#1}}

\newcommand{\sees}[1]{(siehe \sref{#1})}

\newcommand{\sexy}{S-Exy}
\newcommand{\sexp}{S"=Expression}
\newcommand{\sexps}{S"=Expressions}
\newcommand{\cgen}{Code"=Generierung}

\begin{document}

\begin{titlepage}
\title{Prototypen universeller Frameworks für
  \sexp{}-basierte \cgen{}}
\author{Benjamin Teuber}
\date{\today}

\maketitle
\end{titlepage}

\tableofcontents

\listoffigures

\chapter*{Abkürzungsverzeichnis}
\begin{acronym}
%\setlength{\itemsep}{-\parsep}
\acro{DSL}{Domain Specific Language}
\acro{DSSSL}{Document Style Semantics and Specification Language}
\acro{EBNF}{Erweiterte Backus-Naur-Form}
\acro{MDA}{Model Driven Architecture}
\acro{UML}{Unified Modelling Language}
\acro{XML}{Extensible Markup Language}
\end{acronym}

% \setlength{\parindent}{0pt}
% \setlength{\parskip}{2ex}

\lchapter[intro]{Einleitung}

\lsection[intro:motiv]{Motivation}

Modellgetriebene Softwareentwicklung ist in aller Munde: Die \ac{UML}
feiert bald ihr 15-Jähriges bestehen \footnote{Der
  Standarisierungsprozess von UML begann 1994, als Gary Booch und Jim
  Rumbaugh mit der Vereinheitlichung ihrer Modellierungstechniken
  begannen. \cite{TODO}}, IBM vermarktet seit Jahren das Produkt
\textit{Rational Application Developer} (\cite{TODO}), das, wie auch das freie
\textit{Eclipse Modelling Framework} oder auch \textit{Enterprise
  Architect}, Eclipse um modellbasierte \cgen{}
bereichert. Seit neuestem zeigt auch Microsoft Interesse und
verspricht mit \textit{Oslo} \cite{TODO} einen ``Mainstream"=Ansatz
für Modellierung''. \cgen{} fällt auch im World Wide Web eine
immer größer werdende Rolle zu: Ob \textit{Ruby on Rails} oder
\textit{Google Web Toolkit}, praktisch alle Web Frameworks generieren
zumindest ihre HTML-Dateien oder SQL-Strings für den Datenbankzugriff.

Abstraktion durch \cgen{} ist also beliebter denn je, und
Werkzeuge, die diese anbieten oder nutzen, gibt es in großen
Mengen. Dennoch arbeiten die meisten Werkzeuge mit Templates oder
String-Manipulation und damit auf Zeichenketten, womit sie
technologisch einen großen Schritt hinter der \textit{strukturellen}
Generierung stehen, die Lisp-Programmierer bereits vor 40 Jahren mit
\sexps{} und Makros praktiziert haben. Denn über \sexps{} wird Lisp-Code
in einer Baumstruktur repräsentiert, wodurch das Verarbeiten
und Generieren von Code deutlich vereinfacht und darüber hinaus viele
Fehlerquellen vermieden werden. Makros ermöglichen zudem eine
inkrementelle, modulare Compiler-Entwicklung.

Lisp-Programmierer, auf der anderen Seite, haben sich immer nur im die
Erzeugung von Lisp-Code selbst gekümmert und bis auf wenige Ausnahmen
(siehe z.B. ParenScript \cite{TODO}, welches JavaScript aus \sexps{}
generiert) andere Sprachen ignoriert. Zudem wird Lisp allgemein
totgeschrieben, was teils an veraltetem Sprachdesign, hauptsächlich
aber an der geringen Anzahl verfügbarer Bibliotheken im Vergleich zu
Mainstream-Sprachen liegt. Während viele andere Lisp-Konzepte wie
Garbage Collection oder Konstrukte wie der REPL, eine
Lisp-Kommandozeile zum interaktiven Programmieren und Testen, bereits
von modernen Sprachen nachgeahmt wurden, stehen Makros\footnote{Der
  C-Preprozessor bietet ebenfalls Makros an - diese sind allerdings
  weniger mächtig als Lisp-Makros \sees{related:lisp:cprep}.} nur noch
der kleinen Lisp-Community zur Verfügung. Es wäre also wünschenswert,
diese oder etwas Vergleichbares im Rahmen moderner Sprachen für
\cgen{} und -Verarbeitung nutzen zu können.

\lsection[intro:goal]{Fragestellungen und Zielsetzung}

Die grundlegende Fragestellung dieser Arbeit lautet: Ist es möglich, die
Lisp-Ansätze für \cgen{} derart zu verallgemeinern, dass sich
beliebige durch \sexps{} repräsentierte Sprachen damit komfortabel
kompilierien und möglichst auch interpretieren lassen können? Es soll
allerdings nicht zwangsläufig eine Eins-zu-Eins-Kopie der Lisp-Makros
erfolgen, sondern vielmehr geprüft werden, welche Möglichkeiten es noch
gibt und welche davon eventuell noch besser geeignet für den neuen,
breiteren Kontext beliebiger Sprachen sind. Insbesondere soll die
Implementation selbst nicht in Lisp, sondern einer modernen Sprache
erfolgen. Dies hat eine gewisse Unabhängigkeit vom exakten Lisp-Ansatz
und seinen Schwächen oder veralteten Designs zur Folge -
beispielsweise die nicht vorhandene Unterscheidung von Groß- und
Kleinschreibung in \sexps{}. Auch die Entwicklung von neuen Ideen wird
so ermutigt.

Konkret soll in einer Programmiersprache X zunächst eine Repräsentation
für \sexps{} sowie ein \sexp{}-Parser erstellt werden, woraufhin eine
Architektur für \sexp{}-Compiler angelegt wird, die einen inkrementellen
und modularen Compiler-Entwurf ähnlich Lisp unterstützt. Damit soll eine
\sexp{}-Version von X entstehen, welche sich nach X-Quelltext übersetzen
lässt, so dass Werkzeuge, die X generieren wollen, nur noch deren
syntaktisch einfachere \sexp{}-Variante erzeugen müssen. In dem Moment ist
das Bootstrapping abgeschlossen, so dass von nun an ausschließlich mit
\sexp{}-Sprachen programmiert werden könnte. Auch bestehender Quelltext
kann nun durch aus \sexps{} genererierten Versionen ersetzt werden,
wodurch ein metazirkulärer Compiler entsteht.

Darüber hinaus soll zuletzt untersucht werden, inwieweit eine spezielle
(\sexp{}-basierte) \ac{DSL} für Compilerdefinition gestaltet werden kann, in
der sich die Übersetzung einfacher beschreiben lässt als in X
oder deren \sexp{}-Schwester. Diese Sprache kann beispielsweise die
Definition von Lisp-Makros ermöglichen.

\lsection[intro:outline]{Aufbau dieser Arbeit}

\cref{related} versucht, einen Überblick über den Stand der Technik in
Sachen \cgen{} zu geben.

In \cref{sexy} wird mit \sexy{} ein erster, in Ruby geschriebener Prototyp eines
universellen Frameworks für \sexp{}-Compiler geschildert, welcher
sich sehr dicht an den ursprünglichen Lisp-Makros
orientiert.

\cref{magicl} widmet sich MagicL, dem Kern dieser Arbeit. Diese
Neuimplementation basiert auf einer Haskell-Umsetzung
kategorientheoretischer Konzepte, mit deren Hilfe unter anderem sehr
allgemeine und elegante \sexp{}-Parser konstruiert werden
können. Zudem benutzt MagicL im Gegensatz zu \sexy{} getypte Modelle.

\cref{end} fasst zum Schluss die Ergebnisse zusammen und gibt
einen Ausblick auf viele weitere Ideen und Verbesserungen, die nicht im
Rahmen dieser Arbeit behandelt werden können.

\lchapter[related]{Konzepte der generativen Programmierung}

\todo{
\begin{itemize}
\item Marc Oliver Stehr Diss
\item OOPSLA, POPL
\item Baumtransformationen
\item Kategorientheorie
\item JDEX
\item Metaprogrammierung
\item Metamodellierung
\item XML-Editor (Eclipse?)
\item Eclipse Codegen, Transformationen, UML, ...
\item UML
\item Rountrip
\end{itemize}
}

Diese Kapitel soll einen Überblick über vorhandene Technologien zur
\cgen{} liefern.  \sref{related:codegen} erläutert verschiedene
Arten der \cgen{}. In \sref{related:parser} werden Werkzeuge für
die Generierung von Parsern beschrieben. \sref{related:lisp} stellt die
Programmiersprache Lisp und insbesondere \sexps{}, die universelle
Datenstruktur dieser Arbeit, sowie Makros vor. \sexps{} werden in
\sref{related:xml} mit der \ac{XML} verglichen, außerdem werden dort
XML-Werkzeuge vorgestellt. 

\lsection[related:codegen]{\cgen{}}

\begin{itemize}
\item Runtime vs Compiletime
\end{itemize}

\todo{Definition} was \cgen{} bedeutet:
Das automatisiertes Erzeugen von Quelltext. Dennoch gibt es diverse
Unterschiede zwischen \cgen{}swerkzeugen. \todo{quelle}

So differenziert man zwischen aktiver und passiver
\cgen{}. Aktiv bedeutet, dass die Generierung wiederholt
ausgeführt werden kann, wenn sich etwas am Modell oder Generator
ändert, da die komplette Datei generiert wird. Passiv generierter Code
dagegen wird anschließend vom Programmierer modifiziert bzw. erst mit
sinnvollen Inhalten bestückt, so dass dieser normalerweise nur
einmalig generiert werden kann, wenn die Anpassungen nicht
überschrieben werden sollen. \todo{roundtrip} Zwischen aktiver und
passiver Generierung liegen Dateien, in denen nur markierte Abschnitte
generiert werden - so dass der Rest unverändert bleiben kann. Optimal
wäre \todo{kriterien} natürlich ein allgemeiner Merge-Mechanismus, der die Arbeit des
Programmierers reibungslos in die neue Version übernimmt - dies ist
aber leider schwierig zu implementieren.

Zudem lässt sich nach Ein- und Ausgabe des Generators unterscheiden:
Diese können flache Strings, strukturierte (zunächst) ungetypte Daten wie \sexps{}
und XML oder aber getypte Modelle einer Programmiersprache sein.

Vorteile:
\begin{itemize}
\item Abstraktion - Modellarchitekten beötigen keine
  Programmiersprachkenntnisse, Backend austauschbar
``Ist die Sprache an die Problemdomäne angepasst, muss man das Problem
nicht in die Sprache zwängen''
\item Produktivität - DRY-Prinzip spart u.U. viel Zeit
\item Qualität - ist der Generator fehlerfrei, gibt es keine Probleme
  bei neuen Modellen
\item Konsistenz - einheitliche Strukturen/Namen, minimiert Einarbeitungszeit
\end{itemize}

Nachteile:
\begin{itemize}
\item Dokumentation / Einarbeitung
\item Fehlersuche
\item Komplexität
\item Entwicklungsaufwand
\end{itemize}

\lsection[related:notation]{Universelle Notationssprachen}

\begin{itemize}
\item Domänenübergreifende Modellierung
\end{itemize}

\lsubsection[related:notation:xml]{XML}

\begin{itemize}
\item Datenmodell: Baum mit Attributen
\item Syntax: \icode{<tag attr1="...'>...</tag>}
\item Problem: Unterknoten vs. Attribut
  \begin{itemize}
  \item Attribute können immer auch als Unterknoten ausgedrückt werden -
    nur syntaktischer Zucker? 
  \item Unterknoten erlaubt innere Struktur, gut f. komplexere Eigenschaften
  \item Keine klare Trennlinie (Meta in Attribut?), wachsendes Projekt
    kann Wechsel zu Unterknoten erfordern
  \item Wäre ein XML ohne Attribute besser? (Pull- vs Push-Verarbeitung?)
  \end{itemize}
\end{itemize}

\begin{itemize}
\item XPath: Adressieren, z.B. \icode{//chapter[@title=Einleitung"]/paragraph}
  (alle Absätze aus Kap. ``Einleitung'')
\item XSLT: Turing-Vollständige Baum-Transformationssprache in XML
  \begin{itemize}
  \item template: Matcher in XPath
  \item Schleifen, sortierung, if-Abfragen
  \item Nachvolger der \ac{DSSSL} (Scheme-Dialekt $\rightarrow$ \sexp{}-basiert)
  \item Keine ``richtige'', praktische Programmiersprache
  \item $\rightarrow$ oft wird für komplexere Operationen andere Sprache benutzt
  \end{itemize}
\item Für viele Sprachen generierbare XML-Serializer
\end{itemize}

\lsubsection[related:notation:uml]{UML}

\lsubsection[related:notation:json]{JSON}

\lsubsection[related:notation:sexp]{\sexps}

\lsection[related:templates]{Templates und Makros}

\begin{itemize}
\item Grundprinzip Quote/Unquote
\item Unterschiede in Datenstrukturen
  \begin{itemize}
  \item Stringbasiert
  \item Untyüisierte Baumnotation (\sexp{})
  \item Typisiert
  \end{itemize}
\item Unterschiede in Mächtigkeit
  \begin{itemize}
  \item Keine Berechnungen, nur vorhandene Werte einfügen
  \item Vollständige (Meta-)Programmiersprache
  \item Zwischenstufen möglich
  \end{itemize}
\item Macros: 
  \begin{itemize}
  \item Kein explizites (Un-)Quote, Entscheidung über Namen
  \item Syntaktisch nicht von Funktionsaufruf unterscheidbar
  \item Gut: Integrierter
  \item Schlecht: Verschleiert Semantik
  \end{itemize}
\end{itemize}

\lsubsection[related:templates:stringtemplate]{StringTemplate für Java}

\cite{StringTemplate}

\begin{itemize}
\item Stringbasiert
\item Rekursiver Aufruf entspricht Quote
\item Automatischer Splice von Listen: Praktisch, aber kann verwirren /
  bestimmte Anwendungsfälle ausschließen
\item Keine Berechnungen erlaubt
  \begin{itemize}
  \item Argument: Model-View Trennung
  \item Nachteil: komplexe (Kommt dies vor? Frage der Domäne (HTML wohl nicht))
  \item Erweiterbarkeit wünschenswert
  \end{itemize}
\end{itemize}

\lsubsection[related:templates:rails]{Ruby on Rails}

\begin{itemize}
\item Web-Framework
\item Template-Engine Erb für (aber nicht nur) HTML-Output
\item Ansatz von php/perl (welches zuerst?) übernommen
\item Unquote durch spezielle Tags
\item Beliebiger Ruby-Code erlaubt, trotz erwünschter MVC-trennung
\item Kein direktes Quote möglich, aber Aufruf der Rails-Engine oder Erb
\end{itemize}

\lsubsection[related:templates:cprep]{Der C-Präprozessor}
\begin{itemize}
\item C-Makros seit ca. 1975
\item Keine komplette Programmiersprache (if, define, aber nicht goto, funktionen)
\item gensym fehlt
\end{itemize}

\lsubsection[related:templates:ctemp]{Templates in C++}

\begin{itemize}
\item Vorbild für Java-Generics (Generics aber viel weniger mächtig)
\item "`Funktionale Sprache zur Compilationszeit"'
\item Berechnungen im Typsystem
\item Syntax
\item Beispiele
\end{itemize}

\lsubsection[related:templates:temphask]{Template Haskell}

\begin{itemize}
\item Compiler-Erweiterung für Haskell
\item Ziele ähnlich C++-Templates / Makro-Prozessor
\item BQ und Slice
\item Meta-Code können normale Haskell-Funktionen sein
\item Reification (Reflection)
\item Statische Prüfung (nötig? Runtime gleich Compiletime)
\item Problem: Haskell-Syntax
  \begin{itemize}
  \item BQ kann nicht alles darstellen, z.B. $n$-äre Tupel
  \item spezielle Konstruktoren nötig $\Rightarrow$ komplex, Metaprogramm
    nicht ähnlich Programm
  \item Bei Lisp wäre das nicht passiert $\Rightarrow$ Andere Sprachen
    in Lisp-Notation sinnvoll
  \end{itemize}
\end{itemize}

\lsubsection[related:templates:macros]{Lisp-Makros}

\begin{itemize}
\item \cgen{} und Metaprogrammierung seit fast 50 Jahren
\item was können wir lernen?
\item lisp: homoikonisch
\item Einheitliche Syntax macht vieles leichter
\item compilererweitungen durch makros
\end{itemize}

\lsection[related:parser]{Parser-Generatoren}

\begin{itemize}
\item YACC
\item javacc
\item Treetop
\item Parsec
\end{itemize}

\lchapter[sexy]{Objektorientierte Ruby-Implementation}

\todo{überarbeiten}

\sexy{} ist das erste im Rahmen dieser Arbeit entworfene
\sexp{}-Compiler-Framework, welches in Ruby implementiert ist.

\sref{sexy:arch} erläutert die objektorientierte
Systemarchitektur und die Funktionsweise der Komponenten, woraufhin
\sref{sexy:macros} eine Implementation eines Lisp nachempfundenen
Makro-Konstruktes demonstriert. Als Beispiele für \sref{sexy:examples}
dienen die Definitionen der Sprachen, in denen das System selbst
geschrieben ist. \sref{sexy:limits} erörtert die Schwächen dieses
Ansatzes und liefert die Motivation für eine neue Version.

\lsection[sexy:reqs]{Anforderungen}

\begin{itemize}
\item 
\end{itemize}

\lsection[sexy:ruby]{Ruby}

Ruby ist eine dynamisch getypte, interpretierte Programmiersprache, die
sowohl funktional als auch objektorientiert ist und eine relativ
einfache Syntax benutzt\footnote{Die Ruby-Syntax ist einfach im
  Vergleich zu Sprachen wie C - aber natürlich noch immer um ein
  Vielfaches komplexer als Lisp-Syntax}, mit der viele
Schleifenkonstrukte durch die Übergabe von sogenannten Blöcken an
Funktionen realisiert werden können.  Unter Anderem aufgrund des
erfolgreichen Webframeworks \textit{Ruby on Rails} ist Ruby inzwischen
auch außerhalb seines Herkunftslandes Japan recht beliebt.

\lsubsection[sexy:ruby:runtime]{Laufzeiteigenschaften} 

Im Gegensatz zu den meisten kompilierten Sprachen\footnote{In einer
  interpretierten Sprache ist das Bereitstellen einer
  \icode{eval}-Funktion deutlich leichter - schließlich gibt es diese im
Interpreter bereits, so dass im Wesentlichen nur noch die Schnittstelle
erstellt werden muss.} hat Ruby wie Lisp die
Möglichkeit, über eine \icode{eval}-Funktion Code zur Laufzeit zu
evaluieren, was viele interessante Möglichkeiten mit sich bringt:
Beispielsweise lassen sich so Anwendungen erstellen, die durch eine
mitgelieferte Skriptsprache (Ruby selbst) erweitert werden können.

Das Wegfallen der Kompilationsphase hat sowohl Vor- als auch Nachteile:
Eine Übersetzung in Maschinensprache kostet Zeit, andererseits Laufen
kompilierte Programme meist schneller und sind sparender mit
Resourcen. In \textit{Ruby on Rails} beispielsweise muss eine Programm-
oder Template-Datei nur gespeichert werden, damit beim nächsten Aufruf
der Webseite bereits die neue Version in Kraft tritt, was sehr praktisch
zum Entwickeln ist. Allerdings haben Rails-Anwendungen einen hohen
Speicherverbrauch und sind vergleichsweise langsam\footnote{Die
  vergleichsweise schlechte Performance liegt allerdings nicht nur an
  der interpretierten Sprache, sondern auch an der Komplexität des
  Frameworks. Beispielsweise sind php-Anwendungen meist schneller,
  obwohl die Sprache ebenfalls interpretiert ist}.

Ähnllich verhält es sich mit der dynamischen Typisierung: Das Wegfallen
von Variablen-Deklarationen beschleunigt den Entwicklungsvorgang -
Stichwort "`Rapid Prototyping"' - und vereinfacht Refactorings. Im
Gegenzug fällt die nützliche statische Prüfung weg, so dass viele Fehler
erst unerwartet zur Laufzeit auftreten und deren Ursache möglicherweise
schwerer zu lokalisieren ist. Größere Ruby-Projekte verwenden deshalb meist
besonders viele \textit{Unit Tests} - welche natürlich auch bei statisch
typisierten Sprachen nützlich sind.

\lsubsection[sexy:ruby:classes]{Klassen und Methoden}

\lsubsection[sexy:ruby:blocks]{Blöcke}

\lsection[sexy:arch]{Architektur}

\begin{itemize}
\item Sexp
  \begin{itemize}
  \item als Liste
  \item \icode{<>} Notation für Kommentare, Strings usw.
  \item Parser mit Treetop
  \end{itemize}
\item Compiler als Klasse, Vererbung
\item 3 Stufen: Base, Ruby, Comp
\item metazirkulär
\item Formatierung: Fremder Ruby Formatter
\end{itemize}

\lsection[sexy:macros]{Makros}

\begin{itemize}
\item Rekursive Expansion
\item Implementation als Funktion, unterscheidung von Compiler-Funktionen
\item Laufzeitevaluation (\icode{compiler_eval_return})
\item backquote (besserer Ansatz mit Zahlen)
\item \icode{default_macro}
\end{itemize}
\lsection[sexy:examples]{Beispiele}

\lsection[sexy:disc]{Diskussion}

\begin{itemize}
\item Operatoren, Sonderzeichen $\Rightarrow$ Andere
  Repräsentation oder Codierung
\item Scheme vs CL defun/defmacro - Scheme kanonischer (siehe ...)
\item \icode{<>} unnötig
\item Parser versagt bei fehlerhaften Input
\item Genereller Pretty-Printer für andere Sprachen nötig
\end{itemize}

\lchapter[magicl]{Arrow-basierte Implementation in Haskell}

\todo{überarbeiten}

MagicL ist ein zweites Framework für \sexp-Compiler, welches anders
als \sexy{} intern mit getypten Modellen arbeitet. Zudem basiert diese
Neuimplementation auf einer Haskell-Umsetzung kategorientheoretischer
Konzepte (in \sref{magicl:cats_hask} beschrieben), mit deren Hilfe
beispielsweise in \sref{magicl:parser} sehr allgemeine und elegante
\sexp{}-Parser konstruiert werden. In \sref{magicl:sexp} geht es um
das Parsen von \sexps{} und die hierfür bereitgestellten
Hilfsfunktionen. \sref{magicl:arch} erklärt die Rahmenarchitektur mit
Modellen und Compilern, wobei Parser als spezielle Compiler aufgefasst
werden. \sref{magicl:examples} zeigt Beispiele für verschiedene
Modelle, Parser und Compiler, die Teil von MagicL sind.

\lsection[magicl:reqs]{Anforderungen}

\todo{Begriffsklärung \sexp{}-Parser}

\begin{itemize}
\item Schachtelung von Makros
\item EBNF wünschenswert
\item Generischer Pretty-Printer
\item Robusterer \sexp-{Parser} 
\item Typisiert vs untypisierte Zwischenmodelle
\item Vorteile Typisiert
  \begin{itemize}
  \item "`Freier"' statischer Typcheck - Extra-Arbeit in \sexp{}-Modell
  \item simpler als bq-code
  \item Selbstdokumentation des Modells
  \end{itemize}
\item Vorteile untypisiert
  \begin{itemize}
  \item Kommunikation (externe Anwendungen, Netzwerk)
  \item Modellerstellung fällt weg $\Rightarrow$ Zeitersparnis
  \item Redundanzen können in \sexp{}-Version herausgenommen werden
  \end{itemize}
\item MagicL:
  \begin{itemize}
  \item Untypisierte Eingabe (Sexp)
  \item Typisierte Verarbeitung/Ausgabe (z.B. \icode{Code})
  \end{itemize}
\item Repräsentation von \sexps{}
  \begin{itemize}
  \item Sexp-Strachen sollten immer besonderen Head haben (klare
    Semantik, vgl. XML, Pretty-Print)
  \item Gesondert repräsentieren zum erzwingen?
  \item Nein, denn Missbrauch noch immer möglich und behandelnder Code
    wird komplizierter
  \item Definition
  \end{itemize}
\end{itemize}

\lsection[magicl:haskell]{Haskell}

\begin{itemize}
\item Pur, Funktional
\item Infix-Operatoren in Klammern
\item Unit-Typ
Der parametrisierte Datentyp \icode{Maybe} beschreibt optionale Werte,
die nicht vorhanden sein müssen:

\begin{code}
data Maybe a = Nothing | Just a
\end{code}

\icode{Nothing} entspricht \icode{null} in anderen Sprachen.
\item Typinferenz
\item Currying
\item Datentypen, newtype (Abstraktion f. Typklassen), type (Typvariablen)
\item Klassen (Vorbedingungen, Multi, Variablen als Konstruktoren, Abhängigkeiten)
\item Hier: (...) => als auslassung
\end{itemize}

\lsection[magicl:cats]{Kategorientheorie}

Die Kategorientheorie ist ein sehr abstrakter Zweig der Mathematik -
aber auch ein universeller, denn fast alle wichtigen mathematischen
Strukturen sind Kategorien. Kategorientheorie findet dank seiner
Allgemeinheit und Anwendbarkeit für Berechnungen auch in der Informatik
eine immer größer werdende Rolle. Die Implementation von MagicL benutzt
einige kategorientheorietische Begriffe, z.B. werden Parser als
zusammengesetzte Funktoren konstruiert. Dieser Abschnitt führt in die
Kategorientheorie ein und stellt alle später verwendeten Konzepte
vor. Die Definitionen sind weitgehend aus \cite{Grundlagen} übernommen.

\lsubsection[magicl:cats:intro]{Einführung}

\fig{cat_funs}{Ein simples Funktionensystem}

\todo{abs=round}

Der Grundansatz der Kategorientheorie ist die Verallgemeinerung der
Art und Weise, wie mit Funktionstypen gerechnet wird - insbesondere
hinsichtlich der Komposition von Funktionen. \abb{cat_funs} zeigt ein
kleines Funktionensystem zwischen den Mengen $\mathbb{R} \times
\mathbb{R}$, $\mathbb{R}$ und $\mathbb{Z}$. Es kommen folgende
Funktionen vor:
\begin{itemize}
\item $+ : \mathbb{R} \times \mathbb{R} \ato \mathbb{R}$ addiert zwei
  reelle Zahlen.
\item $\mathrm{abs} : \mathbb{R} \ato \mathbb{Z}$ ist die Betragsfunktion.
\item $+1 : \mathbb{Z} \ato \mathbb{Z}$ addiert $1$ zu einer ganzen Zahl.
\item $\mathrm{abs} \circ + : \mathbb{R} \times \mathbb{R} \ato \mathbb{Z}$
  addiert zwei reelle Zahlen und bildet anschließend den Betrag.
\end{itemize}

Die Komposition $\mathrm{abs} \circ +$ (gesprochen "`abs \textit{nach} +"') lässt
sich bilden, weil der Definitionsbereich von $\mathrm{abs}$ mit dem
Zielbereich von $+$ übereinstimmt (nämlich $\mathbb{R}$). Es lassen sich
also zwei im Diagramm aufeinander folgende Pfeile zu einem direkten
zusammenfassen. Die Kategorientheorie "`vergisst"' nun den Bezug zu
Mengen und Funktionen und arbeitet statt dessen abstrakt mit Objekten
und Morphismen.

\lsubsection[magicl:cats:cat]{Kategorien}

\defi{Kategorie}{
Eine Kategorie $\mathbf{C} = (\mathrm{Ob}^\mathbf{C}, \mathrm{Mor}^\mathbf{C},
\circ^\mathbf{C}, \mathrm{id}^\mathbf{C})$ ist gegeben durch
\begin{itemize}
\item eine Klasse $\mathrm{Ob}^\mathbf{C}$ von Objekten\footnote{Da Objekte selbst Mengen
    sein können, wäre eine Definition von $\mathrm{Ob}^\mathbf{C}$ als Menge problematisch.}.
\item eine Menge Morphismen $\mathrm{Mor}^\mathbf{C}_{A,B}$ für alle $ A,B \in
  \mathrm{Ob}^\mathbf{C}$, wobei $A$ und $B$ Domäne und Codomäne genannt werden,
\item einen Kompositionsoperator $\circ^\mathbf{C}_{A,B,C}$ für alle $
  A,B,C \in \mathrm{Ob}^\mathbf{C}$ mit \\
  $\circ^\mathbf{C}_{A,B,C} : \mathrm{Mor}^\mathbf{C}_{B,C} \times
  \mathrm{Mor}^\mathbf{C}_{A,B} \rightarrow \mathrm{Mor}^\mathbf{C}_{A,C}$,
\item eine Identität $\mathrm{id}^\mathbf{C}_A \in \mathrm{Mor}^\mathbf{C}_{A,A}$ für alle $ A \in \mathrm{Ob}^\mathbf{C}$,
\end{itemize}
wobei folgende Axiome erfüllt sein müssen:
\begin{itemize}
\item Neutralität der Identität: $$f \circ_{A,A,B} \mathrm{id}_A = \mathrm{id}_B \circ_{A,B,B} f = f$$
\item Assoziativität:
  $$f \circ_{A,C,D} (g \circ_{A,B,C} h) = (f \circ_{B,C,D} g) \circ_{A,B,D}h$$
\end{itemize}
}

Indizes und Kategorien werden der Einfachheit halber weggelassen, wenn
sie aus dem Kontext hervorgehen. Wie von Funktionen gewohnt, lässt sich
$f \in \mathrm{Mor}_{A,B}$ auch schreiben als $f : A \ato B$. Sind $A$
und $B$ identisch, bezeichnet man f auch als Endomorphismus.

\fig{cat_simple}{Eine einfache Kategorie}

Wie das Einführungsbeispiel erwarten lässt, bilden die Mengen und
Funktionen eine Kategorie, genannt $\mathbf{Set}$. \abb{cat_simple} zeigt eine
andere simple Beispielkategorie, die aus den Objekten $A, B$ und den
Morphismen $f, g, \mathrm{id}_A, \mathrm{id}_B$ besteht. Alle Kompositionen
dieser Morphismen sind wieder in $\mathrm{Mor}^{\mathbf{Set}}$ - denn
jede Kategorie ist selbstverständlich unter Komposition geschlossen.

\fig{cat_comp}{Das Assoziativitätsaxiom als kommutatives Diagramm}

Viele Definitionen der Kategorientheorie erfolgen über sogenannte
kommutative Diagramme:

\defi{Kommutatives Diagramm}{ Ein Diagramm kommutiert, wenn
  für je zwei eingezeichnete Pfade $f=f_1 \circ \cdots \circ f_n : A
  \rightarrow B$ und $g=g_1 \circ \cdots \circ g_n : A \rightarrow B$
  zwischen zwei Objekten $A$ und $B$ die Gleichung $f=g$ gilt.  }
Beispielsweise zeigt \abb{cat_comp} das Assoziativitätsaxiom als
kommutatives Diagramm. $g$ ist nur der Vollständigkeit halber
eingezeichnet und spielt für das kommutative Diagramm selbst keine
Rolle. Dieses Diagramm dient lediglich der Veranschaulichung, ist aber
nicht selbst für die Definition der Assoziativität geeignet -
schließlich setzt \dref{Kommutatives Diagramm} bereits Assoziativität
von $\circ$ voraus.

\lsubsection[magicl:cats:prod]{Produkte und Coprodukte}

Die Kategorientheorie schafft es, Begriffe für Funktionseigenschaften
wie Injektivität sowie Mengenoperationen wie das kartesische Produkt auf
Kategorien zu verallgemeinern, indem sich die neuen Definitionen
ausschließlich auf Objekte und Morphismen beziehen und nicht von Mengen
oder Funktionen im speziellen Gebrauch machen. In der Kategorie
$\mathbf{Set}$ stimmen die neuen Begriffe dann genau mit den alten
überein. Dem kartesischen Produkt entspricht das Produkt von Objekten:

\defi{Produkt}{ Ein Objekt $A \times B$ mit zwei Projektionsmorphismen
  $\pi_1 : A \times B \ato A$ und $\pi_2 : A \times B \ato B$ ist ein
  Produkt von $A$ und $B$, wenn für jedes $X \in \mathrm{Ob}$ sowie für
  alle $f : X \ato A$ und alle $g : X \ato B$ genau ein Morphismus
  $\langle f,g \rangle : X \ato A \times B$ existiert, für den
  \abb{cat_product} kommutiert, d.h.  $\pi_1 \circ \langle f,g \rangle =
  f$ und $\pi_2 \circ \langle f,g \rangle = g$ gelten.  }

\begin{figure}
  \centering
  \subfloat[Produkt]{
    \includegraphics[scale=0.3]{images/cat_product}
    \label{magicl:fig:cat_product}
  }
  \subfloat[Coprodukt]{
    \includegraphics[scale=0.3]{images/cat_coproduct}
    \label{magicl:fig:cat_coproduct}
  }
  \caption{Kommutative Diagramme zur Definition von Produkt und Coprodukt}
\end{figure}

Man kann leicht nachvollziehen, dass das kartesische Produkt genau ein
Produkt für die Kategorie $\mathbf{Set}$ ist. $\langle f,g \rangle$ ist
hier die Funktion, die $x$ auf das Tupel $(f(x), g(x))$ abbildet.

Dreht man im Diagramm alle Pfeile um, erhält man die Definition für das
Coprodukt, ein zum Produkt dualer\footnote{Die zu einer Kategorie
  $\mathbf{C}$ duale Kategorie $\mathbf{C}^{\mathrm{op}}$ entsteht
  nämlich durch das Umdrehen von Pfeilen.} Operator:

\defi{Coprodukt}{ Ein Objekt $A + B$ mit zwei Injektionsmorphismen
  $\iota_1 : A \ato A + B$ und $\iota_2 : B \ato A + B$ ist ein
  Coprodukt von $A$ und $B$, wenn für jedes $X \in \mathrm{Ob}$ sowie
  alle $f : A \ato X$ und alle $g : B \ato X$ genau ein Morphismus
  $[f,g] : A + B \ato X$ existiert, für den \abb{cat_coproduct}
  kommutiert, d.h.  $[f,g] \circ \iota_1 = f$ und $[f,g] \circ \iota_2 =
  g$ gelten.  }

Das Coprodukt entspricht einer disjunkten Vereinigung von Mengen, also
einer Vereinigung von Mengen. die vorher explizit disjunkt gemacht
werden (sofern sie es nicht bereits sind). Dies kann beispielsweise durch
die Indizes $L$ und $R$ geschehen: $\{1,2,3\} + \{2,3,4\} =
\{1_L,2_L,3_L,2_R,3_R,4_R\}$. Der Morphismus $[f,g]$ entspricht einer
Fallunterscheidung: Auf Elemente aus $A$ wird $f$ angewendet, auf welche
aus $B$ entsprechend $g$.

\lsubsection[magicl:cats:func]{Funktoren}

Strukturerhaltende Abbildungen zwischen Objekten und Morphismen zweier
Kategorien werden Funktoren genannt:

\defi{Funktor}{
Ein Funktor $F=(F_{\mathrm{Ob}},F_{\mathrm{Mor}}) : \mathbf{C}
\rightarrow \mathbf{D}$ von Kategorie $C$ nach Kategorie $D$
    \begin{itemize}
    \item bildet jedes Objekt $A \in \mathrm{Ob}^{\mathbf{C}}$ auf $F_{\mathrm{Ob}}(A) \in
      \mathrm{Ob}^{\mathbf{D}}$ ab,
    \item bildet jeden Morphismus $f \in
      \mathrm{Mor}^{\mathbf{C}}_{A,B}$ auf $F_{\mathrm{Mor}}(f) \in
      \mathrm{Mor}^{\mathbf{D}}_{F_{\mathrm{Ob}}(A),F_{\mathrm{Ob}}(B)}$
      ab,
    \end{itemize}
    wobei für alle $A,B,C \in \mathrm{Ob}^{\mathbf{C}}$ und alle $f \in
    \mathrm{Mor^{\mathbf{C}}_{B,C}},g \in
    \mathrm{Mor^{\mathbf{C}}_{A,B}}$ folgende Axiome erfüllt sein
    müssen:
    \begin{itemize}
    \item Erhaltung der Komposition:
      $$F_{\mathrm{Mor}}(f \circ^{\mathbf{C}} g) =
      F_{\mathrm{Mor}}(f) \circ^{\mathbf{D}} F_{\mathrm{Mor}}(g)$$
    \item Erhaltung der Identität:
      $$F_{\mathrm{Mor}}(\mathrm{id}^{\mathbf{C}}_A) =
      \mathrm{id}^{\mathbf{D}}_{F_{\mathrm{Ob}}(A)}$$
    \end{itemize}
}

Statt $F_{\mathrm{Ob}}$ und $F_{\mathrm{Mor}}$ kann einfach $F$
geschrieben werden, wenn aus dem Kontext hervorgeht welche Abbildung
gemeint ist.

Kategorien als Objekte und Funktoren als Morphismen ergeben selbst
wieder eine Kategorie, die Kategorie der kleinen Kategorien - kleine
Kategorien sind Kategorien, deren Klasse von Objekten eine Menge
ist. Diese Einschränkung ist nötig, da Klassen von Klassen in der
Mathematik ähnlich problematisch sind wie Mengen von Mengen.

\lsubsection[magicl:cats:nats]{Natürliche Transformationen}

Eine andere Möglichkeit, aus Funktoren eine Kategorien zu bilden,
besteht darin, diese als Objekte zu benutzen. Alle Funktoren $\mathbf{C}
\ato \mathbf{D}$ als Objekte bilden die sogenannte Funktorkategorie über
$\mathbf{C}$ und $\mathbf{D}$, deren Morphismen natürliche
Transformationen heißen. 

\defi{Natürliche Transformation}{Eine natürliche Transformation $\alpha:F \nto
G$ ordnet jedem Objekt $A$ aus $\mathbf{C}$ einen Morphismus
$\alpha_A:F(A) \ato G(A)$ aus $\mathbf{D}$ zu, wobei für alle Objekte
$A,B$ und alle Morphismen $f:A \ato B$ aus $\mathbf{C}$ die
Gleichung
$$\alpha_B \circ F(f) = G(f) \circ \alpha_A $$
gelten muss, was dem kommutativen Diagramm in \abb{cat_nat}
entspricht.
}

Obwohl natürliche Transformationen in der Funktorkategorie Morphismen
sind, werden sie für die bessere Unterscheidung mit $\nto$ statt
$\ato$ notiert.

\fig{cat_nat}{Kommutatives Diagramm in Kategorie $\mathbf{D}$ für die Definition von
  natürlichen Transformationen}

\lsubsection[magicl:cats:monads]{Monaden}

Monaden setzen sich aus einem Endofunktor und zwei natürlichen
Transformationen zusammen:
\defi{Monade}{Eine Monade $(T,\eta,\mu)$ über der Kategorie $\mathbf{C}$ besteht aus
  \begin{itemize}
  \item einem Endofunktor $T:\mathbf{C} \ato \mathbf{C}$,
  \item einer natürlichen Transformation $\eta:\mathrm{id}_{\mathbf{C}} \nto T$,
  \item einer natürlichen Transformation $\mu:T^2 \nto T$,
  \end{itemize}
wobei für jedes Objekt $A$ folgende Axiome erfüllt sein müssen:
\begin{itemize}
\item Assoziativität: $$\mu_A \circ T(\mu_A) = \mu_A \circ \mu_{T(A)}$$
\item Neutrales Element: $$\mu_A \circ T(\eta_A) = \mu_A \circ \eta_{T(A)} = \mathrm{id}_{T(A)}$$
\end{itemize}
}
$\mathrm{id}_\mathbf{C}:\mathbf{C} \ato \mathbf{C}$ bezeichnet hier den Identitätsfunktor,
$\mathrm{id}_{T(A)}:T(A) \ato T(A)$ dagegen den Identitätsmorphismus. Auch diese Gleichungen ließen sich
als kommutative Diagramme darstellen.  

Das erste Axiom beschreibt zwei verschiedene Arten, einen Morphismus von
$T(T(T(A)))$ nach $T(A)$ zu bilden: $T(\mu_A):T(T(T(A))) \ato T(T(A))$
auf der linken Seite behält das äußere $T$ bei und verwendet $\mu$, um
das innen stehende $T(T(A))$ in $T(A)$ zu überführen. Rechts reduziert
$\mu_{T(x)}:T(T(T(A))) \ato T(T(A))$ dagegen von außen und lässt das
innere $T(A)$ unangerührt. Wird das Ergebnis dann in $\mu$ gesteckt,
sind innere und äußere Reduktion ununterscheidbar. Die Gleichung lässt
sich auch kurz als $\mu \circ T \mu = \mu \circ \mu T$ schreiben.

Das zweite Axiom funktioniert ähnlich, nur beschreiben diesmal beide
Seiten eine Art, den Identitätsmorphismus für das Objekt $T(A)$ zu
bilden. $T(\eta_A):T(A) \ato T(T(A)$ fügt das neue $T$ innen ein,
$\eta_{T(A)}:T(A) \ato T(T(A))$ hingegen außen.

Zu jeder Monade lässt sich eine neue Kategorie bilden, die Kleisli-Kategorie:
\defi{Kleisli-Kategorie}{
Die Kleisli-Kategorie $\mathbf{C}_K$ zur Kategorie $C$ und der
Monade $(T,\eta,\mu)$ besteht aus
\begin{itemize}
\item den Objekten von $\mathbf{C}$,
\item den Morphismen $f^{\mathbf{C}} \in
  \mathrm{Mor}^{\mathbf{C}}_{A,T(B)}$ aus $C$, die in $f \in
  \mathrm{Mor}^{\mathbf{C}_K}_{A,B}$ umbenannt werden,
\item der Identität $\mathrm{id}_A = \eta_A$,
\item der Komposition $f \circ^{\mathbf{C}_K}_{A,B,C} g = \mu_C
  \circ^{\mathbf{C}} T(f) \circ^{\mathbf{C}} g$.
\end{itemize}
}
Die Erfüllung der Kategorieaxiome wird hier nicht gezeigt, folgt aber
aus den Axiomen für Funktoren, natürliche Transformationen und Monaden.

Monaden sind in der Programmierung nützlich, da sie generisch das
Rechnen mit "`eingepackten"' Werten beschreiben. Beispielsweise könnte
$A$ für den Typ \icode{Int} und $T(A)$ für \icode{List of Int}
stehen. $\eta$ beschreibt dann die Erzeugung einer einelementigen Liste,
$\mu$ reduziert eine Liste von Listen auf eine flache Liste. Über die
Kleisli-Kategorie lassen sich damit bespielsweise nichtdeterministische
Funktionen, die eine Liste möglicher Resultate zurückliefern, elegant
Verknüpfen. Haskell (siehe \sref{magicl:haskell}) benutzt Monaden unter
anderem, um Seiteneffekte in eine normalerweise pur funktionale Sprache
einzubauen, wie \sref{magicl:cats_hask:monads} erklärt.

\lsection[magicl:cats_hask]{Kategorien in Haskell}

Die Haskell-Bibliotheken bieten viele kategorientheotische Begriffe an,
die allerdings immer bestimmten Einschränkungen
unterliegen. Beispielsweise sind die Objekte einer Kategorie hier immer
Haskell-Typen. Die Typklasse \icode{Category} ist wie folgt definiert:
\begin{code}
class Category cat where
  id   :: cat a a
  (.)  :: cat b c -> cat a b -> cat a c
\end{code}
Ein Typ \icode{cat}, der selbst zwei Typparameter benötigt, ist also eine
Instanz von \icode{Category}, wenn es generische Identitäts- und
Kompositionsoperatoren gibt, die für beliebige Typen $a,b,c$ benutzt
werden können. Genau genommen bestimmt \icode{Category} also keine
Kategorien, sondern vielmehr die Morphismen bestimmter Kategorien. Auch
die Axiome werden hier nicht gefordert - vielmehr liegt es am
Programmierer, dies für eine "`vernünftige"' Programmsemamtik selbst zu
verifizieren. Man sieht hier schon, dass die Haskell-Begriffe nur sehr
vage mit den mathematischen übereinstimmen - dies wird auch bei den
weiteren Definitionen so bleiben. Die einfachste Instanz von
\icode{Category} ist \icode{(->)}, also die Kategorie der
Haskell-Funktionen, bezeichnet als $\mathbf{Hask}$.
Oft wird statt \icode{.} der \icode{>>>}-Operator (genannt "`vor"') %<<
benutzt mit \icode{f >>> g = g . f}. %<<

\lsubsection[magicl:cats_hask:arrows]{Arrows}

Die Typklasse \icode{Arrow} beschreibt (die Morphismen von) Kategorien,
für die ein Funktor aus der Kategorie $\mathbf{Hask}$ existiert, wo man
also jeder Haskell-Funktion vom Typ \icode{a -> b} einen Morphismus vom
Typ \icode{cat a b} zuordnen kann. Dies ist deshalb sinnvoll, da viele
(Haskell-)Kategorien "`mehr"' können als die Funktionen, formal eine zu
$\mathbf{Hask}$ isomorphe Unterkategorie besitzen. Beispielsweise
benutzt MagicL "`Funktionen, die fehlschlagen können"' oder "`Funktionen
mit Nebeneffekten"' als Kategorien, die jeweils auch normale Funktionen
enthalten. Zusätzlich wird eine Operation auf Tupeln gefordert, aus der
sich ein Produkt zusammensetzen lässt - ein Coprodukt wird zunächst nicht gefordert:
\begin{code}
class (Category ar) => Arrow ar where
  arr   :: (a -> b) -> ar a b
  first :: ar a b  -> ar (a, c) (b, c)
\end{code}
\icode{arr} ist der Funktor, der jede Funktion auf einen Arrow
abbildet\footnote{Die Typen werden auf sich selbst abgebildet}.
\icode{first} ist eine Funktion, die aus einem Arrow einen Arrow auf
Tupeln macht, der nur auf dem ersten Element arbeitet, das zweite
dagegen unverändert durchschleift. Somit lassen sich zusätzliche Werte
weiterreichen, außerdem lassen sich aus \icode{first} sinnvolle
Operationen ableiten:

\begin{code}
  second :: ar a b -> ar (c, a) (c, b)
  second = arr swap >>> first f >>> arr swap
    where swap (x, y) = (y, x)

  (***) :: ar a b -> ar a' b' -> ar (a, a') (b, b')
  f *** g = first f >>> second g

  (&&&) :: ar a b -> ar a b' -> ar a (b, b')
  f &&& g = arr diag >>> (f *** g)
    where diag x = (x,x)
\end{code} % <<

\begin{itemize}
\item \icode{second} ist analog zu \icode{first}, reicht allerdings das erste
Element unverändert weiter.
\item \icode{f *** g} wendet \icode{f} auf das
erste Element, danach \icode{g} auf das zweite Element eines Tupels
an.
\item \icode{f &&& g} ist nun die Haskell-Entsprechung von $\langle f,g
\rangle$ in \dref{Produkt}. \icode{f} und \icode{g} werden also beide
auf die Eingabe angewendet und deren Ergebnisse zu einem Tupel
zusammengesetzt.
\end{itemize}

Möchte man einen Arrow mit einer Funktion verknüpfen, gibt es mit
\begin{code}
f >>^ func = f >>> arr func
\end{code}% <<
noch etwas syntaktischen Zucker.

\lsubsection[magic:cats:coproducts]{Coprodukte: Die Klasse \texttt{ArrowChoice}}

Die Haskell-Entsprechung zu einer disjunkten Vereinigung ist der
\icode{Either}-Datentyp, der folgendermaßen definiert ist:
\begin{code}
data Either a b = Left a | Right b
\end{code}
Coprodukte für Arrows werden durch die Klasse \icode{ArrowChoice} beschrieben:
\begin{code}
class (Arrow ar) => ArrowChoice ar where
  left :: ar a b -> ar (Either a c) (Either b c)
\end{code}
Auch hier wird mit \icode{left} nur eine einfache Operation gefordert,
aus der sich anschließend alles weitere konstruieren lässt. Diese
Funktion wandelt einen Arrow von \icode{a} nach \icode{b} um in
einen Arrow von \icode{Either a c} nach \icode{Either b c}. Bei einem
\icode{Left}-Wert wird also der ursprüngliche Arrow angewendet, ein
\icode{Right}-Wert wird dagegen unverändert weitergereicht.
\begin{code}
  right :: ar a b -> ar (Either c a) (Either c b)
  right f = arr swap >>> left f >>> arr swap
    where swap (Left x)  = Right x
          swap (Right x) = Left x

  (+++) :: ar a b -> ar a' b' -> ar (Either a a') (Either b b')
  f +++ g = left f >>> right g

  (|||) :: ar a c -> ar b c -> ar (Either a b) c
  f ||| g = (f +++ g) >>> arr dropEither
    where dropEither (Left x)  = x
          dropEither (Right x) = x

\end{code} %<<
Die Definitionen sind weitgehend analog zu den entsprechenden
Produkt-Operationen:
\begin{itemize}
\item \icode{right} bearbeitet nur \icode{Right}-Werte, während
  \icode{Left}-Werte unverändert bleiben.
\item \icode{f +++ g} wendet auf \icode{Left}-Werte \icode{f} an, auf
  die anderen \icode{g}.
\item Haben \icode{f} und \icode{g} den selben Rückgabetyp, kann
  \icode{f ||| g} verwendet werden, welches das in diesem Fall unnötige
  \icode{Either} verschwinden lässt. Dies entspricht $[f,g]$ in
  \dref{Coprodukt}
\end{itemize}

\lsubsection[magicl:cats_hask:functors]{Funktoren}

Die Haskell-Bibliotheken definieren eine Klasse \icode{Functor}, welche
allerdings nur Endofunktoren über der Kategorie $\mathbf{Hask}$ repräsentieren:
\begin{code}
class Functor f where
  fmap :: (a -> b) -> f a -> f b
\end{code}
Ein Datenkonstruktor \icode{f} ist also Instanz von \icode{Functor},
wenn die Operation \icode{fmap} Funktionen von \icode{a} nach \icode{b}
auf Funktionen von \icode{f a} nach \icode{f b} abbildet. Der
mathematische Funktor besteht hier also aus \icode{(f,fmap)}.

Diese Arbeit benutzt statt dessen eine eigene \icode{Functor}-Klasse,
die Verschiedene Kategorien zulässt:
\begin{code}
class Functor f ar | f -> ar where
  lift :: ar a b -> f a b
\end{code}
Die Arrows \icode{f} und \icode{ar} bilden eine Instanz von
\icode{Functor}, wenn eine \icode{lift}-Operation \icode{ar}-Arrows auf
\icode{f}-Arrows zwischen den gleichen Typen abbildet - wobei der Typ
\icode{f} den Typ \icode{ar} determiniert. Der mathematische Funktor
hier ist also \icode{(id,lift)}. Im Vergleicht zu Haskell's
Standard-\icode{Functor} ist diese Version also in den Kategorien
allgemeiner, aber dafür spezieller in der Abbildung der Objekte, da hier
die Identität vorgeschrieben ist. Man könnte auch dies allgemein
formulieren - aber im Rahmen von MagicL reicht die spezielle Version
bisher aus.

Alle hier verwendeten \icode{Functor}-Instanzen konstruieren aus einem
\icode{Arrow}-Typ einen zweiten mit zusätzlichen Eigenschaften,
z.B. erweitert der \icode{FailFunctor} einen Arrow-Typ um mögliches
Scheitern. Die Instanz-Deklaration dafür sieht im Gerüst folgendermaßen
aus (die Details werden in \sref{magicl:parser:fail} erläutert):
\begin{code}
newtype FailFunctor ar a b = ...

instance (Arrow ar) => Functor (FailFunctor ar) ar where
  lift f = ...
\end{code}

\lsubsection[magicl:cats_hask:monads]{Monaden}

Die Typklasse \icode{Monad} aus den Haskell-Bibliotheken beschreibt
Monaden über der Kategorie $\mathbf{Hask}$. $\eta$ aus
\sref{magicl:cats:monads} heißt hier \icode{return}, statt $\mu$ wird der
Operator \icode{>>=} %<<
mit anderer Signator gefordert:
\begin{code}
class Monad m where
  return :: a -> m a
  (>>=)  :: m a -> (a -> m b) -> m b
\end{code} % <<
Es gibt auch eine genaue Entsprechung von $\mu$, die hier \icode{join}
heißt:
\begin{code}
join :: (Monad m) => m (m a) -> m a
join x = x >>= id
\end{code} % <<

Zu jeder Haskell-Monade \icode{m} lässt sich wieder die
Kleisli-Kategorie bilden, die die Datentypen als Objekte sowie die
Funktionen \icode{a -> m b} als Morphismen enthält. Die
Haskell-Bibliotheken stellen hierfür den Datentyp \icode{Kleisli}
bereit:
\begin{code}
newtype Kleisli m a b = Kleisli (a -> m b)

instance (Monad m) => Category (Kleisli m) 
  where id = Kleisli return
        Kleisli f . Kleisli g = Kleisli composed
          where composed x = g x >>= f

instance (Monad m) => Arrow (Kleisli m) 
  where arr fun = Kleisli (return . fun)
        first (Kleisli f) = Kleisli tupleF
          where tupleF (x, z) = f x >>= (\ y -> return (y, z))
\end{code} %<<

Arrows und Monaden werden beide verwendet, um abstrakt Verknüpfungen von
speziellen Operationen zu beschreiben. Arrows sind allgemeiner, denn
jede Monade lässt sich beispielsweise mittels \icode{Kleisli} auf einen
entsprechenden Arrow abbilden. Auf der anderen Seite entspricht aber
nicht jedem Arrow eine Monade, denn aus den Arrow-Operationen allein
lässt sich \icode{>>=} % <<
nicht konstruieren (siehe \cite[S. 18f]{Hughes}). Dies wirft die Frage
auf, weshalb Haskell überhaupt Monaden benutzt und nicht alles über
Arrows realisiert. Zum einen gibt es dafür historische Gründe: Monaden
waren bereits 1993 in Haskell präsent \cite[S.23ff]{HaskellHistory},
während Arrows erst 1998 von John Hughes vorgeschlagen wurden, da sich
spezielle Parser mit statischen Komponenten nicht durch Monaden
ausdrücken lassen \cite{Hughes}. Zum anderen bieten Monaden aber auch
Vorzüge: Die Definition einer Monade ist etwas kürzer, da keine
\icode{first}-Funktion für Produkte bereitgestellt werden muss - wie
obiger Code zeigt lässt sich dies bereits mittels \icode{>>=} % <<
ausdrücken. Zudem gibt es für Monaden in Haskell die praktische
\icode{do}-Notation:
\begin{code}
do x <- foo
   y <- bar x
   return (x, y)
\end{code}
ist syntaktischer Zucker für
\begin{code}
foo >>= (\ x ->
  bar x >>= (\ y ->
    return y))          
\end{code} % <<
und ermöglicht eine Schreibweise, die imperativen Programmen ähnelt -
dies ist kein Zufall, da die \icode{IO}-Monade genau für Nebeneffekte
zuständig ist (siehe \sref{magicl:cats_hask:monads:examples:io}). Diese
Verwendung erklärt auch nachträglich den Namen \icode{return}, wobei es
sich noch immer um die $\eta$-Transformation handelt und nicht etwa ein
syntaktisches \icode{return}-Statement wie in imperativen Sprachen
üblich.

Für Arrows gibt es mit \icode{proc} auch eine Notation, mit der
Zwischenergebnisse benannt werden können. Diese ist aber weniger simpel
und elegant als das Monadenäquivalent. Auf der anderen Seite eignen sich
Arrows besser als Monaden für eine punktfreie Schreibweise, d.h. einer
Schreibweise ohne Zwischenvariablen, bei der ausschließlich auf
Komposition zurückgegriffen wird. Punktfreie Notation wird auch bei
Definitionen von Funktionen oft verwendet und ist für viele
Haskell-Programmierer natürlicher und eleganter.

\lsubsubsection[magicl:cats_hask:monads:examples]{Beispiele für Monaden}

\lparagraph[magicl:cats_hask:monads:examples:maybe]{\icode{Maybe}}

Funktionen, die fehlschlagen können, lassen sich in der Form \icode{a
  -> Maybe b} darstellen. Möchte man mehrerer solcher Funktionen
verketten, werden normalerweise viele Fallunterscheidungen benötigt, da
bei jeder Funktion die Rückgabe geprüft und nur im Erfolgsfall die
nächste aufgerufen muss. Haskell vereinfacht dies, indem \icode{Maybe}
zur Monade erklärt wird:
\begin{code}
instance Monad Maybe 
  where return = Just
        (Nothing >>= _) = Nothing
        (Just x  >>= f) = f x
\end{code} % <<
Obiges Codebeispiel
\begin{code}
do x <- foo
   y <- bar x
   return (x, y)
\end{code}
würde in der Maybe-Monade so interpretiert werden: Wenn \icode{foo}
erfolgreich ist, wird das Ergebnis (lokal) in \icode{x} gespeichert. Ist
daraufhin \icode{bar x} ebenfalls erfolgreich, wird dieses in \icode{y}
gespeichert und als Ergebnis \icode{Just (x, y)} zurückgegeben. Schlägt
eine der Funktionen fehl, ist das ergebnis \icode{Nothing}.

\lparagraph[magicl:cats_hask:monads:examples:io]{\icode{IO}}

Jede Programmiersprache benötigt für die reale Welt Möglichkeiten,
Operationen mit Nebeneffekten wie das Schreiben oder solche, die von
externen Nebeneffekten abhängen, wie das Lesen von Dateien,
auszuführen. Dies lässt sich zunächst schwer in eine puren Sprache wie
Haskell integrieren. Die \icode{IO}-Monade bietet hier eine Lösung: Man
stelle sich einen fiktiven Datentyp \icode{World} vor, der den gesamten
Zustand der externen Welt enthält. \icode{IO a} ist nun eine Funktion,
die die Welt liest und eine andere Welt sowie ein a zurückgibt:
\begin{code}
newtype IO a = World -> (World, a)
\end{code}
Zum Verketten zweier \icode{IO}-Operationen wird die von der ersten
zurückgegebene Welt an die zweite übergeben. Damit dies nicht von Hand
geschehen muss, wird \icode{IO} wieder als Monade deklariert. Nun gibt
es aber natürlich keinen wirklichen \icode{World}-Typen - in
Wirklichkeit wird also der Haskell-Compiler alles, was mit \icode{IO}
verpackt ist, in imperativen Code übersetzen. Dennoch gelingt dadurch
die saubere Trennung von puren Code und solchem, der Nebeneffekte
enthalten kann. Da ist nicht möglich ist, eine "`Auspack-Funktion"'
\icode{IO a -> a} zu definieren\footnote{Es gibt eine solche Funktion in
  Haskell, die aber normalerweise nicht verwendet werden sollte.}, das
Gegenteil aber mit \icode{return} möglich ist, kann imperativer Code
immer funktionalen, funktionaler Code aber niemals imperativen
enthalten. Die äußerste Funktion jedes Haskell-Programms, \icode{main},
wird deshalb immer in der \icode{IO}-Monade ausgeführt.

Dank der Kleisli-Kategorie lassen sich mittels \icode{IO} auch Arrows
bereitstellen, die Nebeneffekte enthalten:
\begin{code}
type IOArrow = Kleisli IO
\end{code}

\lsection[magicl:parser]{Parser als Arrows}

Das Herzstück von MagicL ist ein Arrow-basiertes Framework für die
Konstruktion von Parsern. Die obersten Ziele sind Allgemeinheit sowie
sinnvolle Ausgaben im Fehlerfall. Mit Allgemeinheit sind zwei
Anforderungen gemeint: Zum einen sollen beliebige Streams gelesen
werden können und nicht etwa nur Zeichenketten, damit auch \sexps{}
verarbeitet werden können und so eine Art alternativer Makroprozessor
erstellt wird. Zum anderen soll das Interface so allgemein sein, dass
später beliebige andere Parser-Architekturen integriert werden können.

Haskell besitzt mit Parsec\cite{Parsec} bereits eine sehr
performante und praktische Parser-Kombinator-Bibliothek, die auf Monaden
basiert. Diese ist allerdings auf die Verarbeitung von Zeichenketten
beschränkt, weshalb sie in MagicL keine Verwendung findet. 

MagicL benutzt Arrows und Funktoren, um möglichst allgemein zu
sein. Alles, was im Rahmen dieser Arbeit implementiert wurde, hätte zwar
auch über Monaden und Monaden-Transformatoren konstruiert werden
können. Dennoch besteht die Möglichkeit, dass später Ergänzungen
vorgenommen werden sollen, die sich nicht mittels Monaden ausdrücken
lassen - beispielsweise ein effizienterer Parsing-Algorithmus, der
sowohl statische als auch dynamische Komponenten enthält, wie ihn
Swierstra und Duponcheel entworfen haben (siehe \cite[S. 8ff]{Hughes}).

Dieser Abschnitt entwickelt nun schrittweise einen Parser-Datentyp aus
Arrows. Parser zeichnen sich hauptsächlich durch zwei Eigenschaften aus:
\begin{itemize}
\item Sie können fehlschlagen sowie Alternativmöglichkeiten im Falle des
  Scheiterns besitzen.
\item Sie bearbeiten einen Zustand, der die Position im Eingabestream
  beschreibt.
\end{itemize}
Diese beiden Eigenschaften lassen sich einzeln mittels Funktoren auf
bestehenden Kategorien ausdrücken.

\lsubsection[magicl:parser:fail]{Fehlschlagende Arrows}

Berechnungen von $A$ nach $B$, die fehlschlagen können, sollen zwei
mögliche Resultate haben. Im Erfolgsfall wird ein normaler Rückgabewert
aus $B$ geliefert, während im Falle eines Scheiterns eine Fehlermeldung
als String zurückgegeben wird - im Gegensatz zur \icode{Maybe}-Monade,
die im Fehlerfall nur ein \icode{Nothing} liefert. Der Rückgabetyp ist
deshalb das Coprodukt $\mathrm{String}+B$. Statt Morphismen von $A$ nach
$B$ wollen wir also nun Morphismen von $A$ nach $\mathrm{String}+B$. Um
den aufrufenden Code nicht komplizierter zu machen, empfiehlt es sich,
diese Änderung in einer neuen Kategorie $\mathbf{C}_f$ zu
verstecken. $f_{f} : A \rightarrow B$ aus der neuen Kategorie wird
abgebildet auf $f : A \rightarrow \mathrm{String} + B$ Der Arrow
$\mathrm{fail}_{f} : \mathrm{String} \rightarrow a$ in $C_{f}$ schlägt
immer fehl und entspricht $fail : \mathrm{String} \rightarrow
\mathrm{String} + a$ in $C$.

Der Operator $\bigvee : Mor_{A,B} \times Mor_{A,B}
\rightarrow Mor_{A,B} $ bietet Alternativen. Um Morphismen aus
$\mathbf{C}$ in $\mathbf{C}_f$ benutzen zu können, gibt es den Funktor
$\mathrm{lift}_f:\mathbf{C} \ato \mathbf{C}_f$, welcher die
unveränderte, d.h. gelingende Operation für die neue Kategorie
übernimmt.

Die Haskell-Entsprechung von $\mathrm{String}+B$ ist \icode{Either
  String b}, was sich mit \icode{Failable b} abkürzen lässt, wenn man
den parametrisierten Typ \icode{Failable} einführt:

\begin{code}
type Failable a = Either String a
\end{code}

Der Fehlerfall wird durch \icode{Left String} ausgedrückt, ein Erfolg
durch \icode{Right a}. Fehlschlagende Arrows nun sind in MagicL durch den
Typ \icode{FailFunctor} implementiert:

\begin{code}
newtype FailFunctor ar a b = FailF (ar a (Failable b))

instance (Arrow ar) => Functor (FailFunctor ar) ar where
    lift f = FailF (f >>> arr Right)
\end{code} % <<

Arrows von \icode{a} nach \icode{b}, die fehlschlagen können, sind also
Arrows von \icode{a} nach \icode{Failable b}, die in den zusätzlichen
Konstruktor \icode{FailF} eingebettet wurden. Um einen normalen Arrow
\icode{f} aus \icode{ar} nach \icode{FailFunctor ar} zu "`liften"', wird
der Rückgabewert in ein \icode{Right} gebettet und der resultierende
Arrow in \icode{FailF}.
Der Arrow \icode{fail} wird in eine \icode{Arrow} erweiternde Typklasse
ausgegliedert, so dass dieser auch in anderen Kategorien bereitgestellt
werden könnte:

\begin{code}
class (Arrow ar) => ArrowFail ar where
  fail :: ar String a

instance (ArrowChoice ar) => ArrowFail (FailFunctor ar) where
  fail = FailF (arr Left)
\end{code}

Der Oder-Operator $\bigvee$ entspricht in Haskell \icode{<+>}, welchen
die bereits in den Haskell-Bibliotheken definierte Typklasse
\icode{ArrowPlus} bereitstellt:

\begin{code}
instance (ArrowChoice ar) => ArrowPlus (FailFunctor ar) where
  FailF f <+> FailF g = FailF ((f &&& g) >>> arr tupleOr)
    where tupleOr (Left  _, y)  = y
          tupleOr (Right x), _) = Right x
\end{code} % <<

Es werden also \icode{f} und \icode{g} parallel evaluiert und
anschließend von der Funktion \icode{tupleOr} verarbeitet, die, sollte
\icode{f} fehlschlagen, das Ergebnis von \icode{g} zurückgibt, ansonsten
das Ergebnis von \icode{f}.

\fig{cat_fail}{Komposition beim Fail-Funktor}

Die Typabhängigkeit von \icode{ArrowChoice} ist nötig, weil
\icode{FailFunctor ar} nur dann ein \icode{Arrow} ist, wenn \icode{ar}
ein Coprodukt anbietet. Denn die Komposition in $C_{f}$ ist definiert
durch $g_{f} \circ f_{f} = ([fail,g] \circ f)_{f}$, was in Haskell
\begin{code}
FailF g . FailF f = FailF (f >>> (arr Left ||| g))
\end{code} %<<
entspricht. Tritt in \icode{f} ein Fehler auf, wird dieser also wieder
in ein \icode{Left} eingepackt und zurückgegeben. Ansonsten wird das
durch \icode{|||} implizit aus dem \icode{Right}-Konstruktor ausgepackte
Ergebnis an \icode{g} weitergereicht.

\abb{cat_fail} zeigt die Komposition in $\mathbf{C}_f$ und deren
zurückführung auf ein Coprodukt in $\mathbf{C}$. Die Funktion, die $f_f$
auf $f$ abbildet, kann nicht Teil eines Funktors sein. Ein solcher
müsste nämlich das Objekt $B$ sowohl auf $\mathrm{String}+B$ (bei der
Transformation von $f$ als auch auf $B$ selbst (bei $g$) abbilden.

\todo{(Co)Produkt?}

\lsubsection[magicl:parser:state]{Arrows mit Zuständen}

Zustände lassen sich ähnlich zu einem Arrow hinzufügen. Über Produkte
wird der Zustandstyp $S$ (z.B. eine Stream-Position oder der
\textit{Seed} eines Zufallszahlengenerators) an Domäne und Codomäne
herangehängt, was wieder in einer neuen Kategorie $C_{s}$ versteckt
wird. Ein Morphismus $f_{s} : A \rightarrow B$ der neuen Kategorie wird
entsprechend abgebildet auf $f = A \times S \rightarrow B \times S$. Da
hier im Gegensatz zum Fail-Funktor Domäne und Codomäne gleich abgebildet
werden, ist diese Abbildung Teil eines Funktors $F_s: C_{s}
\ato C$. \abb{cat_state} zeigt d

\fig{cat_state}{Komposition in $\mathbf{C}_s$ und Rückführung auf
  $\mathbf{C}$ durch $F_s$}

In MagicL gibt es die Typklasse \icode{StateFunctor}, die einen weiteren
Typparameter \icode{s} für den Zustand bekommt:

\begin{code}
newtype StateFunctor s ar a b = StateF (ar (a, s) (b, s))

instance (Arrow ar) => Functor (StateFunctor s ar) ar where
    lift = StateF . first  
\end{code} % <<

Die "`geliftete"' Version eines Arrows soll den Zustandsparameter
unverändert weitergeben - dies entspricht genau der
\icode{first}-Funktion aus \sref{magicl:cats_hask:arrows}.

Das Lesen und Schreiben von Zuständen wird von den Funktionen \icode{get} und
\icode{put} bereitgestellt, welche in der Typklasse \icode{ArrowState}
definiert werden:

\begin{code}
class (Arrow ar) => ArrowState s ar | ar -> s where
  get :: ar a s
  put :: ar s ()
  
instance (Arrow ar) => ArrowState s (StateFunctor s ar)
  where
    get = StateF (arr (\ (_, state) -> (state, state)))
    put = StateF (arr (\ (state, _) -> ((), state)))
\end{code}

\icode{get} ignoriert also den Eingabewert und gibt den aktuellen
Zustand zurück, während \icode{put} den übergebenen Zustand
"`abspeichert"' und (bis auf diesen) nichts zurückgibt.

\todo{Prod/Coprod?}

\lsubsection[magicl:parser:parse]{Der Parse-Funktor}

Nun lassen sich obige Kategorie-Erweiterungen zu einer Parser-Kategorie
$\mathbf{C}_p = \mathbf{C}_{fs}$ zusammensetzen, d.h. die ursprüngliche
Kategorie wird zunächst um Fehler zu $\mathbf{C}_f$, danach um Zustände
zu $\mathbf{C}_p$ erweitert. Die Reihenfolge hier ist wichtig, damit ein
Morphismus $A \ato B$ aus $\mathbf{C}_p$ auf $A \times S \ato
\mathrm{String} + B \times S$ in $\mathbf{C}$ abgebildet wird und nicht
auf $A \times S \ato (\mathrm{String} + B) \times S$, wie es andersherum
wäre. Denn das Coprodukt muss "`außen"' stehen, um im Kontrollfluß
zuerst bearbeitet zu werden und somit ein Backtracking im Fehlerfall zu
ermöglichen. 

Backtracking wird allerdings zu einem Problem, wenn man sinnvolle
Fehlermeldungen produzieren will. Man stelle sich einen Parser für die
(in einer fiktiven Sprache beschriebene) Grammatik \texttt{\{.*\}
  $\bigvee$ [.*]} vor, die eine beliebige Zeichenkette in geschweiften
oder eckigen Klammern beschreibt. Beim Eingabewort \texttt{\{ABC}
scheitert zunächst aufgrund der fehlenden schließenden Klammer die erste
Alternative, woraufhin die zweite probiert wird. Das Wort beginnt aber
nicht mit \texttt{[}, so dass der Parser beispielsweise mit der Meldung
\texttt{"'Expected [, got \{"'} scheitert. Diese Meldung beschreibt den
Fehler schlecht - statt dessen möchte man nach dem Lesen von \texttt{\{}
das Backtracking deaktivieren, denn bereits hier ist klar, dass die
andere Alternative nicht mehr in Betracht kommt. Dies führt zu einer
sinnvolleren Fehlermeldung wie \texttt{"'Expected \}, got end of
  stream"'}.

Ein derartiger "`nicht-auffangbarer"' Fehler lässt sich durch das
Einbauen einer weiteren Möglichkeit des Scheiterns ermöglichen, wir
definieren also $\mathbf{C}_p = \mathbf{C}_{ffs}$ und bieten eine
Funktion \icode{forceParser} an, die einen (Sub-)Parser derart
modifiziert, dass, falls dieser Scheitert, der Fehler in die "`inneren"'
und damit nicht-recover-fähigen Fail-Kategorie übernommen wird. Hiervon
wird beispielsweise bei der Funktion \icode{macro}
\sees{magicl:sexp} Gebrauch gemacht.

Die Haskell-Definition vom \icode{FailFunctor} benutzt als Zustandstyp
einen Stream (als Liste repräsentiert) vom Token-Typ \icode{t}:

\begin{code}
newtype ParseFunctor t ar a b = 
  P (StateFunctor 
     [t] 
     (FailFunctor (FailFunctor ar))
     a
     b)
\end{code}

Dank der Implementation als Funktor ist die Kategorie, in der der Parser
ausgeführt wird, frei wählbar. So können rein funktionale Parser in
$Hask_p$ konstruiert werden. Benötigt man aber Debug Outputs (z.B. bei
der Suche einer Endlosschleife) oder andere Seiteneffekte, kann
$\mathbf{IO}_p$ benutzt werden. In MagicL werden diese Kategorien durch
die Typaliase FunParser wowie IOParser bereitgestellt:
\begin{code}
type FunParser t a b = ParseFunctor t (->) a b
type IOParser  t a b = ParseFunctor t IOArrow a b
\end{code}
Eine geeignete innere Kategorie könnte
sogar interaktive Debugger, Netzwerktransparenz oder sonstige Features
anbieten. Auch der variable Token-Typ erzeugt viele Möglichkeiten:
Textdateien können mit \icode{Char}, Bitstreams mit \icode{Bool} oder
\sexp{}-Streams mit \icode{Sexp} verarbeitet werden.

\lsubsection[magicl:parser:lib]{Parser-Library}

MagicL beinhaltet eine Parser-Bibliothek, in der u.a. viele simple
Parser-Konstruktoren definiert sind. Hier ein paar
Beipiele\footnote{Abhängigkeiten der Typparameter werden hier der
  Übersichtlichkeit halber weggelassen.}:
\begin{itemize}
\item \icode{empty :: ParseFunctor t ar a a}\\
  gibt seinen Eingabewert unverändert zurueck, wenn der Stream leer ist.
\item \icode{takeWhen :: (t -> Bool) -> (t -> String) -> ParseFunctor t ar a
    t}\\
  testet den ersten Token mit einem Prädikat. Im Erfolgsfall (\icode{True}) wird der
  Token zurückgegeben, ansonsten wird der Token an eine Funktion
  übergeben, die daraus eine Fehlermeldung aufbaut.
\item \icode{member :: [t] -> ParseFunctor t ar a t}\\
  testet, ob der erste Token in der übergebenen Liste vorkommt.
\item \icode{streamEq ::  [t] -> ParseFunctor t ar a [t]}\\
  prüft, ob die ersten $n$ Token mit den Elementen der übergebenen Liste
  übereinstimmen, und gibt diese im Erfolgsfall zurück. Für \icode{t =
    Char} wird hier also ein String gelesen.
\end{itemize}

Alle diese Funktionen (und deren Negationen) geben Parser mit nützlichen
Fehlermeldungen zurück.

Weiterhin gibt es viele Arrow-Kombinatoren, mit denen Parser,
vergleichbar mit den Operationen der Erweiterten Backus-Naur-Form (EBNF)
\cite{TODO}, verschaltet werden können. Mit den bisher eingeführten
Operatoren sind bereits Konkatenation (\icode{>>>}) %<<
und Alternative (\icode{<+>}) abgedeckt, darüber hinaus gibt es für
Instanzen von \icode{ArrowPlus} unter anderem folgende Funktionen:

\begin{code}
optional :: (...) => ar a b -> ar a (Maybe b)
optional f = (f >>^ Just) <+> constArrow Nothing
  where constArrow x = arr (\ _ -> x) 

many :: (...) => ar a b -> ar a [b]
many f = many1 f <+> constArrow []

many1 :: (...) => ar a b -> ar a [b]
many1 f = consArrow f (many f)
  where consArrow :: ar a b -> ar a [b] -> ar a [b]
        consArrow f g = (f &&& g) >>^ (\ (x,xs) -> x : xs)

skip :: (...) => ar a b -> ar a a
skip f = (f &&& id) >>^ snd

sepBy :: (...) => ar a c -> ar a b -> ar a [b]
sepBy sep item = 
  optional (consArrow item (many (skip sep >>> item))) >>^ unMaybeList
    where
      unMaybeList  Nothing  = []
      unMaybeList (Just xs) = xs
\end{code} % <<

\icode{optional} erzeugt einen Arrow, der, sollte der übergebene Arrow
scheitern, \icode{Nothing} zurückgibt - dabei aber "`erfolgreich"'
bleibt. Dies entspricht \icode{[ ]} in EBNF. Hierbei erzeugt
\icode{constArrow Nothing} einen Arrow, der die Eingabe ignoriert und
konstant \icode{Nothing} zurückgibt. Eine (optionale) Wiederholung (in EBNF
\icode{\{ \}}) erzeugt \icode{many}, \icode{many1} verlangt mindestens
ein Vorkommen. Die Hilfsfunktion \icode{consArrow} nimmt zwei
Arrows an und erzeugt daraus einen, der das Element, welches der erste
zurückgibt, vor die Liste hängt, die der zweite zurückliefert.
\icode{skip} ignoriert das Resultat eines Arrows und gibt
statt dessen seine Eingabe zurück - Zustandsänderungen kann der
ignorierte Arrow aber dennoch bewirken. \icode{sepBy} ist ein
komplizierteres Beispiel und ermöglicht das Parsen von Listen mit
Trennzeichen. Dafür bekommt die Funktion zwei Arrows übergeben:
\icode{sep} soll ein Trennzeichen, \icode{item} ein Element lesen. Es
wird zunächst ein \icode{item}, dann beliebig viele, von (ignorierten)
\icode{sep} angeführte \icode{item}-Elemente gelesen. Das ganze ist noch
in ein \icode{optional} gebettet, damit auch eine leere Liste gelesen
werden kann. Die Rückgabe wird mittels \icode{unMaybeList} vom durch
\icode{optional} erzeugten \icode{Maybe}-Datentyp befreit, so dass statt
\icode{Nothing} eine leere Liste zurückgegeben wird, wenn nichts gelesen
werden kann.

\lsubsubsection[magicl:parser:lib:example]{Beispiel: Ein \sexp{}-Parser}

Aufgrund der einfachen gewählten Struktur von \sexps{} und der
praktischen Parser-Library ist es möglich, in vier kurzen Zeilen einen
Parser für \sexps{}\footnote{Gemeint ist ein Parser von Text nach
  \sexps{}, wogegen die \sexp{}-Parser in \sref{magicl:sexp} \sexps{}
  lesen.} zu entwerfen:

\begin{code}
whitespace = skip (many (member " \t\n"))
\end{code}
Zunächst wird Whitespace als beliebige Anhäufung von Spaces, Tabs und
Newlines definiert, die ignoriert werden soll.
\begin{code}
parseSymbol = many1 (notMember " \t\n()") >>^ Symbol
\end{code} % <<
Ein Symbol ist eine Kette von Zeichen, die weder Whitespace noch
Klammern sind. Dieses wird gleich an den \icode{Symbol}-Konstruktor
übergeben, um den Typ \icode{Sexp} zu erhalten.
\begin{code}
parseNode = skip (eq '(') >>> (many parseSexp >>^ Node) >>> skip (eq ')') 
\end{code} % <<
Ein Knoten ist eine von Klammern umgebene Liste von \sexps{}, die
mittels \icode{Node}-Konstruktor zu einem \sexp{} wird.
\begin{code}
parseSexp = whitespace >>> (parseSymbol <+> parseNode) >>> whitespace
\end{code} % <<
Ein \sexp{} ist nun entweder ein Symbol oder ein Knoten, wobei davor und
danach Whitespace auftreten darf.

Tritt bei Lesen ein Fehler auf, wird automatisch eine brauchbare Fehlermeldung
ausgegeben, z.B.

\begin{code}
"(test) )"  ==>  Empty stream expected: ")"  
\end{code}

\lsection[magicl:sexp]{Parsen von \sexps{}}

Die Parser-Bibliothek an sich ist bereits nützlich, um Textdateien
einlesen zu können. Das eigentliche Ziel aber ist die Verarbeitung von
\sexps{}. Es lassen sich zwar bereits Streams von \sexps{} verarbeiten,
es gibt aber bisher keine komfortablen Operationen, um das Innere einer
\sexp{} zu testen oder zu verarbeiten. Da ein \sexp{} selbst wieder eine
Liste und damit ein Stream ist, bietet es sich an, diesen ebenfalls über
einen "`inneren Parser"' zu verarbeiten.

Beispielsweise könnte eine Liste von Personen folgenderweise
repräsentiert sein\footnote{Dieses Format ist unnötig redundant und
  sollte vermutlich besser durch \icode{(persons Franz Walter Heinz)} ersetzt
  werden - aber es handelt sich ja nur um ein einfaches Beispiel.}:
\begin{code}
(person Franz)
(person Walter)  
(person Heinz)
\end{code}

Ein Parser, der eine Liste von Namensstrings produzieren soll, würde mit
der bisherigen Bibliothek so aussehen:

\begin{code}
parsePerson = take >>^ proc >>> (fail ||| id)
  where proc (Node (Symbol "person", Symbol x)) = Right x
        pred _ = Left ("Not a person: " ++ show x)
parsePersons = many parsePerson
\end{code} % <<

Die Verarbeitung von Hand mittels \icode{Node} und \icode{Symbol} im
Pattern-Matching ist relativ umständlich. Deswegen gibt es eine Reihe
nützlicher Hilfsfunktionen für die Konstruktion von \sexp{}-Parsern:

\begin{itemize}
\item \icode{takeSexp} liest eine \sexp{} vom Stream und wandelt diese
  für die Unterscheidung zwischen Symbolen und Knoten mittels
  \icode{|||} in das Coprodukt \icode{Either String [Sexp]} um.
\item \icode{takeSymbol} erwartet ein Symbol und gibt dieses als String
  zurück - ansonsten wird eine Fehlermeldung ausgegeben.
\item \icode{symbolMacro name = skip (eq (Symbol name))} akzeptiert nur
  das Symbol mit Namen \icode{name}.
\item \icode{takeNode} erwartet einen Knoten und gibt diesen als Liste
  von \sexps{} zurück.
\item \icode{compNode innerComp} verarbeitet einen Knoten, indem der
  übergebene Parser \icode{innerComp} auf das Knoteninnere angewendet
  wird. Da Parser in MagicL immer als Compiler definiert werden (siehe
  \sref{magicl:arch:compiler}), heißt diese Funktion nicht \icode{parseNode}
\item \icode{macro name innerComp} % <<
  konsturiert nun einen Parser, der wie ein Macro das erste Element des
  Knotens mit dem Symbol \icode{name} vergleicht und im Erfolgsfall die
  restlichen Elemente mit \icode{innerComp} verarbeitet. Danach wird
  sichergestellt, dass der Knoten auch wirklich vollständig gelesen
  wurde - will man dies nicht, da man den Rest ignoriert, gibt es die
  Funktion \icode{looseMacro} mit identischer Signatur.
\end{itemize} 
Das obige Beispiel lässt sich nun umschreiben:
\begin{code}
parsePerson  = macro "person" takeSymbol  
parsePersons = many parsePerson
\end{code}

\icode{macro} benutzt \icode{forceParser} aus
\sref{magicl:parser:parse}, um das Backtracking auszuhebeln, sobald das
Symbol übereinstimmt, was wieder für bessere Fehlermeldungen
sorgt. Allerdings bedeutet dies, dass Code wie
\begin{code}
macro "foo" (symbolMacro "bar") <+> macro "foo" (symbolMacro "baz")
\end{code}
nicht erwartungsgemäß funktioniert:
\begin{code}
(foo bar)   => ()  d.h. Erfolg, kein Ergebnis
(foo baz)   => Symbol bar expected: baz
\end{code}
Es sollte deshalb immer nur ein \icode{macro} für jeden Begriff benutzt
werden, und eine Oder-Verknüpfung ins Innere verlegt werden - hier also:
\begin{code}
macro "foo" (symbolMacro "bar" <+> symbolMacro "baz")
\end{code}

\lsection[magicl:arch]{Rahmenarchitektur}

Um das Parser-Framework herum soll ein wieder möglichst allgemeines
Interface für die beschreibung von Compilern bestehen. Ziel ist die
selbstständige Suche nach einem passenden Compiler, wenn nur Ein- und
Ausgabetyp spezifiziert sind. Compiler sollen unter anderem als pure
Funktionen oder als Parser spezifiziert werden können.

Ein Compiler von \icode{a} nach \icode{b} ist in MagicL etwas, was sich
in eine Operation mit \icode{a} als Ein- und \icode{b} als Ausgabe
überführen lässt. Diese Operation kann im allgemeinen Nebeneffekte
enthalten, weshalb IOArrow verwendet wird. Typen, mit denen sich
Compiler repräsentieren lassen, implementieren die Typklasse
\icode{Executable}:
\begin{code}
class Executable x a b | x -> a b where
  toIO :: x -> IOArrow a b
\end{code}
\icode{x} ist selbst ein parametrisierter Typ, der die Ein- und
Ausgabetypen \icode{a} und \icode{b} bereits determiniert. Die einfachsten
Instanzen von \icode{Executable} werden durch IOArrows selbst sowie pure
Funktionen gebildet:
\begin{code}
instance Executable (IOArrow a b) a b where
  toIO = id

instance Executable (a -> b) a b where
  toIO f = Kleisli (return . f)
\end{code}
Auch Parser sind ausführbar, sofern der zugrundeliegende Arrow-Typ es
ist:
\begin{code}
instance (...) => Executable (ParseFunctor t ar () a) [t] a where
  toIO = toIO . execParser
\end{code}

Nun soll es möglich sein, einen ausführbaren Typen zu benutzen, um einen
eindeutigen Compiler von \icode{a} nach {b} einzurichten. Dies geschieht
über die Typklasse \icode{Compilable}:
\begin{code}
class (Executable x a b) => Compilable x a b | a b -> x where
  comp :: x
\end{code}
Da es nur einen ausgezeichneten Compiler von \icode{a} nach \icode{b}
geben kann, determinieren \icode{a} und \icode{b} gemeinsam \icode{x},
wobei die umgekehrte Abhängigkeit ebenfalls - von \icode{Executable}
geerbt - besteht. Es handelt sich also um eine 1:1-Beziehung. Die
spezifikation eines simplen funktionalen Compilers würde so aussehen:
\begin{code}
instance Compilable (A -> B) A B where
  comp x = ...
\end{code}
Der Parser, der Strings in Listen von \sexp{} einliest, wird auch als
Compiler spezifiziert:
\begin{code}
instance Compilable (FunParser Char () [Sexp]) String [Sexp] where
  comp = many parseSexp
\end{code}
Die Typklasse \icode{Compiler} "`vergisst"' nun den zur Definition
verwendeten Typen:
\begin{code}
class Compiler a b where
  compile :: IOArrow a b
  
instance (Compilable x a b) => Compiler a b where
  compile = toIO comp
\end{code}
Nun kann ein beliebiger Compiler einfach über einen explizit typisierten
\icode{compile}-Aufruf, wie etwa \icode{compile :: IOArrow String
  [Sexp]}, gefunden

MagicL enthält zudem ein minimalistisches Testframework, um Compiler
oder im speziellen Macros inkrementell zu testen.

\lsection[magicl:code]{\cgen{}}

Um komfortabel korrekt eingerückten Code in einer Zielsprache generieren
zu können, stellt MagicL einen Datentyp \icode{Code} zur Verfügung,
sowie einen Compiler von \icode{Code} nach \icode{String}, welcher ein
Nachbau des von Philip Wadler in \cite[S.223ff]{FunOfProgramming}
vorgestellten Pretty-Printers ist. Die elementaren
Konstruktor-Funktionen sind:
\begin{code}
newline :: Code
text    :: String -> Code
append  :: Code   -> Code -> Code
group   :: Code   -> Code
indent  :: Int    -> Code -> Code
\end{code}

\icode{newline}, \icode{text} und \icode{append} sollten selbsterklärend
sein. \icode{group} versucht den übergebenen \icode{Code} auf eine Zeile
zu bekommen, indem es alle Zeilenumbrüche durch Leerzeichen
ersetzt. Wird dabei allerdings die geforderte Zeilenlänge (im
Standard-Compiler 70) überschritten, wird die ursprüngliche Version mit
Zeilenumbrüchen genommen. \icode{indent} rückt den übergebenen
\icode{Code} bei jedem Zeilenumbruch um $n$ Zeichen ein, z.B. würde
\begin{code} 
indent 2 (conc [text "hallo", newline, text welt])
\end{code}
den Text
\begin{code}
hallo
  welt  
\end{code}
ergeben - dabei verbindet \icode{conc :: [Code] -> Code} eine Liste
mittels \icode{append}. Darüber hinaus gibt es viele weitere allgemeine
Funktionen wie 
\begin{code}
  joinBy :: Code -> [Code]
\end{code}
- welche einen Seperator benutzt, um eine Liste zusammenzufügen.
\begin{code}
joinBy "; " [text "foo", text "bar", text "baz"]  
\end{code}
würde also
\begin{code}
foo; bar; baz
\end{code}
ergeben. Aus diesen allgemeinen Funktionen werden dann Abkürzungen für
syntaktische Programmiersprachenelemente abgeleitet, wie
\icode{commaSep} für eine komma-separierte Liste oder \icode{parens},
\icode{braces} und \icode{brackets} für die drei gängigen Arten der
Klammerung.

\lsection[magicl:code:example]{Beispiel: Ein Pretty-Printer für \sexps{}}

\sexps{} sollen wie folgt formatiert werden: Passt der gesamte Ausdruck
noch auf die aktuelle Zeile, werden normal Leerzeichen verwendet:
\begin{code}
(a b (c d) e)  
\end{code}
Wird die gewünschte Breite aber überschritten, soll jeder Subausdruck
auf einer eigenen Zeile stehen, wobei alle bis auf den ersten um zwei
Zeichen eingerückt werden:
\begin{code}
(a
  b 
  (c d)
  e)  
\end{code}
Dies lässt sich mit dieser rekursiven Funktion erreichen:
\begin{code}
layoutSexp :: Sexp -> Code
layoutSexp (Symbol sym)    = text sym
layoutSexp (Node children) = format (map layoutSexp children)
  where format = parens . group . indent2 . lines
\end{code} %<<
Alternativ könnte \icode{layoutSexp} auch als \sexp{}-Parser
spezifiziert werden.

\lsection[magicl:sexphs]{Haskell in \sexps{}}

Wie auch \sexy{} besitzt auch MagicL eine \sexp{}-basierte und damit für
\cgen{} geeignete Version seiner Implementationssprache, hier
also Haskell. Diese ist zwar nicht vollständig, enthält aber die
wichtigsten Konstrukte, um sinnvoll Programmieren zu können.

\begin{itemize}
\item Typisiertes \icode{Haskell}-Modell vs. direkt Sexp -> Code
\item Funktionsaufrufe simpel
\item Operatoren
\item Typen
\item Syntaktische Konstrukte (where, do, Klassen, ...)
\end{itemize}

\lsection[magicl:disc]{Diskussion}

  \begin{itemize}
  \item MagicL sauberer und klarer als \sexy{}
    \begin{itemize}
    \item Getypte Modelle
    \item Praktische und flexible Parser-Konstruktion dank Kategorientheorie
    \item[$\Rightarrow$] "`Makros a la EBNF"'
    \item Allgemeines Compiler-Interface
    \item Typisierte Codegeneration mit erweiterbarer Bibliothek
    \end{itemize}
  \item Manches wirkt etwas umständilch und redundant
  \item[$\Rightarrow$] Hier könnte \cgen{} helfen
    \begin{itemize}
    \item Modellsprache
    \item Kleine DSL für \icode{code}-Konstruktion (kein \icode{text}
      mehr nötig) - würde auch wieder bei Generierung aus anderen
      Srpachen helfen
    \end{itemize}
  \item Brauchen wir ein \icode{backquote}?
    \begin{itemize}
    \item Typisierte Modelle normalerweise besser
    \item Evtl. Kommunikation mit anderen Programmiersprachen / über Streams
    \end{itemize}
  \end{itemize}
\lchapter[end]{Schluss}

\lsection[end:summary]{Zusammenfassung}

\begin{itemize}
\item Übertragung von Makros
\item Erster Prototyp
\end{itemize}

MagicL ist der Prototyp eines
universellen Frameworks für den Entwurf von Programmier- und
Auszeichnungssprachen. Es gibt dem Meta-Programmierer praktische
Werkzeuge für das Parsing und Übersetzen neuer sowie für Generierung von
Code bestehender Sprachen an die Hand, wobei insbesondere (jedoch
nicht ausschließlich) aus \sexps{} aufgebaute Sprachen unterstützt
werden. Die Parser- und Compilererstellung erfolgt nach einem
kategorientheoretisch motivierten Baukastenansatz, so dass
unter anderem Parser durch die Kombination von Arrows erzeugt werden.

...

\begin{itemize}
\item Fazit
\end{itemize}

\lsection[end:future]{Ausblick}
\begin{itemize}
\item DSL für Modell- und Compilerdefinition
\item Verschiedene DSL's
  \begin{itemize}
  \item Text (Latex)
  \item Graphen und Petrinetze
  \item Test-Framework (Haskell)
  \item Make-Tool (Haskell)
  \item andere Programmier- und Auszeichnungssprachen
  \end{itemize}
\item \sexp{}-IDE
  \begin{itemize}
  \item Struktureller Editor
  \item Modellspezifische GUI-Plugins
  \item Netzwerktransparenz und synchrone Bearbeitung
  \end{itemize}
\item Versionierung
  \begin{itemize}
  \item Diff (evtl. über IDE-Protokoll)
  \item Merge für Teamarbeit und passive \cgen{}
  \end{itemize}
\end{itemize}

\bibliographystyle{gerplain}
\bibliography{diplomarbeit} 

\end{document}

