\documentclass[a4paper, bibgerm]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{ngerman}
\usepackage{bibgerm}
\usepackage{color}
\usepackage{amssymb,amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{acronym}

\lstloadlanguages{Haskell}
\lstnewenvironment{code}
  {\lstset{}%
    \csname lst@SetFirstLabel\endcsname}
  {\csname lst@SaveFirstLabel\endcsname}
\lstset{
  basicstyle=\small\ttfamily,
  flexiblecolumns=false,
  basewidth={0.5em,0.45em}
% ,
%   literate={+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
%   {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
%   {\\\\}{{\char`\\\char`\\}}1
%   {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
%   {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2
%   {.}{{$\circ$}}2
%   {...}{{$\ldots$}}2
% % {\ .\ }{{$\circ$}}2
%   {>>>}{{$\ggg$}}2
% %  {>>}{{>>}}2 {>>=}{{>>=}}2 %<<
%   {|}{{$\mid$}}1
}

\newcommand\icode[1]{\lstinline?#1?}


\newcommand{\todo}[1]{
  \textcolor{red}{TODO: #1}
}

\newcommand{\defaultscale}{0.3}

\newcommand\lchapter{}
\newcommand\lsection{}
\newcommand\lsubsection{}
\newcommand\lsubsubsection{}
\newcommand\lparagraph{}
\newcommand\cref{}
\newcommand\sref{}
\newcommand\abb{}
\newcommand\fig{}
\newcommand\figs{}
\newcommand\subfig{}
\newcommand\vertfig{}
\newcommand\clipvertfig{}

\newcommand{\project}[1]{%
  \renewcommand\lchapter[2][\LChapterDefault]{%
    \def\LChapterDefault{##2}%
    \chapter{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsection[2][\LSectionDefault]{%
    \def\LSectionDefault{##2}%
    \section{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsubsection[2][\LSubSectionDefault]{%
    \def\LSubSectionDefault{##2}%
    \subsection{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsubsubsection[2][\LSubSubSectionDefault]{%
    \def\LSubSubSectionDefault{##2}%
    \subsubsection{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lparagraph[2][\LParagraphDefault]{%
    \def\LParagraphDefault{##2}%
    \paragraph{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\cref[1]{%
    Kapitel~\ref{#1:sec:##1}%
  }%
  \renewcommand\sref[1]{%
    Abschnitt~\ref{#1:sec:##1}%
  }%
  \renewcommand{\abb}[1]{Abb.\ref{#1:fig:##1}}
  \renewcommand{\fig}[3][\defaultscale]{%
    \begin{figure}[htp]
      \centering
      \includegraphics[scale=##1]{images/##2}
      \caption{##3}
      \label{#1:fig:##2}
  \end{figure}}

  \renewcommand{\figs}[3]{%
    \begin{figure}[htp]
      \centering
      ##3
      \caption{##2}
      \label{#1:fig:##1}
    \end{figure}
  }

  \renewcommand{\subfig}[3][\defaultscale]{%
    \subfloat[##3]{
      \includegraphics[scale=##1]{images/##2}
      \label{#1:fig:##2}
    }
  }

  \renewcommand{\vertfig}[3][\defaultscale]{%
    \begin{sidewaysfigure}[htp]
      \centering
      \includegraphics[scale=##1]{images/##2}
      \caption{##3}
      \label{#1:fig:##2}
    \end{sidewaysfigure}%
  }

  \renewcommand{\clipvertfig}[5]{%
    \begin{sidewaysfigure}[htp]
      \centering
      \includegraphics*[scale=##1, viewport=##2]{images/##3}
      \caption{##5}
      \label{#1:fig:##4}
    \end{sidewaysfigure}%
  }
}

\project{magicl}

\newcommand\ato{\rightarrow}

\newtheorem{defini}{Definition}

\newcommand{\defi}[2]{%
  \begin{defini}[#1]
    \label{def:#1}
    #2
  \end{defini}
}

\newcommand{\dref}[1]{Def. \ref{def:#1}}

\newcommand{\sees}[1]{(siehe \sref{#1})}

\newcommand{\sexy}{S-Exy}
\newcommand{\sexp}{S-Expression}
\newcommand{\sexps}{S-Expressions}

\begin{document}

\begin{titlepage}
\title{Prototypische Frameworks für die inkrementelle Übersetzung von \sexp{}-basierten Sprachen}
\author{Benjamin Teuber}
\date{\today}

\maketitle
\end{titlepage}

\tableofcontents

\listoffigures

\chapter*{Abkürzungsverzeichnis}
\begin{acronym}
%\setlength{\itemsep}{-\parsep}
\acro{DSL}{Domain Specific Language}
\acro{DSSSL}{Document Style Semantics and Specification Language}
\acro{EBNF}{Erweiterte Backus-Naur-Form}
\acro{MDA}{Model Driven Architecture}
\acro{UML}{Unified Modelling Language}
\acro{XML}{Extensible Markup Language}
\end{acronym}

% \setlength{\parindent}{0pt}
% \setlength{\parskip}{2ex}

\lchapter[intro]{Einleitung}

\lsection[intro:motiv]{Motivation}

Modellgetriebene Softwareentwicklung ist in aller Munde: Die \ac{UML}
feiert bald ihr 15-Jähriges bestehen \footnote{Der
  Standarisierungsprozess von UML begann 1994, als Gary Booch und Jim
  Rumbaugh mit der Vereinheitlichung ihrer Modellierungstechniken
  begannen. \cite{TODO}}, IBM vermarktet seit Jahren das Produkt
\textit{Rational Application Developer} (\cite{TODO}), das, wie auch das freie
\textit{Eclipse Modelling Framework} oder auch \textit{Enterprise
  Architect}, Eclipse um modellbasierte Code-Generierung
bereichert. Seit neuestem zeigt auch Microsoft Interesse und
verspricht mit \textit{Oslo} \cite{TODO} einen ``Mainstream"=Ansatz
für Modellierung''. Code-Generierung fällt auch im World Wide Web eine
immer größer werdende Rolle zu: Ob \textit{Ruby on Rails} oder
\textit{Google Web Toolkit}, praktisch alle Web Frameworks generieren
zumindest ihre HTML-Dateien oder SQL-Strings für den Datenbankzugriff.

Abstraktion durch Code-Generierung ist also beliebter denn je, und
Werkzeuge, die diese anbieten oder nutzen, gibt es in großen
Mengen. Dennoch arbeiten die meisten Werkzeuge mit Templates oder
String-Manipulation und damit auf Zeichenketten, womit sie
technologisch einen großen Schritt hinter der \textit{strukturellen}
Generierung stehen, die Lisp-Programmierer bereits vor 40 Jahren mit
\sexps{} und Makros praktiziert haben. Denn über \sexps{} wird Lisp-Code
in einer Baumstruktur repräsentiert, wodurch das Verarbeiten
und Generieren von Code deutlich vereinfacht und darüber hinaus viele
Fehlerquellen vermieden werden. Makros ermöglichen zudem eine
inkrementelle, modulare Compiler-Entwicklung.

Lisp-Programmierer, auf der anderen Seite, haben sich immer nur im die
Erzeugung von Lisp-Code selbst gekümmert und bis auf wenige Ausnahmen
(siehe z.B. ParenScript \cite{TODO}, welches JavaScript aus \sexps{}
generiert) andere Sprachen ignoriert. Zudem wird Lisp allgemein
totgeschrieben, was teils an veraltetem Sprachdesign, hauptsächlich
aber an der geringen Anzahl verfügbarer Bibliotheken im Vergleich zu
Mainstream-Sprachen liegt. Während viele andere Lisp-Konzepte wie
Garbage Collection oder Konstrukte wie der REPL, eine
Lisp-Kommandozeile zum interaktiven Programmieren und Testen, bereits
von modernen Sprachen nachgeahmt wurden, stehen Makros\footnote{Der
  C-Preprozessor bietet ebenfalls Makros an - diese sind allerdings
  weniger mächtig als Lisp-Makros \sees{basic:lisp:cprep}.} nur noch
der kleinen Lisp-Community zur Verfügung. Es wäre also wünschenswert,
diese oder etwas Vergleichbares im Rahmen moderner Sprachen für
Code-Generierung und -Verarbeitung nutzen zu können.

Gebiete:
\begin{itemize}
\item Makros
\item Baumtransformationen
\item Rountrip
\item UML
\item XML-Verarbeitung
\item Präprozessoren
\item StringTemplate etc.
\item XML Parser Generator
  \begin{itemize}
  \item Gibt es, vgl. mit Haskell-Modellsprache
  \item Wenn 1:1 Haskell:Sexp "`genausogut"' wie MagicL
  \item Wann ist 1:1 schlecht?
  \end{itemize}

\end{itemize}

\lsection[intro:goal]{Fragestellungen und Zielsetzung}

Die grundlegende Fragestellung dieser Arbeit lautet: Ist es möglich,
die Lisp-Ansätze für Code-Generierung derart zu verallgemeinern, dass
sich beliebige durch \sexps{} repräsentierte Sprachen damit
komfortabel kompilierien und möglichst auch interpretieren lassen
können? Es soll allerdings nicht zwangsläufig eine Eins-zu-Eins-Kopie
der Lisp-Makros erfolgen, sondern vielmehr geprüft werden, welche
Möglichkeiten es noch gibt und welche davon eventuell noch besser
geeignet für den neuen, breiteren Kontext beliebiger Sprachen
sind. Insbesondere soll die Implementation selbst nicht in Lisp
erfolgen, um eine gewisse Unabhängigkeit zu gewährleisten und die
Entwicklung neuer Ideen zu ermutigen.

Konkret soll in einer Programmiersprache X zunächst eine
Repräsentation für \sexps{} sowie ein \sexp{}-Parser erstellt werden,
woraufhin eine Architektur für \sexp{}-Compiler angelegt werden soll,
die einen inkrementellen und modularen Compiler-Entwurf ähnlich Lisp
unterstützt. Damit soll eine \sexp{}-Version von X entstehen, welche
sich nach X-Quelltext übersetzen lässt, so dass Werkzeuge, die X
generieren wollen, nur noch deren simplere \sexp{}-Variante erzeugen
müssen. In dem Moment ist das Bootstrapping abgeschlossen, so dass von
nun an ausschließlich mit \sexp{}-Sprachen programmiert werden
könnte. Auch bestehender Quelltext kann nun durch aus \sexps{}
genererierten Versionen ersetzt werden, wodurch ein metazirkulärer
Compiler entsteht.

Darüber hinaus soll zuletzt untersucht werden, inwieweit eine spezielle
(\sexp{}-basierte) \ac{DSL} für Compilerdefinition gestaltet werden kann, in
der sich die Übersetzung einfacher beschreiben lässt als in X
oder deren \sexp{}-Schwester. Diese Sprache kann beispielsweise die
Definition von Lisp-Makros ermöglichen.

\lsection[intro:outline]{Aufbau dieser Arbeit}

\cref{basic} liefert zunächst alle Grundlagen für die späteren
Kapitel, indem benutzte Programmiersprachen, Verfahren und
mathematische Definitionen erläutert und verglichen werden.

In \cref{sexy} wird mit \sexy{} ein erster, in Ruby geschriebener Prototyp eines
universellen Frameworks für \sexp{}-Compiler geschildert, welcher
sich sehr dicht an den ursprünglichen Lisp-Makros
orientiert.

\cref{magicl} widmet sich MagicL, dem Kern dieser Arbeit. Diese
Neuimplementation basiert auf einer Haskell-Umsetzung
kategorientheoretischer Konzepte, mit deren Hilfe unter anderem sehr
allgemeine und elegante \sexp{}-Parser konstruiert werden
können. Zudem benutzt MagicL im Gegensatz zu \sexy{} getypte Modelle.

\cref{end} fasst zum Schluss die Ergebnisse zusammen und gibt
einen Ausblick auf viele weitere Ideen und Verbesserungen, die nicht im
Rahmen dieser Arbeit behandelt werden können.

\lchapter[basic]{Grundlagen}

Dieses Kapitel soll alle Voraussetzungen für die späteren Kapitel liefern.
\sref{basic:codegen} erläutert verschiedene Arten der
Codegenerierung. In \sref{basic:parser} werden bestehende Werkzeuge
für die Generierung von Parsern beschrieben. \sref{basic:lisp} stellt
die Programmiersprache Lisp und insbesondere \sexps{}, die universelle
Datenstruktur dieser Arbeit, sowie Makros vor. \sexps{} werden in
\sref{basic:xml} mit der \ac{XML} verglichen, außerdem werden dort
XML-Werkzeuge vorgestellt. \sref{basic:ruby} und \sref{basic:haskell}
behandeln die Sprachen Ruby und Haskell, in denen die in dieser Arbeit
vorgestellten Frameworks implementiert sind. Zuletzt erklärt
\sref{basic:cats} die Konzepte der Kategorientheorie, an denen sich
das zweite Framework MagicL orentieren wird.

\lsection[basic:codegen]{Codegenerierung}

\todo{Definition} was Codegenerierung bedeutet:
Das automatisiertes Erzeugen von Quelltext. Dennoch gibt es diverse
Unterschiede zwischen Codegenerierungswerkzeugen. \todo{quelle}

So differenziert man zwischen aktiver und passiver
Codegenerierung. Aktiv bedeutet, dass die Generierung wiederholt
ausgeführt werden kann, wenn sich etwas am Modell oder Generator
ändert, da die komplette Datei generiert wird. Passiv generierter Code
dagegen wird anschließend vom Programmierer modifiziert bzw. erst mit
sinnvollen Inhalten bestückt, so dass dieser normalerweise nur
einmalig generiert werden kann, wenn die Anpassungen nicht
überschrieben werden sollen. \todo{roundtrip} Zwischen aktiver und
passiver Generierung liegen Dateien, in denen nur markierte Abschnitte
generiert werden - so dass der Rest unverändert bleiben kann. Optimal
wäre \todo{kriterien} natürlich ein allgemeiner Merge-Mechanismus, der die Arbeit des
Programmierers reibungslos in die neue Version übernimmt - dies ist
aber leider schwierig zu implementieren.

Zudem lässt sich nach Ein- und Ausgabe des Generators unterscheiden:
Diese können flache Strings, strukturierte (zunächst) ungetypte Daten wie \sexps{}
und XML oder aber getypte Modelle einer Programmiersprache sein.

Vorteile:
\begin{itemize}
\item Abstraktion - Modellarchitekten beötigen keine
  Programmiersprachkenntnisse, Backend austauschbar
``Ist die Sprache an die Problemdomäne angepasst, muss man das Problem
nicht in die Sprache zwängen''
\item Produktivität - DRY-Prinzip spart u.U. viel Zeit
\item Qualität - ist der Generator fehlerfrei, gibt es keine Probleme
  bei neuen Modellen
\item Konsistenz - einheitliche Strukturen/Namen, minimiert Einarbeitungszeit
\end{itemize}

Nachteile:
\begin{itemize}
\item Dokumentation / Einarbeitung
\item Fehlersuche
\item Komplexität
\item Entwicklungsaufwand
\end{itemize}

\lsection[basic:parser]{Parser-Generatoren}

\lsection[basic:lisp]{Lisp und \sexps{}}

\begin{itemize}
\item Code-Generierung und Metaprogrammierung seit fast 50 Jahren
\item was können wir lernen?
\item lisp: homoikonisch
\item Einheitliche Syntax macht vieles leichter
\item compilererweitungen durch makros
\end{itemize}

\lsubsection[basic:lisp:cprep]{Vergleich mit dem C-Präprozessor}
\begin{itemize}
\item C-Makros seit ca. 1975
\item Keine komplette Programmiersprache (if, define, aber nicht goto, funktionen)
\item gensym fehlt
\end{itemize}

\lsection[basic:xml]{XML}

\begin{itemize}
\item gleiche Zielsetzung - Baumstruktur
\item syntax: ``</tag>'' vs. ``)''
\item nur vorteilhaft f texteditor ohne parent-matching!
\item XML komplexer, da Attribute
\item kann auch durch unterknoten ausgedrückt werden - wird es nur aufgrund
unständlicher syntax nicht
\item nicht mehr rekursiv, komplexe attribute gehen nicht (wirklich)
\item diskussion: makros good or bad
\end{itemize}

\begin{itemize}
\item XPath: Adressieren, z.B. \icode{//kap[@title="Grundlagen"]/pa}
  (alle Absätze aus Kap. ``Grundlagen'')
\item XSLT: Turing-Vollständige Baum-Transformationssprache in XML
  \begin{itemize}
  \item template: Matcher in XPath
  \item Schleifen, sortierung, if-Abfragen
  \item Nachvolger der \ac{DSSSL} (Scheme-Dialekt $\rightarrow$ \sexp{}-basiert)
  \item Unterschied zu Makros: Keine ``richtige'', praktische Programmiersprache
  \item $\rightarrow oft wird für komplexere Operationen andere Sprache benutzt$
  \end{itemize}
\end{itemize}

\lsection[basic:ruby]{Ruby}

Ruby ist eine dynamisch getypte, interpretierte Programmiersprache, die
sowohl funktional als auch objektorientiert ist und eine relativ
einfache Syntax benutzt\footnote{Die Ruby-Syntax ist einfach im
  Vergleich zu Sprachen wie C - aber natürlich noch immer um ein
  Vielfaches komplexer als Lisp-Syntax}, mit der viele
Schleifenkonstrukte durch die Übergabe von sogenannten Blöcken an
Funktionen realisiert werden können.  Unter Anderem aufgrund des
erfolgreichen Webframeworks \textit{Ruby on Rails} ist Ruby inzwischen
auch außerhalb seines Herkunftslandes Japan recht beliebt.

\lsubsection[basic:ruby:runtime]{Laufzeiteigenschaften} 

Im Gegensatz zu den meisten kompilierten Sprachen\footnote{In einer
  interpretierten Sprache ist das Bereitstellen einer
  \icode{eval}-Funktion deutlich leichter - schließlich gibt es diese im
Interpreter bereits, so dass im Wesentlichen nur noch die Schnittstelle
erstellt werden muss.} hat Ruby wie Lisp die
Möglichkeit, über eine \icode{eval}-Funktion Code zur Laufzeit zu
evaluieren, was viele interessante Möglichkeiten mit sich bringt:
Beispielsweise lassen sich so Anwendungen erstellen, die durch eine
mitgelieferte Skriptsprache (Ruby selbst) erweitert werden können.

Das Wegfallen der Kompilationsphase hat sowohl Vor- als auch Nachteile:
Eine Übersetzung in Maschinensprache kostet Zeit, andererseits Laufen
kompilierte Programme meist schneller und sind sparender mit
Resourcen. In \textit{Ruby on Rails} beispielsweise muss eine Programm-
oder Template-Datei nur gespeichert werden, damit beim nächsten Aufruf
der Webseite bereits die neue Version in Kraft tritt, was sehr praktisch
zum Entwickeln ist. Allerdings haben Rails-Anwendungen einen hohen
Speicherverbrauch und sind vergleichsweise langsam\footnote{Die
  vergleichsweise schlechte Performance liegt allerdings nicht nur an
  der interpretierten Sprache, sondern auch an der Komplexität des
  Frameworks. Beispielsweise sind php-Anwendungen meist schneller,
  obwohl die Sprache ebenfalls interpretiert ist}.

Ähnllich verhält es sich mit der dynamischen Typisierung: Das Wegfallen
von Variablen-Deklarationen beschleunigt den Entwicklungsvorgang -
Stichwort "`Rapid Prototyping"' - und vereinfacht Refactorings. Im
Gegenzug fällt die nützliche statische Prüfung weg, so dass viele Fehler
erst unerwartet zur Laufzeit auftreten, wenn das 


\lsubsection[basic:ruby:classes]{Klassen und Methoden}

\lsubsection[basic:ruby:blocks]{Blöcke}

\lsection[basic:haskell]{Haskell}

\begin{itemize}
\item Pur, Funktional
\item Infix-Operatoren in Klammern
\item Unit-Typ, Maybe-Typ
\item Typinferenz
\item Currying
\item Datentypen, newtype (Abstraktion f. Typklassen), type (Typvariablen)
\item Klassen (Vorbedingungen, Multi, Variablen als Konstruktoren, Abhängigkeiten)
\end{itemize}

\lsection[basic:cats]{Kategorientheorie}

Die Kategorientheorie ist ein sehr abstrakter Zweig der Mathematik -
aber auch ein universeller, denn fast alle wichtigen mathematischen
Strukturen sind Kategorien. Kategorientheorie findet dank seiner
Allgemeinheit und Anwendbarkeit für Berechnungen auch in der Informatik
eine immer größer werdende Rolle. Die Implementation von MagicL benutzt
einige kategorientheorietische Begriffe, z.B. werden Parser als
zusammengesetzte Funktoren konstruiert. Dieser Abschnitt führt in die
Kategorientheorie ein und stellt alle später verwendeten Konzepte
vor. Die Definitionen sind weitgehend aus \cite{Grundlagen} übernommen.

\lsubsection[basic:cats:intro]{Einführung}

\fig{cat_funs}{Ein simples Funktionensystem}

\todo{abs=round}

Der Grundansatz der Kategorientheorie ist die Verallgemeinerung der
Art und Weise, wie mit Funktionstypen gerechnet wird - insbesondere
hinsichtlich der Komposition von Funktionen. \abb{cat_funs} zeigt ein
kleines Funktionensystem zwischen den Mengen $\mathbb{R} \times
\mathbb{R}$, $\mathbb{R}$ und $\mathbb{Z}$. Es kommen folgende
Funktionen vor:
\begin{itemize}
\item $+ : \mathbb{R} \times \mathbb{R} \ato \mathbb{R}$ addiert zwei
  reelle Zahlen.
\item $\mathrm{abs} : \mathbb{R} \ato \mathbb{Z}$ ist die Betragsfunktion.
\item $+1 : \mathbb{Z} \ato \mathbb{Z}$ addiert $1$ zu einer ganzen Zahl.
\item $\mathrm{abs} \circ + : \mathbb{R} \times \mathbb{R} \ato \mathbb{Z}$
  addiert zwei reelle Zahlen und bildet anschließend den Betrag.
\end{itemize}

Die Komposition $\mathrm{abs} \circ +$ (gesprochen "`abs \textit{nach} +"') lässt
sich bilden, weil der Definitionsbereich von $\mathrm{abs}$ mit dem
Zielbereich von $+$ übereinstimmt (nämlich $\mathbb{R}$). Es lassen sich
also zwei im Diagramm aufeinander folgende Pfeile zu einem direkten
zusammenfassen. Die Kategorientheorie "`vergisst"' nun den Bezug zu
Mengen und Funktionen und arbeitet statt dessen abstrakt mit Objekten
und Morphismen.

\lsubsection[basic:cats:cat]{Kategorien}

\defi{Kategorie}{
Eine Kategorie $\mathbf{C} = (\mathrm{Ob}^\mathbf{C}, \mathrm{Mor}^\mathbf{C},
\circ^\mathbf{C}, \mathrm{id}^\mathbf{C})$ ist gegeben durch
\begin{itemize}
\item eine Klasse $\mathrm{Ob}^\mathbf{C}$ von Objekten\footnote{Da Objekte selbst Mengen
    sein können, wäre eine Definition von $\mathrm{Ob}^\mathbf{C}$ als Menge problematisch.}.
\item eine Menge Morphismen $\mathrm{Mor}^\mathbf{C}_{A,B}$ für alle $ A,B \in
  \mathrm{Ob}^\mathbf{C}$, wobei $A$ und $B$ Domäne und Codomäne genannt werden,
\item einen Kompositionsoperator $\circ^\mathbf{C}_{A,B,C}$ für alle $
  A,B,C \in \mathrm{Ob}^\mathbf{C}$ mit \\
  $\circ^\mathbf{C}_{A,B,C} : \mathrm{Mor}^\mathbf{C}_{B,C} \times
  \mathrm{Mor}^\mathbf{C}_{A,B} \rightarrow \mathrm{Mor}^\mathbf{C}_{A,C}$,
\item eine Identität $\mathrm{id}^\mathbf{C}_A \in \mathrm{Mor}^\mathbf{C}_{A,A}$ für alle $ A \in \mathrm{Ob}^\mathbf{C}$,
\end{itemize}
wobei folgende Axiome erfüllt sein müssen:
\begin{itemize}
\item Neutralität der Identität: $$f \circ_{A,A,B} \mathrm{id}_A = \mathrm{id}_B \circ_{A,B,B} f = f$$
\item Assoziativität:
  $$f \circ_{A,C,D} (g \circ_{A,B,C} h) = (f \circ_{B,C,D} g) \circ_{A,B,D}h$$
\end{itemize}
}

\fig{cat_comp}{Das Assoziativitätsaxiom als kommutatives Diagramm}

Indizes und Kategorien werden der Einfachheit halber weggelassen, wenn
sie aus dem Kontext hervorgehen. Wie von Funktionen gewohnt, lässt sich
$f \in \mathrm{Mor}_{A,B}$ auch schreiben als $f : A \ato B$.

Viele Definitionen der Kategorientheorie erfolgen über kommutative
Diagramme: \defi{Kommutatives Diagramm}{ Ein Diagramm kommutiert, wenn
  für je zwei eingezeichnete Pfade $f=f_1 \circ \cdots \circ f_n : A
  \rightarrow B$ und $g=g_1 \circ \cdots \circ g_n : A \rightarrow B$
  zwischen zwei Objekten $A$ und $B$ die Gleichung $f=g$ gilt.  }
Beispielsweise zeigt \abb{cat_comp} das Assoziativitätsaxiom als
kommutatives Diagramm. $g$ ist nur der Vollständigkeit halber
eingezeichnet und spielt für das kommutative Diagramm selbst keine
Rolle. Dieses Diagramm dient lediglich der Veranschaulichung, ist aber
nicht selbst für die Definition der Assoziativität geeignet -
schließlich setzt \dref{Kommutatives Diagramm} bereits Assoziativität
von $\circ$ voraus.

Wie das Einführungsbeispiel erwarten lässt, bilden die Mengen und
Funktionen eine Kategorie, genannt $\mathbf{Set}$. \abb{cat_simple} zeigt eine
andere simple Beispielkategorie, die aus den Objekten $A, B$ und den
Morphismen $f, g, \mathrm{id}_A, \mathrm{id}_B$ besteht. Alle Kompositionen
dieser Morphismen sind wieder in $\mathrm{Mor}^{\mathbf{Set}}$ - denn
jede Kategorie ist selbstverständlich unter Komposition geschlossen.

\fig{cat_simple}{Eine einfache Kategorie}

\lsubsection[basic:cats:func]{Funktoren}

Strukturerhaltende Abbildungen zwischen Kategorien werden Funktoren genannt:

\defi{Funktor}{
Ein Funktor $F=(F_{\mathrm{Ob}},F_{\mathrm{Mor}}) : \mathbf{C}
\rightarrow \mathbf{D}$ von Kategorie $C$ nach Kategorie $D$
    \begin{itemize}
    \item bildet jedes Objekt $A \in \mathrm{Ob}^{\mathbf{C}}$ auf $F_{\mathrm{Ob}}(A) \in
      \mathrm{Ob}^{\mathbf{D}}$ ab,
    \item bildet jeden Morphismus $f \in
      \mathrm{Mor}^{\mathbf{C}}_{A,B}$ auf $F_{\mathrm{Mor}}(f) \in
      \mathrm{Mor}^{\mathbf{D}}_{F_{\mathrm{Ob}}(A),F_{\mathrm{Ob}}(B)}$
      ab,
    \end{itemize}
    wobei für alle $A,B,C \in \mathrm{Ob}^{\mathbf{C}}$ und alle $f \in
    \mathrm{Mor^{\mathbf{C}}_{B,C}},g \in
    \mathrm{Mor^{\mathbf{C}}_{A,B}}$ folgende Axiome erfüllt sein
    müssen:
    \begin{itemize}
    \item Erhaltung der Komposition:
      $$F_{\mathrm{Mor}}(f \circ^{\mathbf{C}} g) =
      F_{\mathrm{Mor}}(f) \circ^{\mathbf{D}} F_{\mathrm{Mor}}(g)$$
    \item Erhaltung der Identität:
      $$F_{\mathrm{Mor}}(\mathrm{id}^{\mathbf{C}}_A) =
      \mathrm{id}^{\mathbf{D}}_{F_{\mathrm{Ob}}(A)}$$
    \end{itemize}
}

Kategorien als Objekte und Funktoren als Morphismen ergeben selbst
wieder eine Kategorie.

\lsubsection[basic:cats:prod]{Produkte und Coprodukte}

Die Kategorientheorie schafft es, Begriffe für Funktionseigenschaften
wie Injektivität sowie Mengenoperationen wie das kartesische Produkt auf
Kategorien zu verallgemeinern, indem sich die neuen Definitionen
ausschließlich auf Objekte und Morphismen beziehen und nicht von Mengen
oder Funktionen im speziellen Gebrauch machen. In der Kategorie
$\mathbf{Set}$ stimmen die neuen Begriffe dann genau mit den alten
überein. Dem kartesischen Produkt entspricht das Produkt von Objekten:

\defi{Produkt}{ Ein Objekt $A \times B$ mit zwei Projektionsmorphismen
  $\pi_1 : A \times B \ato A$ und $\pi_2 : A \times B \ato B$ ist ein
  Produkt von $A$ und $B$, wenn für jedes $X \in \mathrm{Ob}$ sowie für
  alle $f : X \ato A$ und alle $g : X \ato B$ genau ein Morphismus
  $\langle f,g \rangle : X \ato A \times B$ existiert, für den
  \abb{cat_product} kommutiert, d.h.  $\pi_1 \circ \langle f,g \rangle =
  f$ und $\pi_2 \circ \langle f,g \rangle = g$ gelten.  }

\begin{figure}
  \centering
  \subfloat[Produkt]{
    \includegraphics[scale=0.3]{images/cat_product}
    \label{magicl:fig:cat_product}
  }
  \subfloat[Coprodukt]{
    \includegraphics[scale=0.3]{images/cat_coproduct}
    \label{magicl:fig:cat_coproduct}
  }
  \caption{Kommutative Diagramme zur Definition von Produkt und Coprodukt}
\end{figure}

Man kann leicht nachvollziehen, dass das kartesische Produkt genau ein
Produkt für die Kategorie $\mathbf{Set}$ ist. $\langle f,g \rangle$ ist
hier die Funktion, die $x$ auf das Tupel $(f(x), g(x))$ abbildet.

Dreht man im Diagramm alle Pfeile um, erhält man die Definition für das
Coprodukt, ein zum Produkt dualer\footnote{Die zu einer Kategorie
  $\mathbf{C}$ duale Kategorie $\mathbf{C}^{\mathrm{op}}$ entsteht
  nämlich durch das Umdrehen von Pfeilen.} Operator:

\defi{Coprodukt}{ Ein Objekt $A + B$ mit zwei Injektionsmorphismen
  $\iota_1 : A \ato A + B$ und $\iota_2 : B \ato A + B$ ist ein
  Coprodukt von $A$ und $B$, wenn für jedes $X \in \mathrm{Ob}$ sowie
  alle $f : A \ato X$ und alle $g : B \ato X$ genau ein Morphismus
  $[f,g] : A + B \ato X$ existiert, für den \abb{cat_coproduct}
  kommutiert, d.h.  $[f,g] \circ \iota_1 = f$ und $[f,g] \circ \iota_2 =
  g$ gelten.  }

Das Coprodukt entspricht einer disjunkten Vereinigung von Mengen, also
einer Vereinigung von Mengen. die vorher explizit disjunkt gemacht
werden (sofern sie es nicht bereits sind). Dies kann beispielsweise durch
die Indizes $L$ und $R$ geschehen: $\{1,2,3\} + \{2,3,4\} =
\{1_L,2_L,3_L,2_R,3_R,4_R\}$. Der Morphismus $[f,g]$ entspricht einer
Fallunterscheidung: Auf Elemente aus $A$ wird $f$ angewendet, auf welche
aus $B$ entsprechend $g$.

\lchapter[sexy]{Objektorientierte Ruby-Implementation}

\sexy{} ist das erste im Rahmen dieser Arbeit entworfene \sexp{}-Compiler-Framework, welches in Ruby implementiert ist.

\sref{sexy:arch} erläutert die objektorientierte
Systemarchitektur und die Funktionsweise der Komponenten, woraufhin
\sref{sexy:macros} eine Implementation eines Lisp nachempfundenen
Makro-Konstruktes demonstriert. Als Beispiele für \sref{sexy:examples}
dienen die Definitionen der Sprachen, in denen das System selbst
geschrieben ist. \sref{sexy:limits} erörtert die Schwächen dieses
Ansatzes und liefert die Motivation für eine neue Version.


\lsection[sexy:reqs]{Anforderungen}

\lsection[sexy:arch]{Architektur}

metazirkulär

\lsection[sexy:macros]{Makros}

\lsection[sexy:examples]{Beispiele}

\lsection[sexy:disc]{Diskussion}

\lchapter[magicl]{Arrow-basierte Implementation in Haskell}

MagicL ist ein zweites Framework für \sexp-Compiler, welches anders
als \sexy{} intern mit getypten Modellen arbeitet. Zudem basiert diese
Neuimplementation auf einer Haskell-Umsetzung kategorientheoretischer
Konzepte (in \sref{magicl:haskats} beschrieben), mit deren Hilfe
beispielsweise in \sref{magicl:parser} sehr allgemeine und elegante
\sexp{}-Parser konstruiert werden. In \sref{magicl:sexp} geht es um
das Parsen von \sexps{} und die hierfür bereitgestellten
Hilfsfunktionen. \sref{magicl:arch} erklärt die Rahmenarchitektur mit
Modellen und Compilern, wobei Parser als spezielle Compiler aufgefasst
werden. \sref{magicl:examples} zeigt Beispiele für verschiedene
Modelle, Parser und Compiler, die Teil von MagicL sind.

\lsection[magicl:reqs]{Anforderungen}

\todo{Sexp-Typ diskutieren}

\lsection[magicl:haskats]{Kategorien in Haskell}

Die Haskell-Bibliotheken bieten viele kategorientheotische Begriffe an,
die allerdings immer bestimmten Einschränkungen
unterliegen. Beispielsweise sind die Objekte einer Kategorie hier immer
Haskell-Typen. Die Typklasse \icode{Category} ist wie folgt definiert:
\begin{code}
class Category cat where
  id   :: cat a a
  (.) :: cat b c -> cat a b -> cat a c
\end{code}
Ein Typ \icode{cat}, der selbst zwei Typparameter benötigt, ist also eine
Instanz von \icode{Category}, wenn es generische Identitäts- und
Kompositionsoperatoren gibt, die für beliebige Typen $a,b,c$ benutzt
werden können. Genau genommen bestimmt \icode{Category} also keine
Kategorien, sondern vielmehr die Morphismen bestimmter Kategorien. Auch
die Axiome werden hier nicht gefordert - vielmehr liegt es am
Programmierer, dies für eine "`vernünftige"' Programmsemamtik selbst zu
verifizieren. Man sieht hier schon, dass die Haskell-Begriffe nur sehr
vage mit den mathematischen übereinstimmen - dies wird auch bei den
weiteren Definitionen so bleiben. Die einfachste Instanz von
\icode{Category} ist \icode{(->)}, also die Kategorie der
Haskell-Funktionen, bezeichnet als $\mathbf{Hask}$.
Oft wird statt \icode{.} der \icode{>>>}-Operator (genannt "`vor"') %<<
benutzt mit \icode{f >>> g = g . f}. %<<

\todo{IO-Kategorie als Kleisli IO}

\lsubsection[magicl:haskats:arrows]{Arrows}

Die Typklasse \icode{Arrow} beschreibt (die Morphismen von) Kategorien,
für die ein Funktor aus der Kategorie $\mathbf{Hask}$ existiert, wo man
also jeder Haskell-Funktion vom Typ \icode{a -> b} einen Morphismus vom
Typ \icode{cat a b} zuordnen kann. Dies ist deshalb sinnvoll, da viele
(Haskell-)Kategorien "`mehr"' können als die Funktionen, formal eine zu
$\mathbf{Hask}$ isomorphe Unterkategorie besitzen. Beispielsweise
benutzt MagicL "`Funktionen, die fehlschlagen können"' oder "`Funktionen
mit Nebeneffekten"' als Kategorien, die jeweils auch normale Funktionen
enthalten. Zusätzlich wird eine Operation auf Tupeln gefordert, aus der
sich ein Produkt zusammensetzen lässt - ein Coprodukt wird zunächst nicht gefordert:
\begin{code}
class (Category ar) => Arrow ar where
  arr   :: (a -> b) -> ar a b
  first :: ar a b  -> ar (a, c) (b, c)
\end{code}
\icode{arr} ist der Funktor, der jede Funktion auf einen Arrow
abbildet\footnote{Die Typen werden auf sich selbst abgebildet}.
\icode{first} ist eine Funktion, die aus einem Arrow einen Arrow auf
Tupeln macht, der nur auf dem ersten Element arbeitet, das zweite
dagegen unverändert durchschleift. Somit lassen sich zusätzliche Werte
weiterreichen, außerdem lassen sich aus \icode{first} sinnvolle
Operationen ableiten:

\begin{code}
  second :: ar a b -> ar (c, a) (c, b)
  second = arr swap >>> first f >>> arr swap
    where swap (x, y) = (y, x)

  (***) :: ar a b -> ar a' b' -> ar (a, a') (b, b')
  f *** g = first f >>> second g

  (&&&) :: ar a b -> ar a b' -> ar a (b, b')
  f &&& g = arr diag >>> (f *** g)
    where diag x = (x,x)
\end{code} % <<

\begin{itemize}
\item \icode{second} ist analog zu \icode{first}, reicht allerdings das erste
Element unverändert weiter.
\item \icode{f *** g} wendet \icode{f} auf das
erste Element, danach \icode{g} auf das zweite Element eines Tupels
an.
\item \icode{f &&& g} ist nun die Haskell-Entsprechung von $\langle f,g
\rangle$ in \dref{Produkt}. \icode{f} und \icode{g} werden also beide
auf die Eingabe angewendet und deren Ergebnisse zu einem Tupel
zusammengesetzt.
\end{itemize}

Möchte man einen Arrow mit einer Funktion verknüpfen, gibt es mit
\begin{code}
f >>^ func = f >>> arr func
\end{code}% <<
noch etwas syntaktischen Zucker.

\lsubsection[magic:haskats:coproducts]{Coprodukte: Die Klasse \texttt{ArrowChoice}}

Die Haskell-Entsprechung zu einer disjunkten Vereinigung ist der
\icode{Either}-Datentyp, der folgendermaßen definiert ist:
\begin{code}
data Either a b = Left a | Right b
\end{code}
Coprodukte für Arrows werden durch die Klasse \icode{ArrowChoice} beschrieben:
\begin{code}
class Arrow ar => ArrowChoice ar where
  left :: ar a b -> ar (Either a c) (Either b c)
\end{code}
Auch hier wird mit \icode{left} nur eine einfache Operation gefordert,
aus der sich anschließend alles weitere konstruieren lässt. Diese
Funktion wandelt einen Arrow von \icode{a} nach \icode{b} um in
einen Arrow von \icode{Either a c} nach \icode{Either b c}. Bei einem
\icode{Left}-Wert wird also der ursprüngliche Arrow angewendet, ein
\icode{Right}-Wert wird dagegen unverändert weitergereicht.
\begin{code}
  right :: ar a b -> ar (Either c a) (Either c b)
  right f = arr swap >>> left f >>> arr swap
    where swap (Left x)  = Right x
          swap (Right x) = Left x

  (+++) :: ar a b -> ar a' b' -> ar (Either a a') (Either b b')
  f +++ g = left f >>> right g

  (|||) :: ar a c -> ar b c -> ar (Either a b) c
  f ||| g = (f +++ g) >>> arr dropEither
    where dropEither (Left x)  = x
          dropEither (Right x) = x

\end{code} %<<
Die Definitionen sind weitgehend analog zu den entsprechenden
Produkt-Operationen:
\begin{itemize}
\item \icode{right} bearbeitet nur \icode{Right}-Werte, während
  \icode{Left}-Werte unverändert bleiben.
\item \icode{f +++ g} wendet auf \icode{Left}-Werte \icode{f} an, auf
  die anderen \icode{g}.
\item Haben \icode{f} und \icode{g} den selben Rückgabetyp, kann
  \icode{f ||| g} verwendet werden, welches das in diesem Fall unnötige
  \icode{Either} verschwinden lässt. Dies entspricht $[f,g]$ in
  \dref{Coprodukt}
\end{itemize}

\lsubsection[magicl:haskats:functors]{Funktoren}

Die Haskell-Bibliotheken definieren eine Klasse \icode{Functor}, welche
allerdings nur Endofunktoren - das sind Funktoren von einer Kategorie in
sich selbst - über der Kategorie $\mathbf{Hask}$ repräsentieren:
\begin{code}
class Functor f where
  fmap :: (a -> b) -> f a -> f b
\end{code}
Ein Datenkonstruktor \icode{f} ist also Instanz von \icode{Functor},
wenn die Operation \icode{fmap} Funktionen von \icode{a} nach \icode{b}
auf Funktionen von \icode{f a} nach \icode{f b} abbildet. Der
mathematische Funktor besteht hier also aus \icode{(f,fmap)}.

Diese Arbeit benutzt statt dessen eine eigene \icode{Functor}-Klasse,
die Verschiedene Kategorien zulässt:
\begin{code}
class Functor f ar | f -> ar where
  lift :: ar a b -> f a b
\end{code}
Die Arrows\footnote{Es ist in Haskell üblich, Vorbedingungen wie hier
  \icode{(Arrow ar, Arrow f)} nur dort zu verwenden, wo tatsächlich
  Gebrauch von den speziellen Klasseneigenschaften gemacht wird -
  deshalb wird beides noch nicht in dieser Klassendefinition gefordert.}
\icode{f} und \icode{ar} bilden eine Instanz von \icode{Functor}, wenn
eine \icode{lift}-Operation \icode{ar}-Arrows auf \icode{f}-Arrows
zwischen den gleichen Typen abbildet - wobei der Typ \icode{f} den Typ
\icode{ar} determiniert. Der mathematische Funktor hier ist also
\icode{(id,lift)}. Im Vergleicht zu Haskell's Standard-\icode{Functor}
ist diese Version also in den Kategorien allgemeiner, aber dafür
spezieller in der Abbildung der Objekte, da hier die Identität
vorgeschrieben ist. Man könnte auch dies allgemein formulieren - aber im
Rahmen von MagicL reicht die spezielle Version bisher aus.

Alle hier verwendeten \icode{Functor}-Instanzen konstruieren aus einem
\icode{Arrow}-Typ einen zweiten mit zusätzlichen Eigenschaften,
z.B. erweitert der \icode{FailFunctor} einen Arrow-Typ um mögliches
Scheitern. Die Instanz-Deklaration dafür sieht im Gerüst folgendermaßen
aus (die Details werden in \sref{magicl:parser:fail} erläutert):
\begin{code}
newtype FailFunctor ar a b = ...

instance (Arrow ar) => Functor (FailFunctor ar) ar where
  lift f = ...
\end{code}

\lsection[magicl:parser]{Parser als Arrows}

Das Herzstück von MagicL ist ein Arrow-basiertes Framework für Parser.

\todo{Einleitung, parsec-vergleich, Hughes, andere Arrow-Libs}\\
Dieser Abschnitt entwickelt schrittweise einen Arrow-basierten
Parser-Datentyp. Parser zeichnen sich hauptsächlich durch zwei Eigenschaften aus:
\begin{itemize}
\item Sie können fehlschlagen sowie Alternativmöglichkeiten im Falle des
  Scheiterns besitzen.
\item Sie bearbeiten einen Zustand, der die Position im Eingabestream
  beschreibt.
\end{itemize}
Diese beiden Eigenschaften lassen gut sich einzeln mittels Funktoren auf
bestehenden Kategorien ausdrücken.

\lsubsection[magicl:parser:fail]{Fehlschlagende Arrows}

Berechnungen von $A$ nach $B$, die fehlschlagen können, sollen zwei
mögliche Resultate haben. Im Erfolgsfall wird ein normaler Rückgabewert
aus $B$ geliefert, während im Falle eines Scheiterns eine Fehlermeldung
als String zurückgegeben wird. Der Rückgabetyp ist deshalb das Coprodukt
$\mathrm{String}+B$. Statt Morphismen von $A$ nach $B$ wollen wir also
nun Morphismen von $A$ nach $\mathrm{String}+B$. Um den aufrufenden Code
nicht komplizierter zu machen, empfiehlt es sich, diese Änderung in
einer neuen Kategorie $\mathbf{C}_f$ zu verstecken. $f_{f} : A
\rightarrow B$ aus der neuen Kategorie wird abgebildet auf $f : A
\rightarrow \mathrm{String} + B$ Der Arrow $\mathrm{fail}_{f} : \mathrm{String}
\rightarrow a$ in $C_{f}$ schlägt immer fehl und entspricht $fail :
\mathrm{String} \rightarrow \mathrm{String} + a$ in $C$.

Der Operator $\bigvee : Mor_{A,B} \times Mor_{A,B}
\rightarrow Mor_{A,B} $ bietet Alternativen. Um Morphismen aus
$\mathbf{C}$ in $\mathbf{C}_f$ benutzen zu können, gibt es den Funktor
$\mathrm{lift}_f:\mathbf{C} \ato \mathbf{C}_f$, welcher die
unveränderte, d.h. gelingende Operation für die neue Kategorie
übernimmt.

Die Haskell-Entsprechung von $\mathrm{String}+B$ ist \icode{Either
  String b}, was sich mit \icode{Failable b} abkürzen lässt, wenn man
den parametrisierten Typ \icode{Failable} einführt:

\begin{code}
type Failable a = Either String a
\end{code}

Der Fehlerfall wird durch \icode{Left String} ausgedrückt, ein Erfolg
durch \icode{Right a}. Fehlschlagende Arrows nun sind in MagicL durch den
Typ \icode{FailFunctor} implementiert:

\begin{code}
newtype FailFunctor ar a b = FailF (ar a (Failable b))

instance (Arrow ar) => Functor (FailFunctor ar) ar where
    lift f = FailF (f >>> arr Right)
\end{code} % <<

Arrows von \icode{a} nach \icode{b}, die fehlschlagen können, sind also
Arrows von \icode{a} nach \icode{Failable b}, die in den zusätzlichen
Konstruktor \icode{FailF} eingebettet wurden. Um einen normalen Arrow
\icode{f} aus \icode{ar} nach \icode{FailFunctor ar} zu "`liften"', wird
der Rückgabewert in ein \icode{Right} gebettet und der resultierende
Arrow in \icode{FailF}.
Der Arrow \icode{fail} wird in eine \icode{Arrow} erweiternde Typklasse
ausgegliedert, so dass dieser auch in anderen Kategorien bereitgestellt
werden könnte:

\begin{code}
class (Arrow ar) => ArrowFail ar where
  fail :: ar String a

instance (ArrowChoice ar) => ArrowFail (FailFunctor ar) where
  fail = FailF (arr Left)
\end{code}

Der Oder-Operator $\bigvee$ entspricht in Haskell \icode{<+>}, welchen
die bereits in den Haskell-Bibliotheken definierte Typklasse
\icode{ArrowPlus} bereitstellt:

\begin{code}
instance (ArrowChoice ar) => ArrowPlus (FailFunctor ar) where
  FailF f <+> FailF g = FailF ((f &&& g) >>> arr tupleOr)
    where tupleOr (Left  _, y)  = y
          tupleOr (Right x), _) = Right x
\end{code} % <<

Es werden also \icode{f} und \icode{g} parallel evaluiert und
anschließend von der Funktion \icode{tupleOr} verarbeitet, die, sollte
\icode{f} fehlschlagen, das Ergebnis von \icode{g} zurückgibt, ansonsten
das Ergebnis von \icode{f}.

\fig{cat_fail}{Komposition beim Fail-Funktor}

Die Typabhängigkeiten von \icode{ArrowChoice} ist nötig, weil
\icode{FailFunctor ar} nur dann ein \icode{Arrow} ist, wenn \icode{ar}
ein Coprodukt anbietet. Denn die Komposition in $C_{f}$ ist definiert
durch $g_{f} \circ f_{f} = ([fail,g] \circ f)_{f}$, was in Haskell
\begin{code}
FailF g . FailF f = FailF (f >>> (arr Left ||| g))
\end{code} %<<
entspricht. Tritt in \icode{f} ein Fehler auf, wird dieser also wieder
in ein \icode{Left} eingepackt und zurückgegeben. Ansonsten wird das
durch \icode{|||} implizit aus dem \icode{Right}-Konstruktor ausgepackte
Ergebnis an \icode{g} weitergereicht.

\abb{cat_fail} zeigt die Komposition in $\mathbf{C}_f$ und deren
zurückführung auf ein Coprodukt in $\mathbf{C}$. Die Funktion, die $f_f$
auf $f$ abbildet, kann nicht Teil eines Funktors sein. Ein solcher
müsste nämlich das Objekt $B$ sowohl auf $\mathrm{String}+B$ (bei der
Transformation von $f$ als auch auf $B$ selbst (bei $g$) abbilden.

\todo{(Co)Produkt?}

\lsubsection[magicl:parser:state]{Arrows mit Zuständen}

Zustände lassen sich ähnlich zu einem Arrow hinzufügen. Über Produkte
wird der Zustandstyp $S$ (z.B. eine Stream-Position oder der
\textit{Seed} eines Zufallszahlengenerators) an Domäne und Codomäne
herangehängt, was wieder in einer neuen Kategorie $C_{s}$ versteckt
wird. Ein Morphismus $f_{s} : A \rightarrow B$ der neuen Kategorie wird
entsprechend abgebildet auf $f = A \times S \rightarrow B \times S$. Da
hier im Gegensatz zum Fail-Funktor Domäne und Codomäne gleich abgebildet
werden, ist diese Abbildung Teil eines Funktors $F_s: C_{s}
\ato C$. \abb{cat_state} zeigt d

\fig{cat_state}{Komposition in $\mathbf{C}_s$ und Rückführung auf
  $\mathbf{C}$ durch $F_s$}

In MagicL gibt es die Typklasse \icode{StateFunctor}, die einen weiteren
Typparameter \icode{s} für den Zustand bekommt:

\begin{code}
newtype StateFunctor s ar a b = StateF (ar (a, s) (b, s))

instance (Arrow ar) => Functor (StateFunctor s ar) ar where
    lift = StateF . first  
\end{code} % <<

Die "`geliftete"' Version eines Arrows soll den Zustandsparameter
unverändert weitergeben - dies entspricht genau der
\icode{first}-Funktion aus \sref{magicl:haskats:arrows}.

Das Lesen und Schreiben von Zuständen wird von den Funktionen \icode{get} und
\icode{put} bereitgestellt, welche in der Typklasse \icode{ArrowState}
definiert werden:

\begin{code}
class (Arrow ar) => ArrowState s ar | ar -> s where
  get :: ar a s
  put :: ar s ()
  
instance (Arrow ar) => ArrowState s (StateFunctor s ar)
  where
    get = StateF (arr (\ (_, state) -> (state, state)))
    put = StateF (arr (\ (state, _) -> ((), state)))
\end{code}

\icode{get} ignoriert also den Eingabewert und gibt den aktuellen
Zustand zurück, während \icode{put} den übergebenen Zustand
"`abspeichert"' und (bis auf diesen) nichts zurückgibt.

\todo{Prod/Coprod?}

\lsubsection[magicl:parser:parse]{Der Parse-Funktor}

Nun lassen sich obige Kategorie-Erweiterungen zu einer Parser-Kategorie
$\mathbf{C}_p = \mathbf{C}_{fs}$ zusammensetzen, d.h. die ursprüngliche
Kategorie wird zunächst um Fehler zu $\mathbf{C}_f$, danach um Zustände
zu $\mathbf{C}_p$ erweitert. Die Reihenfolge hier ist wichtig, damit ein
Morphismus $A \ato B$ aus $\mathbf{C}_p$ auf $A \times S \ato
\mathrm{String} + B \times S$ in $\mathbf{C}$ abgebildet wird und nicht
auf $A \times S \ato (\mathrm{String} + B) \times S$, wie es andersherum
wäre. Denn das Coprodukt muss "`außen"' stehen, um im Kontrollfluß
zuerst bearbeitet zu werden und somit ein Backtracking im Fehlerfall zu
ermöglichen. 

Backtracking wird allerdings zu einem Problem, wenn man sinnvolle
Fehlermeldungen produzieren will. Man stelle sich einen Parser für die
(in einer fiktiven Sprache beschriebene) Grammatik \texttt{\{.*\}
  $\bigvee$ [.*]} vor, die eine beliebige Zeichenkette in geschweiften
oder eckigen Klammern beschreibt. Beim Eingabewort \texttt{\{ABC}
scheitert zunächst aufgrund der fehlenden schließenden Klammer die erste
Alternative, woraufhin die zweite probiert wird. Das Wort beginnt aber
nicht mit \texttt{[}, so dass der Parser beispielsweise mit der Meldung
\texttt{"'Expected [, got \{"'} scheitert. Diese Meldung beschreibt den
Fehler schlecht - statt dessen möchte man nach dem Lesen von \texttt{\{}
das Backtracking deaktivieren, denn bereits hier ist klar, dass die
andere Alternative nicht mehr in Betracht kommt. Dies führt zu einer
sinnvolleren Fehlermeldung wie \texttt{"'Expected \}, got end of
  stream"'}.

Ein derartiger "`nicht-auffangbarer"' Fehler lässt sich durch das
Einbauen einer weiteren Möglichkeit des Scheiterns ermöglichen, wir
definieren also $\mathbf{C}_p = \mathbf{C}_{ffs}$ und bieten eine
Funktion \icode{forceParser} an, die einen (Sub-)Parser derart
modifiziert, dass, falls dieser Scheitert, der Fehler in die "`inneren"'
und damit nicht-recover-fähigen Fail-Kategorie übernommen wird. Hiervon
wird beispielsweise bei der Funktion \icode{macro}
\sees{magicl:sexp} Gebrauch gemacht.

Die Haskell-Definition vom \icode{FailFunctor} benutzt als Zustandstyp
einen Stream (als Liste repräsentiert) vom Token-Typ \icode{t}:

\begin{code}
newtype ParseFunctor t ar a b = 
  P (StateFunctor 
     [t] 
     (FailFunctor (FailFunctor ar))
     a
     b)
\end{code}

Dank der Implementation als Funktor ist die Kategorie, in der der Parser
ausgeführt wird, frei wählbar. So können rein funktionale Parser in
$Hask_p$ konstruiert werden. Benötigt man aber Debug Outputs (z.B. bei
der Suche einer Endlosschleife) oder andere Seiteneffekte, kann
$\mathbf{IO}_p$ benutzt werden. Eine geeignete innere Kategorie könnte
sogar interaktive Debugger, Netzwerktransparenz oder sonstige Features
anbieten. Auch der variable Token-Typ erzeugt viele Möglichkeiten:
Textdateien können mit \icode{Char}, Bitstreams mit \icode{Bool} oder
\sexp{}-Streams mit \icode{Sexp} verarbeitet werden.

\lsubsection[magicl:parser:lib]{Parser-Library}

MagicL beinhaltet eine Parser-Bibliothek, in der u.a. viele simple
Parser-Konstruktoren definiert sind. Hier ein paar
Beipiele\footnote{Abhängigkeiten der Typparameter werden hier der
  Übersichtlichkeit halber weggelassen.}:
\begin{itemize}
\item \icode{empty :: ParseFunctor t ar a a}\\
  gibt seinen Eingabewert unverändert zurueck, wenn der Stream leer ist.
\item \icode{takeWhen :: (t -> Bool) -> (t -> String) -> ParseFunctor t ar a
    t}\\
  testet den ersten Token mit einem Prädikat. Im Erfolgsfall (\icode{True}) wird der
  Token zurückgegeben, ansonsten wird der Token an eine Funktion
  übergeben, die daraus eine Fehlermeldung aufbaut.
\item \icode{member :: [t] -> ParseFunctor t ar a t}\\
  testet, ob der erste Token in der übergebenen Liste vorkommt.
\item \icode{streamEq ::  [t] -> ParseFunctor t ar a [t]}\\
  prüft, ob die ersten $n$ Token mit den Elementen der übergebenen Liste
  übereinstimmen, und gibt diese im Erfolgsfall zurück. Für \icode{t =
    Char} wird hier also ein String gelesen.
\end{itemize}

Alle diese Funktionen (und deren Negationen) geben Parser mit nützlichen
Fehlermeldungen zurück.

Weiterhin gibt es viele Arrow-Kombinatoren, mit denen Parser,
vergleichbar mit den Operationen der Erweiterten Backus-Naur-Form (EBNF) \cite{TODO}, verschaltet werden können. Mit den bisher eingeführten
Operatoren sind bereits Konkatenation (\icode{>>>}) %<<
und Alternative (\icode{<+>}) abgedeckt, darüber hinaus gibt es für
Instanzen von \icode{ArrowPlus} unter anderem folgende Funktionen:

\begin{code}
optional :: ar a b -> ar a (Maybe b)
optional f = (f >>^ Just) <+> constArrow Nothing
  where constArrow x = arr (\ _ -> x) 

many :: ar a b -> ar a [b]
many f = many1 f <+> constArrow []

many1 :: (ArrowPlus ar) => ar a b -> ar a [b]
many1 f = consArrow f (many f)
  where consArrow :: ar a b -> ar a [b] -> ar a [b]
        consArrow f g = (f &&& g) >>^ (\ (x,xs) -> x : xs)

skip :: ar a b -> ar a a
skip f = (f &&& id) >>^ snd

sepBy :: ar a c -> ar a b -> ar a [b]
sepBy sep item = 
  optional (consArrow item (many (skip sep >>> item))) >>^ unMaybeList
    where
      unMaybeList  Nothing  = []
      unMaybeList (Just xs) = xs
\end{code} % <<

\icode{optional} erzeugt einen Arrow, der, sollte der übergebene Arrow
scheitern, \icode{Nothing} zurückgibt - dabei aber "`erfolgreich"'
bleibt. Dies entspricht \icode{[ ]} in EBNF. Hierbei erzeugt
\icode{constArrow Nothing} einen Arrow, der die Eingabe ignoriert und
konstant \icode{Nothing} zurückgibt. Eine (optionale) Wiederholung (in EBNF
\icode{\{ \}}) erzeugt \icode{many}, \icode{many1} verlangt mindestens
ein Vorkommen. Die Hilfsfunktion \icode{consArrow} nimmt zwei
Arrows an und erzeugt daraus einen, der das Element, welches der erste
zurückgibt, vor die Liste hängt, die der zweite zurückliefert.
\icode{skip} ignoriert das Resultat eines Arrows und gibt
statt dessen seine Eingabe zurück - Zustandsänderungen kann der
ignorierte Arrow aber dennoch bewirken. \icode{sepBy} ist ein
komplizierteres Beispiel und ermöglicht das Parsen von Listen mit
Trennzeichen. Dafür bekommt die Funktion zwei Arrows übergeben:
\icode{sep} soll ein Trennzeichen, \icode{item} ein Element lesen. Es
wird zunächst ein \icode{item}, dann beliebig viele, von (ignorierten)
\icode{sep} angeführte \icode{item}-Elemente gelesen. Das ganze ist noch
in ein \icode{optional} gebettet, damit auch eine leere Liste gelesen
werden kann. Die Rückgabe wird mittels \icode{unMaybeList} vom durch
\icode{optional} erzeugten \icode{Maybe}-Datentyp befreit, so dass statt
\icode{Nothing} eine leere Liste zurückgegeben wird, wenn nichts gelesen
werden kann.

\lsubsubsection[magicl:parser:lib:example]{Beispiel: Ein \sexp{}-Parser}

Aufgrund der einfachen gewählten Struktur von \sexps{} und der
praktischen Parser-Library ist es möglich, in vier kurzen Zeilen einen
Parser für \sexps{}\footnote{Gemeint ist ein Parser von Text nach
  \sexps{}, wogegen die \sexp{}-Parser in \sref{magicl:sexp} \sexps{}
  lesen.} zu entwerfen:

\begin{code}
whitespace = skip (many (member " \t\n"))
\end{code}
Zunächst wird Whitespace als beliebige Anhäufung von Spaces, Tabs und
Newlines definiert, die ignoriert werden soll.
\begin{code}
parseSymbol = many1 (notMember " \t\n()") >>^ Symbol
\end{code} % <<
Ein Symbol ist eine Kette von Zeichen, die weder Whitespace noch
Klammern sind. Dieses wird gleich an den \icode{Symbol}-Konstruktor
übergeben, um den Typ \icode{Sexp} zu erhalten.
\begin{code}
parseNode = skip (eq '(') >>> (many parseSexp >>^ Node) >>> skip (eq ')') 
\end{code} % <<
Ein Knoten ist eine von Klammern umgebene Liste von \sexps{}, die
mittels \icode{Node}-Konstruktor zu einem \sexp{} wird.
\begin{code}
parseSexp = whitespace >>> (parseSymbol <+> parseNode) >>> whitespace
\end{code} % <<
Ein \sexp{} ist nun entweder ein Symbol oder ein Knoten, wobei davor und
danach Whitespace auftreten darf.

Tritt bei Lesen ein Fehler auf, wird automatisch eine brauchbare Fehlermeldung
ausgegeben, z.B.

\begin{code}
"(test) )"  ==>  Empty stream expected: ")"  
\end{code}

\lsection[magicl:sexp]{Parsen von \sexps{}}

Die Parser-Bibliothek an sich ist bereits nützlich, um Textdateien
einlesen zu können. Das eigentliche Ziel aber ist die Verarbeitung von
\sexps{}. Es lassen sich zwar bereits Streams von \sexps{} verarbeiten,
es gibt aber bisher keine komfortablen Operationen, um das Innere einer
\sexp{} zu testen oder zu verarbeiten. Da ein \sexp{} selbst wieder eine
Liste und damit ein Stream ist, bietet es sich an, diesen ebenfalls über
einen "`inneren Parser"' zu verarbeiten.

Beispielsweise könnte eine Liste von Personen folgenderweise
repräsentiert sein\footnote{Dieses Format ist unnötig redundant und
  sollte vermutlich besser durch \icode{(persons Franz Walter Heinz)} ersetzt
  werden - aber es handelt sich ja nur um ein einfaches Beispiel.}:
\begin{code}
(person Franz)
(person Walter)  
(person Heinz)
\end{code}

Ein Parser, der eine Liste von Namensstrings produzieren soll, würde mit
der bisherigen Bibliothek so aussehen:

\begin{code}
parsePerson = take >>^ proc >>> (fail ||| id)
  where proc (Node (Symbol "person", Symbol x)) = Right x
        pred _ = Left ("Not a person: " ++ show x)
parsePersons = many parsePerson
\end{code} % <<

Die Verarbeitung von Hand mittels \icode{Node} und \icode{Symbol} im
Pattern-Matching ist relativ umständlich. Deswegen gibt es eine Reihe
nützlicher Hilfsfunktionen für die Konstruktion von \sexp{}-Parsern:

\begin{itemize}
\item \icode{takeSexp} liest eine \sexp{} vom Stream und wandelt diese
  für die Unterscheidung zwischen Symbolen und Knoten mittels
  \icode{|||} in das Coprodukt \icode{Either String [Sexp]} um.
\item \icode{takeSymbol} erwartet ein Symbol und gibt dieses als String
  zurück - ansonsten wird eine Fehlermeldung ausgegeben.
\item \icode{symbolMacro name = skip (eq (Symbol name))} akzeptiert nur
  das Symbol mit Namen \icode{name}.
\item \icode{takeNode} erwartet einen Knoten und gibt diesen als Liste
  von \sexps{} zurück.
\item \icode{compNode innerComp} verarbeitet einen Knoten, indem der
  übergebene Parser \icode{innerComp} auf das Knoteninnere angewendet
  wird. Da Parser in MagicL immer als Compiler definiert werden (siehe
  \sref{magicl:arch:compiler}), heißt diese Funktion nicht \icode{parseNode}
\item \icode{macro name innerComp} % <<
  konsturiert nun einen Parser, der wie ein Macro das erste Element des
  Knotens mit dem Symbol \icode{name} vergleicht und im Erfolgsfall die
  restlichen Elemente mit \icode{innerComp} verarbeitet. Danach wird
  sichergestellt, dass der Knoten auch wirklich vollständig gelesen
  wurde - will man dies nicht, da man den Rest ignoriert, gibt es die
  Funktion \icode{looseMacro} mit identischer Signatur.
\end{itemize} 
Das obige Beispiel lässt sich nun umschreiben:
\begin{code}
parsePerson  = macro "person" takeSymbol  
parsePersons = many parsePerson
\end{code}

\icode{macro} benutzt \icode{forceParser} aus
\sref{magicl:parser:parse}, um das Backtracking auszuhebeln, sobald das
Symbol übereinstimmt, was wieder für bessere Fehlermeldungen
sorgt. Allerdings bedeutet dies, dass Code wie
\begin{code}
macro "foo" (symbolMacro "bar") <+> macro "foo" (symbolMacro "baz")
\end{code}
nicht erwartungsgemäß funktioniert:
\begin{code}
(foo bar)   => ()  d.h. Erfolg, kein Ergebnis
(foo baz)   => Symbol bar expected: baz
\end{code}
Es sollte deshalb immer nur ein \icode{macro} für jeden Begriff benutzt
werden, und eine Oder-Verknüpfung ins Innere verlegt werden - hier also:
\begin{code}
macro "foo" (symbolMacro "bar" <+> symbolMacro "baz")
\end{code}

\lsection[magicl:arch]{Rahmenarchitektur}

\lsection[magicl:examples]{Beispiele}

\lsection[magicl:disc]{Diskussion}

\lchapter[end]{Schluss}

\lsection[end:summary]{Zusammenfassung}

\begin{itemize}
\item Übertragung von Makros
\item Erster Prototyp
\end{itemize}

MagicL ist der Prototyp eines
universellen Frameworks für den Entwurf von Programmier- und
Auszeichnungssprachen. Es gibt dem Meta-Programmierer praktische
Werkzeuge für das Parsing und Übersetzen neuer sowie für Generierung von
Code bestehender Sprachen an die Hand, wobei insbesondere (jedoch
nicht ausschließlich) aus \sexps{} aufgebaute Sprachen unterstützt
werden. Die Parser- und Compilererstellung erfolgt nach einem
kategorientheoretisch motivierten Baukastenansatz, so dass
unter anderem Parser durch die Kombination von Arrows erzeugt werden.

...

\begin{itemize}
\item Fazit
\end{itemize}

\lsection[end:future]{Ausblick}
\begin{itemize}
\item DSL für Modell- und Compilerdefinition
\item Verschiedene DSL's
  \begin{itemize}
  \item Text (Latex)
  \item Graphen und Petrinetze
  \item Test-Framework (Haskell)
  \item Make-Tool (Haskell)
  \item andere Programmier- und Auszeichnungssprachen
  \end{itemize}
\item \sexp{}-IDE
  \begin{itemize}
  \item Struktureller Editor
  \item Modellspezifische GUI-Plugins
  \item Netzwerktransparenz und synchrone Bearbeitung
  \end{itemize}
\item Versionierung
  \begin{itemize}
  \item Diff (evtl. über IDE-Protokoll)
  \item Merge für Teamarbeit und passive Code-Generierung
  \end{itemize}
\end{itemize}
\end{document}
