\documentclass[12pt, a4paper, bibgerm]{scrbook}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{ngerman}
\usepackage{bibgerm}
\usepackage{color}
\usepackage{amssymb,amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{rotating}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{acronym}

\newenvironment{DIFnomarkup}{}{}

\lstloadlanguages{Haskell}
\lstnewenvironment{code}
  {\lstset{}%
    \csname lst@SetFirstLabel\endcsname}
  {\csname lst@SaveFirstLabel\endcsname}
\lstset{
  basicstyle=\small\ttfamily,
  flexiblecolumns=false,
  basewidth={0.5em,0.45em}
% ,
%   literate={+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
%   {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
%   {\\\\}{{\char`\\\char`\\}}1
%   {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
%   {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2
%   {.}{{$\circ$}}2
%   {...}{{$\ldots$}}2
% % {\ .\ }{{$\circ$}}2
%   {>>>}{{$\ggg$}}2
% %  {>>}{{>>}}2 {>>=}{{>>=}}2 %<<
%   {|}{{$\mid$}}1
}

\newcommand\icode[1]{\lstinline?#1?}

\newcommand\phpo{\lstinline+<?+}
\newcommand\phpc{\lstinline+?>+}

% \newenvironment{code}{\begin{verbatim}}{\end{verbatim}}
% \newcommand\icode[1]{\verb^#1^}


\newcommand{\todo}[1]{
  \textcolor{red}{TODO: #1}
}

\newcommand{\defaultscale}{0.3}

\newcommand\lchapter{}
\newcommand\lsection{}
\newcommand\lsubsection{}
\newcommand\lsubsubsection{}
\newcommand\lparagraph{}
\newcommand\myref{}
\newcommand\cref{}
\newcommand\sref{}
\newcommand\fref{}
\newcommand\abb{}
\newcommand\fig{}
\newcommand\figs{}
\newcommand\subfig{}
\newcommand\vertfig{}
\newcommand\clipvertfig{}

\newcommand{\project}[1]{%
  \renewcommand\lchapter[2][\LChapterDefault]{%
    \def\LChapterDefault{##2}%
    \chapter{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsection[2][\LSectionDefault]{%
    \def\LSectionDefault{##2}%
    \section{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsubsection[2][\LSubSectionDefault]{%
    \def\LSubSectionDefault{##2}%
    \subsection{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lsubsubsection[2][\LSubSubSectionDefault]{%
    \def\LSubSubSectionDefault{##2}%
    \subsubsection{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\lparagraph[2][\LParagraphDefault]{%
    \def\LParagraphDefault{##2}%
    \paragraph{##2}
    \label{#1:sec:##1}%
  }
  \renewcommand\myref[1]{%
    \ref{#1:sec:##1}%
  }%
  \renewcommand\cref[1]{%
    Kapitel~\ref{#1:sec:##1}%
  }%
  \renewcommand\sref[1]{%
    Abschnitt~\ref{#1:sec:##1}%
  }%
  \renewcommand{\fref}[1]{\ref{#1:fig:##1}}
  \renewcommand{\abb}[1]{Abb.~\ref{#1:fig:##1}}
  \renewcommand{\fig}[3][\defaultscale]{%
    \begin{figure}[h]
      \centering
      \includegraphics[scale=##1]{images/##2}
      \caption{##3}
      \label{#1:fig:##2}
  \end{figure}}

  \renewcommand{\figs}[3]{%
    \begin{figure}[htp]
      \centering
      ##3
      \caption{##2}
      \label{#1:fig:##1}
    \end{figure}
  }

  \renewcommand{\subfig}[3][\defaultscale]{%
    \subfloat[##3]{
      \includegraphics[scale=##1]{images/##2}
      \label{#1:fig:##2}
    }
  }

  \renewcommand{\vertfig}[3][\defaultscale]{%
    \begin{sidewaysfigure}[htp]
      \centering
      \includegraphics[scale=##1]{images/##2}
      \caption{##3}
      \label{#1:fig:##2}
    \end{sidewaysfigure}%
  }

  \renewcommand{\clipvertfig}[5]{%
    \begin{sidewaysfigure}[htp]
      \centering
      \includegraphics*[scale=##1, viewport=##2]{images/##3}
      \caption{##5}
      \label{#1:fig:##4}
    \end{sidewaysfigure}%
  }
}

\makeatletter
\newbox\sf@box
\newenvironment{SubFloat}[2][]%
{\def\sf@one{#1}%
\def\sf@two{#2}%
\setbox\sf@box\hbox
\bgroup}%
{ \egroup
\ifx\@empty\sf@two\@empty\relax
\def\sf@two{\@empty}
\fi
\ifx\@empty\sf@one\@empty\relax
\subfloat[\sf@two]{\box\sf@box}%
\else
\subfloat[\sf@one][\sf@two]{\box\sf@box}%
\fi}
\makeatother

\project{magicl}

\newcommand\ato{\rightarrow} %Morphismen
\newcommand\nto{\Rightarrow} %Natürliche Transformationen

\newtheorem{defini}{Definition}

\newcommand{\defi}[2]{%
  \begin{defini}[#1]
    \label{def:#1}
    #2
  \end{defini}
}

\newcommand{\dref}[1]{Def. \ref{def:#1}}

\newcommand{\seec}[1]{(siehe \cref{#1})}
\newcommand{\sees}[1]{(siehe \sref{#1})}
\newcommand{\seea}[1]{(siehe \abb{#1})}

\newcommand{\sexp}{S"=Expression}
\newcommand{\sexps}{S"=Expressions}
\newcommand{\cgen}{Code"=Generierung}
\newcommand{\mprog}{Meta"=Programmierung}
\newcommand{\cpp}{C\texttt{++}}

\title{Prototyp eines \sexp{}-basierten\\Rahmenwerks für
  sprachübergreifende \\\mprog{}} 
\author{Benjamin Teuber\\aus Hamburg} 
\date{\today}

\begin{document}

\begin{titlepage}

  \makeatletter
  \parindent = 0pt
  \sffamily\bfseries

  \null
  \vskip 1cm
  {\Huge\@title\par}
  \vskip 1.5cm

  {\Large\@author\par}
  \vskip 1cm

  {\large\@date\par}
  \vskip 1cm

  \vfill
  {Diplomarbeit am\\
   Arbeitsbereich "`Theoretische Grundlagen der Informatik"',\\
   Department Informatik,\\
   Universität Hamburg\par
  }
  {\vskip 1.5em}

  {Erstbetreuer: Dr.\ Daniel Moldt\par}
  {Zweitbetreuer: Prof.\ Dr.\ Leonie Dreschler-Fischer\par}
 \end{titlepage}
\thispagestyle{empty}

\pagenumbering{roman}

\section*{\centering Zusammenfassung}
Template-gestützte \cgen{} ist in der Informatik allgegenwärtig und
tritt in den verschiedensten Formen auf. Entsprechend groß ist die
Vielfalt verwendeter Werkzeuge -- seien es der C-Präprozessor, PHP oder
auch XSL-Transformationen. Die meisten bestehenden Technologien sind
allerdings aufgrund der verwendeten Syntax und Datenstrukturen recht
fehleranfällig und umständlich in der Benutzung. Eine weitgehend
vergessene, aber äußerst elegante und praktische Form der \cgen{} bietet
dagegen die Lisp-Sprachfamilie, welche mit \sexps{} als universeller,
einfacher Datenstruktur arbeitet sowie mit Makros, die als
``Lightweight-Compiler'' fungieren.

Diese Diplomarbeit beschäftigt sich mit der Frage, wie der Lisp-Ansatz
weiter verallgemeinert werden kann, um beliebige Zielsprachen,
verschiedene Modelltypisierungsgrade sowie eine EBNF-artige Komposition
von Makros zu ermöglichen. Dafür wird mit MagicL ein prototypisches
Framework in Haskell erstellt. Mit Hilfe einer kategorientheoretisch
motivierten Architektur auf der Basis von Arrows sowie einem Modell für
die strukturierte Quelltext-Erzeugung können dann unter anderem
\sexp{}-Sprachen eingelesen und typisiert oder weiterhin als
\sexps{} weiterverarbeitet werden. Für reine \sexp{}-Compiler wird
darüber hinaus eine DSL definiert, die einen gegenüber Lisp
verallgemeinerten Quasiquote-Operator sowie ein flexibles Makrosystem
bereitstellt und von einem metarekursiven Compiler nach Haskell
übersetzt wird.

\cleardoublepage


\addcontentsline{toc}{section}{Inhaltsverzeichnis}
\tableofcontents

\chapter*{Abkürzungsverzeichnis}
\begin{acronym}
\acro{ASCII}{American Standard Code for Information Interchange}
\acro{CSV}{Comma Separated Values}
\acro{DSL}{Domain Specific Language}
\acro{DSSSL}{Document Style Semantics and Specification Language}
\acro{EBNF}{Erweiterte Backus-Naur-Form}
\acro{GUI}{Graphical User Interface}
\acro{GHC}{Glasgow Haskell Compiler}
\acro{HTML}{Hypertext Markup Language}
\acro{JVM}{Java Virtual Machine}
\acro{MDA}{Model Driven Architecture}
\acro{PDF}{Portable Document Format}
\acro{PHP}{PHP: Hypertext Preprocessor}
\acro{SQL}{Structured Query Language}
\acro{UML}{Unified Modelling Language}
\acro{XML}{Extensible Markup Language}
\acro{XML-RPC}{XML Remote Procedure Call}
\acro{XPath}{XML Path Language}
\acro{XSL}{Extesible Stylesheet Language}
\acro{XSL-FO}{XSL - Formatting Objects}
\acro{XSLT}{XSL Transformation}
\acro{W3C}{World Wide Web Consortium}
\acro{WWW}{World Wide Web}
\end{acronym}
\addcontentsline{toc}{section}{Abkürzungsverzeichnis}

% \setlength{\parindent}{0pt}
% \setlength{\parskip}{2ex}


\lchapter[intro]{Einleitung}

\pagenumbering{arabic}

Unter \mprog{} versteht man das programmatische Manipulieren von
Programmen - anders gesagt: ``Metaprogramming is writing code that
writes code'' \cite[S.16]{metaprog-ruby}. Man unterscheidet zwischen
statischer und dynamischer
\mprog{} \cite[S.17]{metaprog-ruby}. Dynamische \mprog{} behandelt die
Manipulation von Programmen während der Laufzeit, weshalb man auch von
Laufzeit-\mprog{} spricht. Dies funktioniert nur in Sprachen, die diese
Möglichkeit explizit vorsehen, wie Ruby \cite{metaprog-ruby} oder auch
Java \cite{JavaReflection}.

Diese Arbeit beschäftigt sich stattdessen mit statischer
\mprog{}, in der es um das Erzeugen von Quelltext geht, der anschließend
an beliebige Compiler oder Interpreter gereicht werden kann, weshalb 
auch die Bezeichnungen Kompilationszeit-\mprog{} und generative
(Meta-)Programmierung \cite[S.17]{metaprog-sh} benutzt werden.

Diese Art der \mprog{} ist in der Informatik allgegenwärtig,
beispielsweise kann jeder Compiler als Meta-Programm gesehen werden. Die
auf \cgen{} basierende ``modellgetriebene Softwareentwicklung'' erfreut
sich immer größerer Popularität: Während UML \cite{UML} bald sein
15-jähriges Bestehen\footnote{Der Standarisierungsprozess von UML begann
  1994, als Gary Booch und Jim Rumbaugh mit der Vereinheitlichung ihrer
  Modellierungstechniken anfingen \cite[S. 17]{UML}.} feiert, vermarktet
IBM seit Jahren das Produkt \textit{Rational Application Developer}
\cite{RAD}, das, wie auch das freie \textit{Eclipse Modelling
  Framework} sowie \textit{Enterprise Architect}, Eclipse um
modellbasierte \cgen{} bereichert. Seit neuestem zeigt auch Microsoft
Interesse und verspricht mit \textit{Oslo}  \cite{Oslo} einen
``Mainstream"=Ansatz für Modellierung''. Generativer Programmierung
fällt auch im World Wide Web eine immer größer werdende Rolle zu: Ob
\textit{Ruby on Rails} oder \textit{Google Web Toolkit}, praktisch alle
Web Frameworks generieren zumindest ihre HTML-Dateien oder SQL-Abfragen
für den Datenbankzugriff.

\cgen{} aus Modellen\footnote{Auch Programmcode wird hier als Modell
  angesehen -- mit anderen Worten: "`Code is data and data is code."'}
bietet viele Vorteile: Zunächst gibt es dadurch einen höheren
Abstraktionsgrad, so dass Modellarchitekten mit Domain Specific
Languages (DSLs) arbeiten können und so die Ziel-Programmiersprache
nicht kennen müssen. Auch ist es möglich, durch Austauschen des
Generator-Backends die Zielsprache zu wechseln, ohne Modelle anpassen zu
müssen. Alternativ sind durch \mprog{} integrierte DSLs oder
Spracherweiterungen möglich, die dann beliebig mit der Backendsprache
vermischt werden können -- die Möglichkeit, eine Programmiersprache zu
modifizieren, liegt somit nicht mehr ausschließlich beim
Hersteller. \mprog{} erhöht die Produktivität, da sich Algorithmen in
einer speziell auf die Problemdomäne zugeschnittenen Sprache mit weniger
Aufwand formulieren lassen. Sie kann ebenfalls die Qualität verbessern, da ein
korrekter Generator auch aus neuen Modellen -- sofern diese verifiziert
sind -- immer fehlerfreien Code erzeugt. Daneben weist generierter Code eine
höhere Konsistenz auf, da generierte Strukturen, Funktionsnamen
etc. immer einheitlich sind. Dies erleichtert die Benutzung von
generierten Schnittstellen enorm.

Mit \mprog{} sind allerdings auch Nachteile verbunden: Die Komplexität des
Software-Systems wird durch die zusätzliche Ebene erhöht und es
entstehen neue mögliche Fehlerquellen. Auch die Suche nach Fehlern in
den Modellen kann erschwert werden, wenn die Probleme sich erst im
generierten Code manifestieren -- hier wird oft eine manuelle
Rückverfolgung benötigt um festzustellen, welcher Code aus welchem
Modell erzeugt wurde. Darüber hinaus erfordern neue
Modellierungssprachen immer eine Einarbeitung und müssen dokumentiert
werden. Auch sollte es nicht zu viele konkurrierende DSLs für eine
Domäne geben, so dass einheitliche Standards verloren
gehen. Beispielsweise kommt es bei Lisp \cite{Lisp}-Dialekten aufgrund
der Leichtigkeit, mit der die Sprache erweitert werden kann, durchaus
vor, dass jeder Programmierer in seiner eigenen Sprache programmiert, so
dass die Wartung von fremden Code sehr aufwändig wird. Um dies zu
vermeiden, ist der rege Austausch von Sprachen und Spracherweiterungen
wichtig, damit die Community schnell zu gemeinsamen Standards kommt
und nicht jeder Programmierer "`das Rad neu erfindet"'.

Trotz dieser möglichen Probleme überwiegen in vielen Fällen die
Vorteile, so dass die Bedeutung von generativer Programmierung sowie die
Vielfalt an Werkzeugen immer weiter zunehmen. Diese Arbeit beschäftigt
sich ganz allgemein mit der Frage, wie \mprog{} besser, einfacher und
einheitlicher gestaltet werden kann als bisher.

\lsection[intro:motiv]{Motivation}

Die Entwicklung eines Code-Generators ist gewöhnlich mit großem Aufwand
verbunden. So muss zunächst eine Eingabesprache festgelegt werden, für
die dann eine typisiertes Modellrepräsentation sowie ein Parser zur
Überführung in diese benötigt werden. Für den Parser wird eine eigene
Beschreibungssprache verwendet, die vom Programmierer vorher erlernt
werden musste und eventuell eine eingeschränkte Mächtigkeit besitzt, so
dass eine programmatische Nachbearbeitung der Modelle nötig werden
kann. Im Zuge der Verarbeitung, die in einer allgemeinen
Programmiersprache geschieht, werden eventuell noch weitere Modelle
benötigt. Die Quelltexterzeugung selbst erfolgt dann meist mittels
String-basierter Templates, welche aufgrund der fehlenden
Ausgabetypisierung oft zu Syntaxfehlern führen und so aufwändiges
Debugging benötigen. Auch die Template-Sprache ist einzeln zu erlernen
und eventuell ebenfalls in ihren Möglichkeiten eingeschränkt, so dass in
einigen Fällen nochmals eine Vorverarbeitung der Daten erfolgen muss.

Andererseits verfolgen Lisp-Programmierer bereits seit ca. 40
Jahren \cite{EvolutionOfLisp} einen strukturellen Ansatz zur \mprog{}, der den
mit Spracherweiterungen verbundenen Aufwand minimiert und Lisp
Bezeichnungen wie "`The programmable programming
language"' \cite{Federano} beschert hat. Hier werden Ein- und Ausgabecode
ausschließlich durch \sexps{} \sees{model:sexp} in einer untypisierten
Baumstruktur repräsentiert, so dass Zeichenketten weder eingelesen noch
erzeugt werden müssen, wodurch ein großer Teil des Generators bereits
wegfällt -- denn das Verarbeiten und Erzeugen von Bäumen ist simpler und
weniger fehlerbehaftet. \sexps{} fungieren auch direkt als Modelle, so
dass weitere Datenstrukturen für die Verarbeitung nur noch selten
benötigt werden. Lisp-Makros \sees{template:lisp} stellen kleine
Compiler-Plugins dar, die jeweils die Übersetzung eines einzelnen
Sprachkonstrukts beschreiben und so einen inkrementellen,
baukastenartigen Ansatz der Compiler-Entwicklung unterstützen. Da Makros
selbst Lisp-Funktionen sind, ist die einzige verwendete Metasprache mit
der generierten Sprache identisch, was die Einarbeitung erleichtert und
darüber hinaus die Möglichkeit eröffnet, Meta-Code selbst durch
Generierung zu erzeugen.

Leider ist das System ausschließlich auf die Erzeugung von Lisp-Code
ausgerichtet und wird normalerweise nicht für andere Zielsprachen
benutzt -- eine der wenigen Ausnahmen ist Parenscript \cite{Parenscript},
ein Werkzeug zur Erzeugung von JavaScript-Code aus Common Lisp. Generell
wird die Generierung anderer Sprachen von Lisp-System selbst aber
schlecht unterstützt, so dass die Bereitstellung derartiger Bibliotheken
mit unverhältnismäßig hohem Aufwand verbunden sind. Lisp-Dialekte werden
heutzutage nur noch von einer kleinen Community benutzt, was teils an
veraltetem Sprachdesign, hauptsächlich aber an der geringen Anzahl
verfügbarer Bibliotheken im Vergleich zu Mainstream-Sprachen
liegt. Während viele andere Lisp-Konzepte wie Garbage Collection oder
Konstrukte wie der REPL, eine Lisp-Kommandozeile zum interaktiven
Programmieren und Testen, bereits von modernen Sprachen nachgeahmt
wurden, ist der Ansatz einer \sexp-basierten \mprog{} mittels
Makros\footnote{Der C-Präprozessor bietet ebenfalls Makros an
  \sees{template:cprep}, welche allerdings weit weniger mächtig sind.}
nach wie vor einzigartig. Es wäre also wünschenswert, diesen
verallgemeinern und auf beliebige Backendsprachen übertragen zu können.

\lsection[intro:goal]{Fragestellung und Zielsetzung}

Die grundlegende Fragestellung lautet: Ist es möglich, den Lisp-Ansatz
inkrementeller \mprog{} auf \sexp{}-Basis derart zu verallgemeinern, dass
komfortabel in beliebige Zielsprachen generiert werden kann? Der Rahmen
dieser Arbeit soll allerdings deutlich weiter gefasst sein als die bloße
Anwendung von Lisp-Makros auf die Erzeugung verschiedener Sprachen --
diese könnte eventuell bereits durch die Implementation einer geeigneten
Lisp-Bibliothek erreicht werden. Vielmehr sollen sowohl Lisp als auch
andere Systeme zunächst auf Stärken und Schwächen untersucht und
anschließend eine eigene Architektur entworfen werden, die eine
möglichst hohe Flexibilität sowie maximal viele Vorteile bestehender
Werkzeuge in sich vereinen soll. Diese soll dann in einer geeigneten
Programmiersprache umgesetzt und so ein prototypisches Framework
bereitgestellt werden. Anschließend soll eine möglichst praktische,
selbst in \sexps{} notierte DSL
für die Beschreibung von \sexp{}-Compilern kreiert werden.

\lsection[intro:outline]{Aufbau dieser Arbeit}

Zunächst stellt \sref{intro:example} mit einer DSL für
Bildschirmpräsentationen ein Anwendungsbeispiel für generative
Programmierung vor, das im weiteren Verlauf dieser Arbeit immer wieder
aufgegriffen wird.

\cref{model} erläutert verschiedene Möglichkeiten der Repräsentation von
Quellcode und anderen Modellen und die damit verbundenen Vor- und
Nachteile. Hier werden insbesondere \sexps{} vorgestellt -- welche in
dieser Arbeit eine zentrale Rolle einnehmen -- und unter anderem mit XML
verglichen.

Fast alle \cgen{}swerkzeuge benutzen Templates für die
Quelltext-Erzeugung -- wenn auch auf sehr verschiedene Arten und
Weisen. \cref{template} beschreibt Templates zunächst anhand der
Begriffe Quasiquote und Unquote, welche aus der Lisp-Welt
stammen. Anschließend wird eine Auswahl Template-basierter Werkzeuge
vorgestellt und in Hinblick vorher erarbeiteter Kriterien evaluiert --
unter anderem auch Lisp-Makros.

Aus den vorangegangenen Untersuchungen über Modelle und Werkzeuge werden
in \cref{reqs} Anforderungen für das universelle, im Rahmen dieser
Arbeit entworfene Rahmenwerk MagicL abgeleitet. Wesentlich ist hier,
dass die Definition beliebiger Compiler zwischen den Modelltypen
Zeichenkette, \sexp und Objekt -- mit einem Fokus auf \sexps{} -- auf
eine möglichst einfache und flexible Weise unterstützt wird, weshalb
neben Lisp-Makros verschiedene Aspekte der im vorigen Kapitel
vorgestellten Werkzeuge zusammen mit einigen neuen Ideen verwendet
werden sollen.

Um die geforderte Flexibilität erreichen zu können, basiert die
gesamte Architektur von MagicL auf Konzepten der Kategorientheorie,
einem sehr abstrakten Zweig der Mathematik. Neben vielfältigen anderen
Verwendungsmöglichkeiten können mit Kategorien beliebige Arten von
Prozessketten derart beschrieben werden, dass Verarbeitungseinheiten
über Operatoren nach dem Baukastenprinzip kombinierbar sind. \cref{cats}
führt deshalb in die Kategorientheorie ein und erklärt die später
benötigten Begriffe.

Die Programmiersprache Haskell stellt unter anderem mit Arrows und
Monaden die programmatischen Umsetzungen kategorientheoretischer
Konzepte zur Verfügung, mit deren Hilfe es unter anderem gelingt,
Nebeneffekte sauber isoliert in die ansonsten pur funktionale Sprache zu
integrieren. MagicL ist in Haskell mittels Arrows implementiert, weshalb
\cref{haskell} zunächst die Sprachgrundlagen und anschließend die
kategorientheoretischen Typklassen und Funktionen erläutert.

Ein grundlegender Überblick über die Architektur von MagicL wird in
\cref{arch} vermittelt. Hier werden die verschiedenen modellspezifischen
Bibliotheken und Hilfsmittel vorgestellt, die MagicL für die
Konstruktion von Compilern bereitstelt. Zudem werden die Haskell-DSL und
die darauf aufbauende Compiler-DSL vorgestellt, die dem
Meta-Programmierer in MagicL zur Verfügung stehen.

\cref{arrowparser} zeigt, wie sich durch die Kombination einfacher
Funktoren eine Parser-Kategorie konstruieren lässt. Die
Haskell-Umsetzung dieser Kategorie ergibt eine elegante Art der
Beschreibung von Parsern, die nicht nur für Zeichenketten verwendet
werden können. Darauf aufbauend wird eine Parser-Bibliothek mit
nützlichen Hilfsfunktionen zur Erzeugung und Kombination von Parsern
bereitgestellt.

Neben der Parser-Bibliothek enthält MagicL eine Reihe weiterer
Basiskomponenten, welche in \cref{magicl} vorgestellt werden. Eine
Generator-Bibliothek erlaubt die funktionale Erzeugung von Quelltext auf
eine Weise, die weniger Anfällig für Syntaxfehler ist als ein direktes
Templating auf String-Ebene. \sexps{} werden in MagicL ebenfalls durch
Parser verarbeitet, welche als verallgemeinerte Makros gesehen
werden. Eine \sexp{}-Bibliothek stellt eine Reihe von Hilfsfunktionen
für \sexp{}-Parsing bereit und liefert darüber hinaus einen Parser und
einen Generator für die Serialisierung von \sexps{} in
Zeichenketten. Außerdem wird die allgemeine, ebenfalls Arrow-basierte
Compiler-Schnittstelle vorgestellt, mit der verschiedene Parser sowie
funktionale und imperative Compiler angesprochen werden können. Damit
ist es zudem möglich, Haskell mittels Typinferenz selbstständig den passenden
Compiler für eine Aufgabe auswählen zu lassen. 

Mit Hilfe der vorangehenden Werkzeuge wird in \cref{sexphs} die
Haskell-DSL implementiert, welche eine auf \sexp{} übertragene Version
von Haskell und damit eine vollständige funktionale Programmiersprache
darstellt und eine rein \sexp{}-basierte Generierung von
Haskell-Quelltext ermöglicht. 

\cref{sexpcomp} bildet den Höhepunkt der Arbeit und stellt die DSL vor,
in der MagicL-Benutzer eigene Compiler definieren können. Die
Compiler-DSL ist eine Erweiterung der Haskell-DSL und enthält einen
Quasiquote-Operator für \sexps{} sowie ein Lisp ähnliches
Makrosystem. Der Compiler-Compiler, der von der Compiler-DSL in die
Haskell-DSL übersetzt, wird selbst in der Compiler-DSL definiert und ist
somit metazirkulär.

\cref{disc} diskutiert das entstandene Framework in Hinblick auf die
vorherigen Anforderungen und vergleicht MagicL mit anderen Systemen zur
\mprog{}. Schließlich wird die gesamte Arbeit in \cref{end}
zusammengefasst und ein Ausblick auf mögliche Fortsetzungen dieser
Arbeit gegeben. 

\lsection[intro:example]{Beispieldomäne}

Für die einfachere Diskussion verschiedener Werkzeuge und Konzepte
versucht diese Arbeit, möglichst eine einheitliche Domäne für
Anwendungsbeispiele zu verwenden. Dabei geht es um eine fiktive, zu
erstellende DSL für Präsentationen -- genannt Slide -- die Konzepte wie
Folientitel, Aufzählungen, Bilder etc. in einer kurzen
Notation bereitstellt. Slide-Code wird vom Modellierer -- hier dem
Ersteller einer Präsentation -- geschrieben und vom Slide-Compiler in
Latex \cite{Latex}-Code mit der Beamer \cite{LatexBeamer}-Klasse übersetzt
\seea{flow_example_simple}, aus der anschließend eine PDF-Datei erzeugt
werden kann.

\fig[0.4]{flow_example_simple}{Der Slide-Compiler} 

Die Aufgabe eines Werkzeugs zur \cgen{} besteht nun darin, den
Meta-Programmierer bei der Entwicklung des Slide-Compilers soweit wie
möglich zu unterstützen.

\lchapter[model]{Repräsentation von Modellen}

In bestehenden \cgen{}swerkzeugen werden Modelle für Ein- und Ausgaben
auf eine von drei Arten repräsentiert: Als rohe Zeichenkette, als
typisiertes Objekt oder durch eine ungetypte
Baumrepräsentation. Beispiele für letztere sind unter anderem \sexps{},
XML sowie JSON. Dieses Kapitel erarbeitet zunächst Vergleichskriterien
für Repräsentationsformen. Anschließend werden alle diese Ansätze sowie
die graphische Repräsentationssprache UML vorgestellt und anhand der
Kriterien bewertet.

\lsection[model:crit]{Vergleichskriterien}

Als Vergleichskriterien für die Bewertung von
Modellrepräsentationen werden Typisierungsgrad, Universalität,
graphische Darstellung sowie Komposition von Modellen verwendet.

\lsubsection[model:crit:type]{Typisierung}

Das wohl wesentliche Merkmal einer Modellrepräsentation ist seine
Typisierung. Es gibt auf der einen Seite gänzlich untypisierte
Repräsentationen wie beispielsweise Bit-Streams, die viel Flexibilität,
aber keinerlei Typsicherheit oder strukturellen Datenzugriff mit sich
bringen. Auf der anderen Seite stehen statisch getypte Objekte, die
komfortablen Zugriff und Typsicherheit garantieren, im Gegenzug aber
sehr unflexibel sind. Dazwischen stehen universelle Notationen wie XML,
die eine Struktur, aber keine direkte Typisierung besitzen\footnote{Es
  gibt zwar die Möglichkeit, XML-Dokumente gegen eine externe
  Spezifikation zu validieren oder automatisch in ein typisiertes Objekt
zu überführen. Allerdings ist dies eher mit einer Grammatik
zum Parsen von Strings vergleichbar als mit inhärent typisierten Daten.}.

\lsubsection[model:crit:univ]{Universalität} 

Manche Codegeneratoren sind nur für eine spezielle Ausgabesprache
gedacht, was sich in den festen Modellen wiederspiegelt. Andere
verwenden Modelle, die bereits universell und direkt auf jede Domäne
anwendbar sind. Dazwischen liegen Systeme, in denen der
Metaprogrammierer neue Modelle definieren kann, so dass eine
Übertragbarkeit vorliegt, die allerdings mit einem kleinen Mehraufwand
verbunden ist.

\lsubsection[model:crit:graphic]{Graphische Darstellung}

Die Möglichkeit, ein Modell zu visualisieren oder gar mit einer
graphischen Benutzeroberfläche zu bearbeiten, ist sehr praktisch für
Dokumentation, Übersichtlichkeit sowie Zusammenarbeit mit
Domänenexperten, die das verwendete System nicht genau verstehen müssen.

\lsubsection[model:crit:compose]{Komposition}

Sinnvollerweise sollten Modelle schachtelbar sein, so dass
komplexe Modelle aus einfacheren zusammengesetzt werden können.
Dies lässt sich durch die Konzepte Unterknoten oder Attribut ausdrücken.

Modelle lassen sich oft als knotenbenannte Bäume beschreiben, in denen
die Kinder eines Knotens als Untermodelle oder Komponenten aufgefasst
werden. Dies entspricht dem Entwurfsmuster
Komposition \cite[S.182f]{CompositePattern}. Unterknoten sind nicht
weiter gekennzeichnet und können somit nur durch ihre Reihenfolge oder
ihren Inhalt (zu dem auch der Name gehört) unterschieden
werden. \abb{model_tree} zeigt eine simple Aufzählung als
Listenknoten mit zwei Unterknoten.

\fig{model_tree}{Eine einfache Aufzählung als Baumstruktur}

Attribute hingegen ordnen auf Ebene des Oberknotens Eigenschaftsnamen
Werte zu, was eher dem gängigen Bild von Objekteigenschaften
entspricht. Eine Komposition durch Attribute ist nur dann möglich, wenn
als Werte wiederum beliebige Modelle zugelassen sind -- was
beispielsweise nicht für XML-Attribute gilt. Da bereits eine Benennung auf
oberer Ebene erfolgt, besitzen Unterknoten hier oft keinen Namen
mehr. Manche Repräsentationen erlauben auch Listenwertige
Attribute. \abb{model_attr} zeigt die Repräsentation eines betitelten
Bildes durch Attribute, welche als beschriftete Kanten dargestellt
werden.

\fig{model_attr}{Eigenschaften eines Bildes als Attribute}

Beide Sichtweisen lassen sich leicht ineinander überführen. Um
beispielsweise Attribute durch Unterknoten zu ersetzen, wird pro
Attribut ein neuer Knoten desselben Namens eingeführt (oder ein
bestehender, anonymer Unterknoten benannt). So zeigt
\abb{model_attr_as_node} das letzte Beispiel nochmals in
Knotenrepräsentation. Aus diesem Grund reicht bereits die komplette
Unterstützung eines der beiden Konzepte, um alle Ausdrucksmöglichkeiten
bereitzustellen.

\fig{model_attr_as_node}{Eigenschaften eines Bildes als Knoten}

\medskip{}

Im nächsten Abschnitt werden die verschiedenen Modellarten im Hinblick
auf diese Kriterien diskutiert.

\lsection[model:string]{Strings}

Zeichenketten stehen auf der niedrigsten Stufe der Datenrepräsentation --
schließlich sind sie lediglich Bitfolgen. Damit sind Strings immer dann
erforderlich, wenn Modelle zur persistenten Speicherung oder
Kommunikation serialisiert werden müssen.

Um ein Modell als String zu repräsentieren, muss zunächst eine Syntax
festgelegt werden. Eine Folie, die eine Aufzählung enthält, könnte
beispielsweise so codiert werden:
\begin{DIFnomarkup}\begin{code}
a slide titled "My Slide" with list "one", "two" and "three"  
\end{code}\end{DIFnomarkup}

Da Zeichenketten per se keinerlei Struktur oder Typisierung ermöglichen, ist
eine String-Repräsentation für die Erzeugung und Bearbeitung sowie
komplexere Verarbeitung von Modellen eher ungeeignet. Vor der
Verarbeitung sollte ein String deshalb vom Parser in ein strukturiertes
Modell umgewandelt werden. Eine graphische Darstellung besitzen Strings
nicht, wenn man von der Anzeige als Text absieht.

\lsection[model:object]{Objekte}

Das Wort ``Objekt'' wird in dieser Arbeit nicht ausschließlich im
objektorientierten Sinn verwendet -- vielmehr ist hier "`Datentypinstanz
einer Programmiersprache"' gemeint, so dass auch nicht objektorientierte
Sprachen einbezogen werden. Objekte bieten den höchsten Typisierungsgrad
und die damit verbundene Sicherheit\footnote{Eine weitere Steigerung der
  Sicherheit wäre über Typen hinausgehende Validierung von
  Modellen.}. Es muss zwischen Objekten in statisch und dynamisch
getypten Sprachen unterschieden werden, denn in dynamischen Typsystemen
werden Typfehler erst beim Zugriff, bei \cgen{} also vermutlich erst im
Übersetzungsvorgang erkannt. In den meisten Sprachen gibt es Attribute
für Objekte sowie einen Listen- oder Arraydatentyp. Unbenannte
Komponenten haben Objekte gewöhnlich nicht -- eine Ausnahme bilden
Haskell-Datentypen \sees{haskell}. Eine Visualisierung von Objekten kann
als Graph mit benannten Kanten erfolgen. \abb{model_slide_obj} zeigt
obiges Folienbeispiel in einer statisch typisierten Programmiersprache
mit listenwertigen Attributen.

\fig{model_slide_obj}{Folie als typisiertes Objekt}

\lsection[model:sexp]{\sexps}

\sexps{} bilden die grundlegende Syntax aller Lisp-Dialekte. Die
Definition ist sehr einfach: Ein \sexp{} ist entweder ein Symbol oder
eine Liste von \sexps{}. Symbole sind Zeichenketten\footnote{Die meisten
  Lisp-Dialekte unterscheiden nicht zwischen Groß- und Kleinbuchstaben
  in Symbolen -- das im Rahmen dieser Arbeit entwickelte Framework
  hingegen schon.}, die keine Leerzeichen oder andere vom Lisp
verwendeten Sonderzeichen enthalten. Listen werden in runde Klammern
gesetzt -- mit Leerzeichen als Trennsymbol. Beispiele für \sexps{} sind:
\begin{itemize}
\item \icode{foo}
\item \icode{(slide)}
\item \icode{(list one two three)}
\end{itemize}

\sexps{} sind zwar formal als Listen definiert, werden aber meist als
Bäume mit benannten Knoten interpretiert -- hierfür wird das erste
Element einer Liste -- typischerweise ein Symbol -- als Name sowie alle
weiteren als Unterknoten aufgefasst. Zwischen \icode{(foo)} und
\icode{foo} wird dabei weiterhin unterschieden. Nicht alle gängigen
Verwendungen von \sexps{} fügen sich jedoch in dieses Baumschema
ein. Beispielsweise enthält Common Lisp oft Konstrukte in der Art von
\icode{(interval (1 10))}, wo in \icode{(1 10)} die 1 keinen Namen,
sondern einen Wert darstellt. Konsistenter wäre hier \icode{(interval 1
  10)}. Darüber hinaus kommen oft der ``leere \sexp{}'' \icode{()} sowie
nicht-symbolische Knotennamen wie in \icode{((lambda x (+ x 1)) 41)}
vor, wo eine anonyme Funktion direkt auf einen Wert angewendet wird.

Über die bloße \sexp{}-Syntax hinaus besitzen Lisp-Dialekte oft noch
Syntax für Kommentare, Strings, Symbolnamen mit Leerzeichen
etc. Dennoch sind \sexps{} wohl die einfachste benutzte
Repräsentationsform für strukturierte Daten. Das Modell selbst ist
ungetypt, da in den Blättern Strings stehen. Eine Validierung kann
daher erst nach dem Einlesen erfolgen.

Attribute sind in der Grundstruktur nicht vorgesehen, können aber wie
oben beschrieben durch Unterknoten simuliert werden. Beispielsweise
könnte eine Folie mit Bild und Aufzählung wie folgt dargestellt werden:
\begin{DIFnomarkup}\begin{code}
(slide 
  (title My Slide)
  (image
    (source diagram.png)
    (caption This is a diagram))
  (list one two three))
\end{code}\end{DIFnomarkup}
Dies entspricht dem Baum in \abb{model_slide_sexp}. In konkreten
Lisp-Dialekten würde man diese Repräsentation selten anfinden: Zum einen
würde eine String-Notation zur Unterscheidung von Werten und Variablen
verwendet werden. Zum anderen ist es üblich, feste Parameter wie
Folientitel nicht zu benennen, sondern implizit durch die Reihenfole
zuzuordnen. Dies könnte dann derart aussehen:
\begin{DIFnomarkup}\begin{code}
(slide "My Slide"
  (image "diagram.png" "This is a diagram")
  (list "one" "two" "three"))
\end{code}\end{DIFnomarkup}

\fig{model_slide_sexp}{Baumansicht einer Folie in \sexps{}}

Trotz der simplen Struktur und Syntax, die auch benötigte Werkzeuge wie
Editoren, Parser usw. vereinfachen, bieten \sexps{} also eine
universelle Modellierungssprache an, mit der auch Attribute und Listen
indirekt repräsentiert werden können.

\lsection[model:xml]{XML}

XML ist die wohl derzeit meistverbreitete Markup-Sprache, weshalb hier
auf eine detailierte Einführung verzichtet wird. Wie bei \sexps{}
handelt es sich um eine strukturierte, ungetypte Repräsentation, die
einem knotenbenannten Baum entspricht. XML unterscheidet sich von
\sexps{} -- Syntax zunächst ausgenommen -- hauptsächlich durch das
Vorhandensein von Attributen, die allerdings nur Strings als Werte
erlauben. Darüber hinaus gibt es Features wie Namensräume, Referenzen
und CDATA-Abschnitte, welche Zeichenketten repräsentieren können, die
mit XML-Syntax interferieren würden.

Das Folien-Beispiel lässt sich in XML wie folgt modellieren:
\begin{DIFnomarkup}\begin{code}
<slide title="My Slide">
  <image source="diagram.png">
    This is a diagram
  </image>
  <list>
    <item>one</item>
    <item>two</item>
    <item>three</item>
  </list>
</slide>
\end{code}\end{DIFnomarkup} %"<
Titel und Bildquelle werden als Attribute modelliert, als
Bildanschrift wird implizit das Innere vom Knoten \icode{image}
verwendet. Das Beispiel zeigt, dass die XML-Syntax im Vergleich zu
\sexps{} eine erhöhte Redundanz aufweist. Die erzwungene Wiederholung
des Knotennamens in schließenden Tags soll die Robustheit im Falle
vergessener Tags erhöhen, hat aber neben dem erhöhten Schreibaufwand den
Nachteil, dass XML damit im Gegensatz zu \sexps{} eine kontextsensitive
Sprache und folglich aufwändiger zu parsen wird. XML-Parser, die
kontextfreie Parser-Generatoren benutzen, müssen deshalb anschließend in
einem zusätzlichen Durchlauf die korrekte Zuordnung der Schließ-Tags
überprüfen. Die Schreibarbeit lässt sich zwar durch die Verwendung eines
speziellen XML-Editors wieder verringern, allerdings könnte ein solcher
auch die Zuordnung von Unterknoten -- beispielsweise durch Einrückung -- 
verdeutlichen, was die Redundanz wieder unnötig erscheinen lässt.

Ein anderer Grund weshalb das Beispiel umständlich wirkt ist, dass
XML-Knoten als Unterknoten zwar beliebig viele XML-Knoten, aber -- im
Gegensatz zu \sexps{} nur einen String besitzen können. Aus diesem Grund
sowie dem Nichtvorhandensein listenwertiger Attribute sind zusätzliche
\icode{item}-Knoten erforderlich\footnote{Würde man stattdessen den
\icode{list}-Knoten weglassen, gäbe es Probleme bei mehreren Listen auf
einer Folie.}. \abb{model_slide_xml} zeigt die Baumdarstellung dieses
Beispiels.

\fig{model_slide_xml}{Baumansicht einer Folie in XML}

Ein häufiges Problem bei der Definition von XML-Formaten ist die Frage,
ob eine spezielle Eigenschaft durch einen Unterknoten oder durch ein
Attribut repräsentiert werden sollte. Attribute sind in der Schreibweise
kürzer und deshalb komfortabler, auf der anderen Seite erlauben sie aber
keine zusammengesetzten Werte\footnote{Es ist zwar möglich, über einen
  Attribut-String im XML-Format innere Struktur in Attribute einzubauen
  -- dieser würde dann aber nicht automatisch geparst werde, so dass von
  diesem Trick eher abzuraten ist.}. Es kommt deshalb durchaus vor, dass
eine Eigenschaft zunächst als Attribut realisiert wird, dann aber später
bei wachsender Komplexität und Modellierungsgenauigkeit durch einen
Unterknoten ersetzt werden muss, wodurch eine Inkompatibilität zu alten
Dateien entsteht. Beispielsweise könnte es sich nachträglich als Fehler
herausstellen, den Folientitel als Attribut gewählt zu haben, wenn
spätere Slide-Erweiterungen es erlauben sollen, Titel mittels
\icode{color}-Tag einzufärben.

Es stellt sich also die Frage, ob XML-Attribute überhaupt notwendig sind
oder vielmehr ein optionales Feature, was nur aufgrund der umständlichen
Syntax für Knotendefinitionen genutzt wird. In diesem Fall
sollten Attribute wohl zukünftig aus XML verschwinden, schließlich
schreibt das W3C \cite{XmlSpec}: "`The number of optional features in XML
is to be kept to the absolute minimum, ideally zero"'.

Ist also ein zweiter, limitierter Kantentyp für bestimmte Zwecke
nützlich? Ein Beispiel wäre die Trennung von normalen und
Meta-Eigenschaften, wobei letztere als Attribute repräsentiert werden
könnten. Ein anderes ist die Aufteilung zwischen Pull- und
Push-Verarbeitung: Attribute werden üblicherweise direkt mit einem per
Query erfragten Knoten mitgeliefert (Push), während Unterknoten nur
mitgeschickt werden, wenn diese explizit abgefragt wurden (Pull). Auch
für die Trennung von optionalen und erforderlichen Eigenschaften könnte
solch ein zweiter Kantentyp nützlich sein.

Das Problem bei all diesen Beispielen ist jedoch die Einschränkung auf
String-Attribute. Sobald ein Attribut einen strukturierten Wert erhalten
soll, bricht jede systematische Trennung zusammen, und es muss auf
Unterknoten zugegriffen werden. In diesem Fall ist es aber vermutlich
besser, von Anfang an auf Attribute zu verzichten.

Eine ähnliche Diskussion lässt sich über Namespaces führen. Auch wenn
deren Nützlichkeit unbestritten ist, ist es fraglich, ob sie unbedingt
Teil des Grund-XML sein müssen. Moderner wäre ein Entwurf mit
minimaler Basissprache, in der Doppelpunkte in Knotennamen zugelassen
sind, sowie einem Plugin-System, welches unter anderem einen
Namespace-Präprocessor bereitstellt, der die Doppelpunkte korrekt
interpretiert. Auf diese Weise wäre es auch möglich, alternative
Lösungen für das Namensraumproblem anzubieten. Beispielsweise könnte ein
anderer Ansatz eine Wiederholung der Namespace-Abkürzung in jedem Tag
vermeiden, indem ein spezielles Tag \icode{in-namespace} eingeführt
wird, so dass statt
\begin{DIFnomarkup}\begin{code}
<slide:list>
  <slide:item>one</slide:item>  
  <slide:item>two</slide:item>  
  <slide:item>three</slide:item>  
</slide:list>
\end{code}\end{DIFnomarkup}
nun
\begin{DIFnomarkup}\begin{code}
<in-namespace ns="slide">
  <list>
    <item>one</item>  
    <item>two</item>  
    <item>three</item>  
  </list>  
</in-namespace>
\end{code}\end{DIFnomarkup}
geschrieben werden könnte.
\lsection[model:json]{JSON}

JSON ist sowohl eine Markupsprache als auch eine Teilmenge von
JavaScript \cite{JavaScript}, weshalb es direkt von einem
JavaScript-Interpreter eingelesen werden kann. Dies macht JSON vor allem
für Webanwendungen interessant. Mit JSON können anonyme Objekte mit
Attributen -- auch listenwertige -- explizit repräsentiert werden. Als
Blätter sind Strings und elementare Datentypen zugelassen, die beim
Einlesen dynamisch typisiert werden.

Das Folien-Beispiel kann in JSON wie folgt repräsentiert werden:
\begin{DIFnomarkup}\begin{code}
{
  "title" : "My Slide"
  "image" : {
    "source"  : "diagram.png"
    "caption" : "This is a diagram"
  }
  "list"  : ["one", "two", "three"]
}
\end{code}\end{DIFnomarkup}
\begin{DIFnomarkup}\begin{code}
{
  "title" : "My Slide"
  "image" : {
    "source"  : "diagram.png"
    "caption" : "This is a diagram"
  }
  "list"  : ["one", "two", "three"]
}
\end{code}\end{DIFnomarkup}
Die Benennung als \icode{slide} muss außerhalb erfolgen, d.h. bei einem
übergeordneten Objekt als Attribut oder auf der höchsten Ebene
beispielsweise durch den Dateinamen.

Aufgrund der Austauschbarkeit von Attributen und benannten Unterknoten
sind JSON und \sexps{} gleich ausdrucksstark, wie das Beispiel
zeigt. Der einzige strukturelle Unterschied besteht im obersten Knoten,
der bei JSON anonym und bei \sexps{} benannt ist.

\lsection[model:uml]{UML}

UML ist eine graphische Modellierungssprache, die speziell für die
Spezifikation von Softwaresystemen entworfen wurde und insbesondere den
objektorientierten, imperativen Entwurf unterstützt. Viele Werkzeuge können
aus UML beispielsweise Java-Quellcode generieren. Es gibt in UML eine
Reihe verschiedener Diagrammarten, die verschiedene Knoten- und
Kantentypen in einem Graphen erlauben. Teilweise können auch Unterknoten
in einen Knoten eingebettet werden. Abgespeichert werden UML-Diagramme
meist in einem XML-Format, da UML keine eigene Serialisierung definiert.

Nach graphischen Elementen ist bereits eine Teilmenge der
UML-Klassen\-diagramme äquivalent zu XML etc., da diese bereits
knotenbenannte Bäume mit Attributen darstellen kann. Die bisherigen
Abbildungen dieses Kapitels benutzen beispielsweise Aggregations- und
Attributkanten um Unterknoten und Attribute zu repräsentieren.  Es
handelt sich hierbei jedoch nicht um semantisch korrekte UML-Diagramme --
beispielsweise wurden benannte Knoten wie UML-Klassen
aufgemalt. \abb{model_slide_uml} zeigt eine Modellierung des
Folienbeispiels als UML-Objektdiagramm.

\fig{model_slide_uml}{Folienbeispiel als UML-Objektdiagramm}

Wenn man also die von UML (mehr oder weniger) klar definierte,
objektorientierte Semantik aller graphischen Elemente berücksichtigt,
handelt es nicht nicht mehr um eine abstrakte, domänenunabhängige
Sprache.

\lsection[model:sum]{Zusammenfassung}

Es gibt in bestehenden Code-Geneneratoren drei grundlegende Arten, ein
Modell zu repräsentieren, die alle ihre Daseinsberechtigung haben und
über Parser, Generatoren und Compiler ineinander umgewandelt werden
können.

Strings sind immer nötig, wenn ein Modell dauerhaft gespeichert oder
verschickt werden soll. Für alle anderen Zwecke sind diese dagegen eher
unpraktisch.

Für eine aufwändigere Verarbeitung, die komplexe Rechnungen oder
Algorithmen erfordert, eignen sich Objekte am besten. Fehler werden vor
allem bei statisch typisierten Objekten frühestmöglich erkannt. Dafür
ist es allerdings nötig, spezielle Klassen bzw. Datentypen für diese
Modelle zu definieren. Zudem ist eine Übertragbarkeit zwischen
Programmiersprachen im Allgemeinen nicht gegeben.

Untypisierte Baumrepräsentation eignen sich aufgrund ihrer Struktur und
Flexibilität besonders für die Erzeugung und Bearbeitung von Modellen --
mit einem geeigneten universellen Editor könnten Benutzer komfortabel
und ohne die Möglichkeit von Syntaxfehlern Modelle beliebiger Domänen
erzeugen, ohne dass der Editor vorher Informationen über Syntax oder
Semantik der Modelle benötigt. Auch die maschinelle Erzeugung von
Modellen ist in einer Baumrepräsentation am einfachsten. Simple
Verarbeitungsprozesse können mit Bäumen ebenfalls gut durchgeführt
werden.

\begin{sidewaysfigure}[tp]
  \centering
\begin{tabular}{|l|l|l|l|l|l|l|}\hline
\bf Modell                        & \bf String & \bf Objekt           & \bf \sexps{}    & \bf XML  & \bf JSON & \bf UML         \\\hline\hline
\bf Typisierung                   & gering     & sehr hoch            & mittel          & mittel   & mittel   & relativ hoch    \\\hline
\bf Universell                    & ja         & Klasse erforderlich  & ja              & ja       & ja       & ja              \\\hline
\bf Domänenunabhängig             & ja         & nein                 & ja              & ja       & ja       & nein            \\\hline
\bf Graphische Darstellung        & Text       & Graph                & Baum            & Baum     & Baum     & Graph           \\\hline
\bf Unterknoten                   & nein       & selten               & ja              & ja       & nein     & ja              \\\hline
\bf Attribute                     & nein       & fast immer           & nein            & primitiv & ja       & ja              \\\hline
\bf Listenwertige Attribute       & nein       & meistens             & nein            & nein     & ja       & nein            \\\hline
\bf Feature-Anzahl                & minimal    & nach Sprache         & minimal         & mittel   & klein    & groß            \\\hline
\end{tabular}
  \caption{Vergleich verschiedener Modellrepräsentationen}
  \label{magicl:fig:model_sum}
\end{sidewaysfigure}

\abb{model_sum} zeigt eine tabellarische Zusammenfassung des in diesem
Abschnitt erfolgten Vergleichs von Strings, Objekten, UML sowie den
Baumrepräsentationssprachen \sexps{}, XML und JSON. Den \sexps{} fällt
unter den Baumrepräsentationen eine besondere Rolle zu, da diese im
Gegensatz zu beispielsweise XML minimal und redundanzfrei definiert
sind, ohne an Ausdrucksmächtigkeit zu verlieren. Damit wird \sexps{}
verarbeitenden Werkzeugen keinerlei unnötige Komplexität
aufgezwungen. Aus diesem Grund widmet sich diese Arbeit weitgehend der
\sexp-gestützten Code-Generierung.

\lchapter[template]{Template-basierte \cgen{}}

Templates werden für die Erzeugung von Dokumentmengen eingesetzt, für
die gewisse statische Bereiche in jedem Dokument identisch sind, während
sich nur die dynamischen Bereiche ändern -- beispielsweise eine Webseite,
die Daten aus einer Datenbank anzeigt. Auch bei der Erzeugung von
Programmen tritt dieser Fall auf, so dass Templates eine große Rolle bei
\cgen{} spielen. Ein Template legt die statischen Bereiche fest und lässt
Platzhalter für die dynamischen. Es handelt sich dabei im Grunde um eine
mathematische Funktion, deren Eingabe die dynamischen Daten und deren
Ausgabe ein fertiges Dokument ist.

Gewissermaßen können also Templates bereits in jeder Programmiersprache
definiert werden, die Funktionsdefinitionen ermöglicht. Solch eine
Funktion müsste das Zieldokument mittels String-Operatoren
zusammensetzen, was im Normalfall zu umständlich ist. Stattdessen bieten
Templating-Sprachen eine ``schablonenartige'' Notation, die sich gut
anhand der im Lisp-Umfeld üblichen Operatoren Quasiquote\footnote{Neben
  Quasiquote ist auch der Begriff Backquote üblich. Zudem
  gibt es in Lisp-Sprachen oft auch ein einfaches Quote, welches einen
  komplett statischen Bereich erzeugt, ohne darin auf Unquotes zu
  achten.} und Unquote beschreiben lässt. Ein Quasiquote erzeugt ein
Template, und das Innere eines Quasiquotes wird als statisch
interpretiert, solange darin kein Unquote auftritt. Ein Unquote, welches
nur innerhalb eines Quasiquote auftauchen darf, erzeugt einen
dynamischen Unterabschnitt, welcher in der vom Werkzeug bereitgestellten
Meta-Sprache beschrieben ist. Hier werden die Eingabeparameter des
Templates verwendet. Der Vorteil dieser Notationsform besteht darin,
dass ein Template -- bis auf die dynamischen Abschnitte -- genauso
aussieht wie das Zieldokument und dadurch gut lesbar bleibt.

Es gibt viele verschiedene Werkzeuge, die vom Template-Prinzip Gebrauch
machen. Diese unterscheiden sich oft neben der Syntax in vielen weiteren
Punkten. Dieser Abschnitt stellt zunächst diese Vergleichskriterien vor,
anschließend wird eine Auswahl Template-basierter Werkzuge zur \cgen{}
anhand dieser Kriterien verglichen und bewertet.

\lsection[template:crit]{Vergleichskriterien}

Unterschiede zwischen verschiedenen, Template-basierten Code-Generatoren
bestehen in den verwendeten Modellen, der konkreten Weise der
Template-Erzeugung, der Mächtigkeit der Metasprache, der Art des --
eventuell rekursiven -- Aufrufs von Templates sowie Unterstützung von
Komponententrennung und der Möglichkeit, widerum Templates aus Templates
generieren zu können.  

\lsubsection[template:crit:model]{Verwendete Modelle}

Template-Engines unterscheiden sich sowohl in den Eingabe-, als auch in
den Ausgabemodellen. Verwendet werden für beides gewöhnlich
Zeichenketten, typisierte Objekte sowie untypisierte Bäume wie \sexps{}
oder XML \seec{model}. Mit den Modellen variieren die
Typisierungsgrade und damit auch das Maß und der Zeitpunkt einer
möglichen Validierung der Daten.

Die generierbaren Zielsprachen unterscheiden sich ebenfalls -- manche
Generatoren können jede Sprache generieren, während andere nur eine
einzige oder eine Familie von Sprachen unterstützen.

\lsubsection[template:crit:def]{Art der Template-Erzeugung}

Auch wenn fast alle Ansätze der Template-Erzeugung sich mit Quote und
Unquote beschreiben lassen, gibt es einige Unterschiede bei der genauen
Verwendung.

Nicht überall sind Quasiquotes explizit -- oft interpretieren
Templating-Systeme auch automatisch die äußerste Ebene einer Template-Datei als
quotiert. Manche Werkzeuge besitzen kein universelles
Quasiquote, mit dem sich wirklich jede gewünschte, Quellcode erzeugende
Funktion ausdrücken lässt. Aus syntaktischen Gründen könnte es
beispielsweise nicht möglich sein, eine variable Anzahl an Statements zu
erzeugen.

Auch die Möglichkeit zur Schachtelung weiter Quasiquotes in
Unquote-Bereichen ist nicht überall gegeben. Darüber hinaus benutzen
manche Systeme ein implizites Unquote, welches automatisch
eingesetzt wird, wenn ein Token mit dem Namen eines Template-Parameters
übereinstimmt.

Manche Werkzeuge bieten auch die Möglichkeit, Code nicht über die
Templates-Notation, sondern direkt programmatisch -- beispielsweise durch
String-Manipulationen -- zu erzeugen. Vor allem in Systemen ohne
universelles Quasiquote wird diese Hintertür benötigt.

\lsubsection[template:crit:lang]{Metaprogrammiersprache}

Die Bandbreite bei der Sprachmächtigkeit in Unquote-Bereichen ist hoch:
Es gibt Werkzeuge, die überhaupt keine Berechnungen, sondern lediglich das
Einfügen der Parameter zulassen. Auf der anderen Seite stehen
vollständige (Meta-)Programmiersprachen -- Zwischenstufen sind ebenfalls
möglich. Zudem gibt es Unterschiede beim mit einem Metaprogramm
verbundenen Schreibaufwand.

\lsubsection[template:crit:contr]{Aufruf von Templates}

Ein weiterer Unterschied zwischen Code-Generatoren liegt in der Art, ob
und wie Templates selbst andere Templates aufrufen können. Manche
Systeme können nur ein einzelnes Template verarbeiten, so dass alles
weitere in einer externen Programmiersprache festgelegt ist. Engines mit
einer vollständigen Metaprogrammiersprache bieten hingegen oft die
Möglichkeit, programmatisch die Template-Engine selbst und damit
indirekt ein weiteres Template aufzurufen. Andere lassen den direkten
Aufruf weiterer Templates zu. Eine Alternative zur aufrufbasierten
Steuerung ist durch Makros gegeben. Makros sind Templates, die an einen
Knotennamen oder ein Muster gebunden sind. Der Generator entscheidet
dann anhand des Modells, welches Template für die Verarbeitung zuständig
ist.

\lsubsection[template:crit:sep]{Komponententrennung}
Die meisten Software-Systeme lassen sich durch eine
Model-View-Controller-Architektur (MVC) \cite[S.5ff]{DesignPatterns} beschreiben. Daten und deren
Verarbeitung werden vom Modell verwaltet. Ablaufsteuerung und Behandlung
von Benutzerinteraktionen gehören in den Controller. Views sind für die
graphische oder textuelle Formatierung der Modelle zuständig.

Code-Generatoren benötigen normalerweise sehr wenige
Benutzerinteraktionen und haben eine simple Ablaufsteuerung, da diese
lediglich Eingabemodelle in Ausgabemodelle übersetzen. Controller
stellen deshalb meist nur einen kleinen Anteil am Generator. Als Views
können Templates aufgefasst werden, weshalb diese meist den Hauptteil
bilden.

Eine klare Komponententrennung zwischen diesen Bereichen verbessert die
Modularität und somit Übersichtlichkeit, Wartbarkeit und
Aufgabenverteilung innerhalb des Projektes. Deswegen gelten
beispielsweise Views, die komplexe Berechnungen am Modell vornehmen, als
schlechter Stil. Es ist daher von Vorteil, wenn Generatoren eine
Trennung von Model, View und Controller unterstützen oder gar forcieren
-- auf der anderen Seite sollte das Werkzeug aber nicht im Wege stehen, wenn
eine ungewöhnliche Aufgabe andere Mittel erfordert.

\lsubsection[template:crit:gentemp]{Generierung von Templates}

\cgen{} bietet generell die Möglichkeit, eine Programmiersprache um neue
Abstraktionen zu erweitern, indem die neuen Konzepte vom Generator auf
bestehende abgebildet werden. Manchmal ist es aber von Nutzen, die
Metasprache selbst erweitern zu können. Dies lässt sich unter anderem
erreichen, indem der Template-Code selbst generierbar ist.

Manche Engines können nur Code einer speziellen Zielsprache generieren,
die nicht mit der Metasprache übereinstimmt -- hier sind Templates
offensichtlich nicht generierbar. Aber auch Frameworks, die prinzipiell
jede Sprache generieren können, haben oft Probleme, wenn Metasprache und
Zielsprache übereinstimmen. Soll beispielsweise ein Unquote in der
Zielsprache generiert werden, wird es ohne weitere Maßnahmen fälschlich
als Unquote der Metasprache interpretiert werden, was zu einem Fehler
führt. Stattdessen muss dieses Unquote auf eine umständliche Weise,
z.B. durch Escape-Sequenzen, erzeugt werden.

\medskip{}

Im Folgenden werden nun die Template-Prozessoren -- oder mit Templates
verwandten Systeme -- PHP, StringTemplate, \cpp{}, Template Haskell, C, XSL
und Lisp vorgestellt sowie anhand der vorangegangenen Kriterien
eingeordnet und diskutiert.

\lsection[template:php]{PHP}

Die Skriptsprache PHP ist von vornherein als Template-System
konstruiert, womit Code beliebiger Sprachen generiert werden kann. Viele
Web-Frameworks benutzen PHP oder eine PHP ähnelnde Syntax, um Templates
für HTML-Dateien zu beschreiben. Jeder Block PHP-Code muss mit \phpo{}
und \phpc{} umgeben sein, was praktisch ein Unquote darstellt. PHP ist
selbst die -- Touring-vollständige -- Metasprache in diesem
Template-System. Parameter in PHP sind dynamisch typisierte Objekte. Das
Ergebnis der PHP-Blöcke wird als String in die Ausgabedatei eingefügt,
die ansonsten aus den implizit quotierten Nicht-PHP-Bereichen der
Template-Datei besteht. Die Unquote-Syntax ist an XML angelehnt, da PHP
hauptsächlich für die Erzeugung von HTML-Dokumenten verwendet
wird. Statt eines direkten Template-Aufrufs gibt es die Möglichkeit,
über die Funktion \icode{include} eine andere PHP-Datei
einzubinden. Eine Trennung von Model und View wird von PHP nicht
speziell unterstützt oder gefordert, ist aber möglich. Generierung von
PHP-Dateien selbst wird nicht speziell unterstützt und ist deswegen
schwer umzusetzen.

Als Beispiel hier ein PHP-Template, welches HTML-Code für eine
Aufzählungsliste erzeugt:
\begin{DIFnomarkup}\begin{code}
<ul>
<? foreach ($items as $item) {
     echo("<li>" . $item . "</li>");
   }
?>
</ul>
\end{code}\end{DIFnomarkup} %$
Hierbei ist \icode{$items} %$
 der Eingabeparameter, der eine Liste von
Strings enthält.  Aufgrund der fehlenden Möglichkeit zur Schachtelung
von Templates müssen die einzelnen Aufzählungspunkte mit
String-Konkatenation erzeugt werden, was bei einem größeren Beispiel
unübersichtlich werden könnte.

\lsection[template:stringtemplate]{StringTemplate}

StringTemplate \cite{StringTemplate} ist eine string-basierte
Template-Engine für Java. Auch hier ist eine Template-Datei implizit
quotiert, ein Unquote erfolgt mittels \icode{$foo$} oder
\icode{<foo>}. Im Gegensatz zu PHP und den meisten anderen Systemen --
beispielsweise Velocity \cite{Velocity} für Java -- ist
die Mächtigkeit der Unquote-Bereiche in StringTemplate stark reduziert,
um eine Model-View-Trennung zu erzwingen -- alle Berechnungen sollen also
im Modell, und nicht im Template selbst erfolgen.

Neben der Referenzierung von Java-Objekten -- hier wird automatisch
\icode{toString()} aufgerufen -- und deren Instanzvariablen sind nur
Template-Aufrufe sowie \icode{if}-Abfragen erlaubt, wobei letztere nur
zwischen \icode{true} und \icode{false} bzw. \icode{null} und
nicht-\icode{null} unterscheiden können -- aber keine Berechnungen oder
Vergleichsoperatoren benutzen können. "`Anonyme Templates"' (analog zu
anonymen Funktionen) entsprechen einem Quasiquote -- es ist allerdings
auch möglich, extern definierte Templates aufzurufen. Statt der
Bereitstellung eines Konstrukts wie \icode{foreach} iteriert
StringTemplate automatisch, wenn ein referenzierter Wert eine Liste ist
-- dies funktioniert auch bei Template-Aufrufen. Hier kann zusätzlich ein
Separator-String angegeben werden, der dann jeweils zwischen den
Elementen steht. Es gibt auch die Möglichkeit, bei der Verarbeitung
einer Liste abwechselnd zwei oder mehr Templates aufzurufen -- dies wird
beispielsweise für sich abwechselnde Farben von Zeilen in HTML-Tabellen
benötigt.

Der hier verfolgte Ansatz funktioniert in der Praxis wohl sehr gut und
erreicht tatsächlich im Vergleich zu anderen Engines eine sauberere
Aufteilung der Module sowie übersichtlichere und kürzere
Template-Dateien. Der einzige Schwachpunkt tritt auf, wenn Berechnungen
durchgeführt werden müssten, die eigentlich nicht ins Modell, sondern
ins View gehören, wie beispielsweise ein rotes Einfärben von negativen
Werten. Hierfür müsste ein zusätzliches Attribut \icode{isRed} im Modell
bereitgestellt werden, wodurch die Trennung wiederum verletzt wäre. Für
solche Fälle wäre es hilfreich, wenn StringTemplate das Definieren von
Helper-Klassen, deren Methoden aus den Templates aufgerufen werden
können, unterstützen würde.

Die Erzeugung einer HTML-Liste kann in StringTemplate wie folgt aussehen:
\begin{DIFnomarkup}\begin{code}
<ul>
$items:{
  <li> $it$ </li>
}$
</ul>
\end{code}\end{DIFnomarkup} %$
Über die Eingabeliste \icode{items} wird automatisch iteriert und für
jedes Element ein anonymes inneres Template aufgerufen, um den
Listeneintrag zu erzeugen. Da der innere Template-Parameter nicht
benannt wurde, benutzt StringTemplate standardmäßig \icode{it}. 

\lsection[template:ctemp]{Templates in \cpp{}} \cpp{}-Templates bieten
die Möglichkeit, Klassen oder Funktionen unter anderen durch Typnamen zu
parametrisieren, um so generische Konstrukte wie Collection-Klassen
definieren zu können. Die bekannten Java-Generics  \cite{JavaGenerics}
wurden Templates nachempfunden und haben eine ähnliche Syntax -- diese
sind allerdings simpler und weniger mächtig. Templates werden direkt vom
\cpp{}-Compiler ausgewertet, so dass es kein sichtbares oder verfügbares
Ausgabemodell gibt. Neben Typen können auch manche Werte wie Integer
sowie andere Templates übergeben werden. Der Aufruf des Templates
erfolgt durch die Übergabe des konkreten Typnamens oder Wertes in
spitzen Klammern bei Benutzung der entsprechenden Klasse oder
Funktion. Mit \cpp{}-Templates lässt sich sehr viel mehr konstruieren
als lediglich generische Collection-Klassen -- beispielsweise zeigt
\abb{cpp-fibonacci} die Berechnung von Fibonacci-Zahlen zur
Kompilationszeit (übernommen von \cite{CppFib}. Weitere kreative
Verwendungsmöglichkeiten von Templates finden sich in der Bibliothek
Boost \cite{Boost}.
\begin{figure}
  \centering
  \begin{DIFnomarkup}\begin{code}
template<int N> struct fib {
  static const int result = fib<N-1>::result + fib<N-2>::result;
};

template<> struct fib<0> {
  static const int result = 0;
};

template<> struct fib<1> {
  static const int result = 1;
};

// fib<10>::result ergibt 55
  \end{code}\end{DIFnomarkup}
  \caption{Die Fibonacci-Folge mit \cpp{}-Templates}
  \label{magicl:fig:cpp-fibonacci}
\end{figure}
Da aber nur sehr primitive Eingabemodelle zugelassen sind und komplexere
Berechnungen nicht möglich sind, sind andere in diesem Kapitel
vorgestellte Systeme deutlich universeller als \cpp{}-Templates. Eine
Model-View-Trennung ist ebenfalls nicht möglich, ohne komplexe Modelle
aber auch nicht notwendig. Da Aufrufe von Templates über eine spezielle
Syntax erfolgen, handelt es sich hier nicht um Makros. Templates werden
direkt vom Compiler ausgewertet und nicht etwa einem eigenständigen
Präprozessor. Deswegen ist es nicht möglich, Templates selbst zu
generieren.

\lsection[template:temphask]{Template Haskell}

Template Haskell ist eine Compiler-Erweiterung für Haskell, die die
Grundidee von \cpp{}-Templates als "`funktionale
Kompilationszeit-Sprache"' aufgreift und erweitert, um ein sehr
mächtiges System zu erhalten. Eingabemodelle können beliebige
Haskell-Datentypen sein, die Ausgaben einzelner Templates sind Objekte
eines speziellen Datentyps, der Haskell-Code beschreibt. Templates sind
selbst Haskell-Funktionen, so dass Metasprache und generierte Sprache
identisch sind und Templates somit Turing-vollständig und typsicher
sind. In Quelldateien kann Meta-Code mit normalen Code gemischt werden
-- zudem bietet Template Haskell Reifikation, d.h. in Templates können
Meta-Informationen wie Typen über Code in derselben Datei abgefragt
werden, was enorme Möglichkeiten eröffnet.

Da Templates Funktionen sind, können diese komplett programmatisch
erzeugt werden -- deswegen ist auch eine beliebige Modularisierung
möglich. Darüber hinaus gibt es auch Syntax für Quasiquote und Unquote,
wodurch kürzerer und lesbarer Meta-Code ermöglicht wird. Es gibt
verschiedene Quasiquote-Arten für Befehle, Patterns und
Toplevel-Definitionen, wodurch die Typsicherheit verstärkt wird -- dies
bringt allerdings eine höhere Komplexität mit sich. Quotierung und
programmatische Erzeugung können beliebig kombiniert werden. Die
Quelldatei kann als implizit quotiert aufgefasst werden, da überall ein
Unquote benutzt werden kann, um auf die Meta-Ebene zu gelangen. Der
quotierte Bereich wird allerdings übernommen -- schließlich kann auch
"`normaler Code"' von Meta-Code aufgerufen werden, so dass dieser auch
als Meta-Code verwendet werden kann. Wie in \cpp{} werden die Templates
direkt vom Compiler ausgewertet, so dass keine Generierung von Templates
selbst möglich ist.

Ein (inneres) Quasiquote wird in Template Haskell durch \icode{[|} und
  \icode{|]} notiert, ein Unquote durch \icode{$}. %$
Beispielsweise zeigt \abb{ths-summ} ein Template\footnote{Beide
  Beispiele in diesem Abschnitt sind übernommen von \cite{ThsTutorial}}, welches eine anonyme
Funktion mit \icode{n} Parametern erzeugt, welche diese aufsummiert. Das
Beispiel zeigt auch, wie generierte Variablennamen automatisch
nummeriert werden, um Namenskonflikte zu vermeiden.

\begin{figure}[h]
  \centering
\begin{DIFnomarkup}\begin{code}
-- Template-Definition
summ n = summ' n [| 0 |]
summ' 0 code = code
summ' n code = [| \x -> $(summ' (n-1) [|$code+x|] ) |]

-- Aufruf
$(summ 3)  -- ergibt (\x1 -> \x2 -> \x3 -> 0+x1+x2+x3)
\end{code}\end{DIFnomarkup} %$
  \caption{Generierung einer anonymen Funktion mit n Parametern in Template Haskell}
  \label{magicl:fig:ths-summ}
\end{figure}

Das Quasiquote ist allerdings nicht umfassend, es gibt also Templates, die
nur auf programmatische Art erzeugt werden können. Beispielsweise zeigt
\abb{ths-tuple} ein Template, das eine Zahl $n$ als Eingabe bekommt und
den Haskell-Code für ein $n$-äres Tupel mit den Zahlen $1$ bis $n$
zurückliefert. Dieses Template kann nicht mittels Quasiquote implementiert
werden, da Tupel variabler Länge syntaktisch in Haskell selbst nicht
repräsentierbar sind. Zudem muss Code für Literale wie Zahlen typisiert
erzeugt werden, wenn die Zahl selbst nicht vorn vornherein feststeht und
so ein Quasiquote benutzt werden kann. Deswegen muss auf Konstruktoren wie
TupE und LitE zurückgegriffen werden, wodurch die Ähnlichkeit von
Template und generiertem Code verschwindet und die Komplexität leider
deutlich erhöht wird.

\begin{figure}[h]
  \centering
  \begin{DIFnomarkup}\begin{code}
tupleNums n = TupE [LitE (IntegerL i) | i <- [1..n]]

$(tupleNums 5) -- ergibt (1, 2, 3, 4, 5)
  \end{code}\end{DIFnomarkup} %$
  \caption{Generierung von Tupeln dynamischer Länge in Template Haskell}
  \label{magicl:fig:ths-tuple}
\end{figure}

\lsection[template:cprep]{C-Präprozessor}

Der C-Präprozessor, welcher um das Jahr 1973 entwickelt
wurde \cite{CPrep}, wird unter anderem verwendet, um Abhängigkeiten
zwischen Quellcode-Dateien über bedingte Include-Statements zu
verwalten. Er läuft als eigenes Programm vor dem C-Compiler und kann
deshalb auch in Kombination mit anderen Sprachen benutzt werden. Mit
dem Befehl \icode{#define} können Makros auf Textersetzungsbasis sowie
Compiler-Konstanten definiert werden. \abb{c-loop2d} zeigt
beispielsweise ein Makro, mit dessen Hilfe sich zwei verschachtelte
Iterationen über Zahlen komfortabler notieren lassen.
\begin{figure}[h]
  \centering
  \begin{DIFnomarkup}\begin{code}
#define loop2d(xmax, ymax)   \
  for(int x=0; x<xmax; x++)  \
   for(int y=0; y<ymax; y++)

loop2d(2, 3) {
  printf("(%d-%d) ", x, y);
}
// Ergibt "(0-0) (0-1) (0-2) (1-0) (1-1) (1-2) "
  \end{code}\end{DIFnomarkup}
\caption{Ein simples C-Makro für zwei verschachtelte Schleifen}
  \label{magicl:fig:c-loop2d}
\end{figure}
Ein explizites Unquote wird hier nicht benötigt -- stattdessen wird nach
Parameternamen entschieden. Makros auf Textersetzungsbasis ermöglichen
viele zusätzliche Fehlerquellen wie Namenskonflikte. Beispielsweise
funktioniert \icode{loop2d} nicht, wenn es noch andere Variablen
\icode{x} oder \icode{y} gibt, die im Inneren verwendet werden.

Zusätzlich bietet der Präprozessor die Möglichkeit, mittels \icode{#if}
einfache Abfragen auf Compiler-Konstanten wie das Vorhandensein oder
simple, ganzzahlige Berechnungen und Vergleiche durchzuführen und davon
abhängig Zeilen einzubinden oder wegzulassen. Darüber hinaus sind
keinerlei Berechnungen im Präprozessor möglich.

Da es sich um Makros handelt, werden diese Templates nicht über eine
spezielle Syntax aufgerufen -- ein Makro-Aufruf gleicht stattdessen
einem Funktionsaufruf und die Unterscheidung zwischen beiden erfolgt
durch die Prüfung, ob ein Makro dieses Namens vorhanden ist. Dies kann
man sowohl positiv als auch negativ sehen: Meist ist es für einen
Programmierer angenehm, nicht wissen zu müssen, ob ein Befehl ein Makro
oder eine Funktion ist -- insbesondere wenn ein Makro nur aus
Optimierungsgründen existiert, obwohl eine Funktion an der gleichen
Stelle auch ginge. Auf der anderen Seite verschleiern Makros die
Semantik -- wenn ein Programmierer beispielsweise sorglos ein Makro
verwendet im Glauben, es handele sich um eine Funktion, können
unerwartete Fehler wie Namenskonflikte auftreten.

\lsection[template:xsl]{XSL}

Die Extensible Stylesheet Language (XSL) \cite{XSLT} ist eine
Sprachfamilie, mit der XML-Dokumente unter anderem in graphische
Repräsentationen überführt werden können. XSL besteht aus drei
XML-basierten Sprachen:
\begin{itemize}
\item XSL - Formatting Objects (XSL-FO) zur Beschreibung des graphischen Layouts von Seiten
\item XML Path Language (XPath) zum Adressieren von Elementen in XML-Dokumenten
\item XSL Transformation (XSLT) als Transformationssprache für XML-Dokumente
\end{itemize}
XSL-FO spielt für die abstrakte Betrachtung von \cgen{} keine Rolle und
wird hier nicht näher behandelt.

Mit XPath können komfortabel Knotenmengen in XML-Bäumen referenziert
werden. Beispielsweise selektiert der Ausdruck
\icode{//chapter[@title="Einleitung"]/paragraph} alle Elemente mit Namen
\icode{paragraph}, die direkte Kinder eines Elements mit Namen
\icode{chapter} und dem Attribut \icode{title} mit Wert
\icode{Einleitung} sind, wobei der Knoten \icode{chapter} an einer
beliebigen Stelle im Baum stehen darf.

XSLT ist eine Template-basierte Transformationssprache, mit der ein
XML-Dokument in ein anderes überführt werden kann -- wobei reiner
ASCII-Text als ``einelementiger XML-Baum'' ebenfalls erzeugt werden
kann. XSLT ist Turing-vollständig und relativ umfangreich -- so sind
unter anderem Konstrukte zur Iteration, Sortierung und bedingten
Ausführung enthalten. 

Zur Unterscheidung von Metasprache und generiertem Code wird der
Namespace \icode{xsl} benutzt, der somit als Unquote fungiert. Templates
können sowohl direkt als Funktionen aufgerufen werden als auch als Makros,
die über Pfad-Matching dem aktuell zu verarbeitenden Knoten zugeteilt
werden. Ein funktionaler Aufruf erfolgt mit \icode{<xsl:call-template>},
die alternative Kontrollübergabe an den Makro-Prozessor mit
\icode{<xsl:apply-templates/>}. Beides kann allerdings nicht derart
kombiniert werden, dass ein funktional aufgerufenes Template dennoch
über Matcher überprüft ob es auf einen Knoten wirklich anwendbar ist.

\abb{xslt-example} zeigt ein Template, das eine eigene Notation für
Aufzählungslisten in HTML übersetzt.
\begin{figure}
  \centering
  \begin{DIFnomarkup}\begin{code}
Eingabe:
<list>
  <item>foo</item>
  <item>bar</item>
  <item>baz</item>
</list>

Template:
<xsl:template match="/list">
  <ul>
    <xsl:for-each select="item">
      <li><xsl:value-of select="." /></li>
    </xsl:for-each>
  </ul>
</xsl:template>    

Ausgabe:
<ul>
  <li>foo</li>
  <li>bar</li>
  <li>baz</li>
</ul>
  \end{code}\end{DIFnomarkup} %"<
  \caption{Erzeugung einer Aufzählungsliste mit XSLT}
  \label{magicl:fig:xslt-example}
\end{figure}

XSLT ist zwar so mächtig wie Programmiersprachen,
allerdings aufgrund der XML-Syntax mit deutlich mehr Schreibaufwand
verbunden, so dass für komplexe Berechnungen oft auf eine andere Sprache
zurückgegriffen wird. Einige XSLT-Prozessoren bieten dafür die
Möglichkeit, externe Programme aus XSLT-Templates heraus
aufzurufen. Eine Komponententrennung ist ohne diese Möglichkeit
ebenfalls umständlich. Aufgrund der Übereinstimmung von Meta- und
Zielsprache ist eine Generierung von XSLT-Dateien prinzipiell
möglich. Ein Problem ist allerdings wieder die Zuordnung der Unquotes --
um beispielsweise ein \icode{<xsl:apply-templates/>} zu generieren, muss
dieses umständlich entweder in einem CDATA-Abschnitt quotiert oder über
das nachträgliche Ändern des Element-Namespace erzeugt werden.

\lsection[template:lisp]{Lisp}

Lisp ist eine der ältesten Programmiersprachfamilien der Welt, die unter
anderem für ihre Möglichkeiten zur Metaprogrammierung bekannt ist. Neben
alten, aber noch immer benutzten Sprachen wie Emacs Lisp, Scheme oder
Common Lisp entstehen auch immer wieder neue Lisps wie
Clojure \cite{Clojure}, welches auf der Java Virtual Machine (JVM)
aufsetzt. Alle Lisp-Sprachen basieren auf \sexps{} und verzichten auf
die meiste Syntax wie Infix-Operatoren -- gleichzeitig sind \sexps{}
selbst in jedem Lisp als Datenstrukturen verfügbar, so dass jedes
Programm gleichzeitig ein Lisp-Objekt ist und entsprechend manipuliert
werden kann\footnote{Ein C-Programm kann zwar auch ein anderes
  C-Programm als String manipulieren -- dies ist allerdings mit \sexps{},
  die eine innerer Struktur besitzen, deutlich komfortabler als die
  Arbeit mit rohen Strings.}. Diese Eigenschaft sowie die Einfachheit von
\sexps{} selbst machen Lisp für Metaprogrammierung sehr geeignet. Mit
der \icode{eval}-Funktion unterstützt Lisp auch
Laufzeit-Metaprogrammierung, auf die hier nicht näher eingegangen
wird. Denn üblicher ist inzwischen die Benutzung von Makros generative
Metaprogrammierung. Im Folgenden beziehen sich alle
Erklärungen auf die Sprache Common Lisp -- andere Dialekte haben aber
meist ähnliche Konstrukte.

\begin{figure}[h]
  \centering
  \begin{DIFnomarkup}\begin{code}
Einfaches Quasiquote ohne Unquote - ergibt (+ 1 2 3):

 `(+ 1 2 3)


Quasiquote mit Unquote - ergibt (+ 1 7 3) falls x=2:

`(+ 1 ,(+ x 5) 3)


Unquote mit Splicing - ergibt (+ 1 2 3 4 5) falls input = (2 3 4):

`(+ 1 ,@input 5)
  \end{code}\end{DIFnomarkup}
  \caption{Drei Beispiele für Quasiquotes in Common Lisp}
  \label{magicl:fig:lisp-quotes}
\end{figure}

Makros werden mittels \icode{(defmacro ..)} definiert und sind letztlich
Funktionen, die Code als Parameter bekommen und Code (beides als
\sexps{}) zurückliefern. Der Rückgabewert kann sowohl programmatisch als
auch mittels Quasiquote erzeugt werden. Neben dem normalen Unquote gibt
es auch ein Unquote mit "`Splicing"', welches alle Elemente einer Liste
einzeln einfügt. \abb{lisp-quotes} zeigt drei kurze
Verwendungsbeispiele, die alle Code zur Addition mehrerer
Zahlen\footnote{In Lisp ist der Operator \icode{+} nicht binär, sondern
  akzeptiert beliebig viele Argumente. Dies ist ein Vorteil der
  Verwendung von \sexp{}-Syntax anstelle von Infix-Operatoren -- auch
  wenn dies zunächst gewöhnungsbedürftig ist.} generieren.

Mit diesen Operationen können beliebige einzelne \sexps{} erzeugt
werden. Da das Template selbst aus Lisp-Code besteht und auch beliebigen
anderen Lisp-Code aufrufen kann, ist die Metasprache mächtig,
erweiterbar sowie modularisierbar und benötigt vergleichsweise kurze
Metaprogramme.

Lisp-Makros können nicht direkt aufgerufen werden, stattdessen wird ein
\sexp{}-Knoten ähnlich wie bei C nach seinem Knotennamen zu einem Makro
zugeordnet. Es wird also bei jedem Expansionsschritt global geprüft, ob
ein Makro so benannt ist wie das erste Element des zu expandierenden
\sexp{}. Ist dies der Fall, werden die restlichen Elemente als Parameter
an das Makro übergeben, woraufhin der vom Makro zurückgegebene \sexp{}
erneut expandiert wird. Lässt sich kein Makro zu einem Ausdruck
zuordnen, werden alle Elemente davon einzeln expandiert und der
resultierende \sexp{} als Funktionsaufruf interpretiert. Hier stellt
sich wieder die Frage, ob die äußere Ununterscheidbarkeit von Makros und
Funktionsaufrufen eher positiv oder negativ zu sehen ist. Positiv ist,
dass die konkrete Implementation einer \sexp{}-Sprache so versteckt wird
und nachträglich verändert werden kann. Negativ sind unerwünschtes
Verhalten wie Mehrfachevaluation oder Namenskonflikte -- im Gegensatz zu
C stellt Lisp allerdings Möglichkeiten bereit, um diese zu
vermeiden. Beispielsweise kann mit dem \icode{gensym}-Befehl ein global
eindeutiger Variablenname erzeugt werden.

Als Beispiel soll ein Operator \icode{if-not} definiert werden, der
genau andersherum funktioniert wie ein normales \icode{if}. In einer
Sprache wie Java wäre dies überhaupt nicht möglich -- in Lisp reicht ein
Zweizeiler:

\begin{code}
(defmacro if-not (condition false-part &optional true-part)
  `(if ,condition ,true-part ,false-part))

; Aufruf
(if-not (= 4 5) "ungleich" "gleich")  ; ergibt "ungleich"  
(if-not (= 1 1) "ungleich")           ; ergibt nil
\end{code}

Lisp-Makros können immer nur genau einen Ausdruck zurückliefern, weshalb
auch das Quasiquote nur einen \sexp{} erzeugen kann. Sind mehrere
Rückgaben erforderlich, müssen diese in ein \icode{progn} geschachtelt
werden, welches den Lisp-Interpreter\footnote{Es kann sich
  selbstverständlich auch um einen Compiler handeln.} anweist, mehrere
Befehle nacheinander auszuführen. Beispielsweise definiert \\
\icode{define-arithmetic-functions} zwei Funktionen auf einmal:
\begin{DIFnomarkup}\begin{code}
(defmacro define-arithmetic-functions ()
  `(progn (defun add (x y) (+ x y))
          (defun sub (x y) (- x y))))


; Aufruf
(define-arithmetic-functions)
\end{code}\end{DIFnomarkup}

\begin{figure}[h]
  \centering
  \begin{DIFnomarkup}\begin{code}
Definition eines "Meta-Makros":

(defmacro metamacro (name cmd)
  `(defmacro ,name (x)
     `(,',cmd ,x)))    

Beispiel-Aufruf:

(metamacro mymacro print)

Wird kompiliert nach:

(defmacro mymacro (x)
  `(print ,x))
  \end{code}\end{DIFnomarkup}
  \caption{Ein Makro-erzeugendes Makro in Common Lisp}
  \label{magicl:fig:lisp-macrogen}
\end{figure}

Makros können als kleine "`Compiler-Plugins"' aufgefasst werden, mit
denen die Sprache direkt erweitert bzw. DSLs integriert werden
können. Beispielsweise könnte damit ein nach Lisp kompilierendes
Prolog \cite[S.388ff]{NorvigCL} -- selbstverständlich in \sexp{}-Syntax --
konstruiert werden, welches beliebig mit Lisp-Code gemischt werden
kann. Auch Makro-schreibende Makros sind in Lisp möglich -- hier ergibt
sich allerdings wieder das Problem, ob sich ein Unquote auf das innere
oder äußere Quasiquote bezieht. In Common Lisp bezieht sich ein Unquote
immer auf das innerste Quasiquote -- die Aufhebung eines äußeren
Quasiquote ist dagegen sehr trickreich und gewöhnungsbedürftig, wie
\abb{lisp-macrogen} zeigt. Der Lösungsansatz benutzt zwischen zwei
Unquotes ein Quote mit Syntax \icode{'}, welches nicht mit diesen
interagiert.

Da ausschließlich \sexps{} als Rückgabe von Makros möglich sind, kann
mit dem Lisp-Makrosystem zunächst kein Code anderer Programmiersprachen
generiert werden. Allerdings ist es möglich, mit Makros ein
Lisp-Programm zu erzeugen, welches dann den Zielcode generiert.

\lsection[template:sum]{Zusammenfassung und Diskussion}

In dieser Sektion wurde eine Reihe von Template-basierten
Code-Generatoren miteinander verglichen. \abb{comp_sum} zeigt eine
tabellarische Übersicht dieses Vergleichs. 

\begin{sidewaysfigure}[tp]
\subfloat{
\begin{tabular}{|l|l|l|l|l|} \hline
\bf Werkzeug                &\bf PHP                    &\bf C-Makros    &\bf StringTemplate                 &\bf Templates in \cpp{}         \\\hline\hline  
\bf Eingabemodell           &Objekt                     &String          &Objekt als String                  &Typname/Wert/Template           \\\hline                      
\bf Eingabevalidierung      &relativ stark              &schwach         &stark                              &stark                           \\\hline       
\bf Ausgabemodell           &String                     &String          &String                             &Code für Funktion/Klasse        \\\hline     
\bf Ausgabevalidierung      &minimal                    &minimal         &minimal                            &unklar, da Compiler-intern      \\\hline      
\bf Zielsprache             &beliebig                   &beliebig        &beliebig                           &\cpp{}                          \\\hline      
\bf Quasiquote              &implizit                   &\icode{#define} &implizit / \icode{\{args | ..\}}   &\icode{template<args> ..}       \\\hline
\bf Unquote                 &\phpo{}\icode{ .. }\phpc{} &implizit        &\icode{$ .. $} oder \icode{< .. >} &implizit                        \\\hline
\bf universelles Quasiquote &ja                         &nein            &ja                                 &nein                            \\\hline
\bf Code-Objekt verfügbar   &String                     &nein            &nein                               &nein                            \\\hline
\bf Sprachmächtigkeit       &maximal                    &sehr gering     &minimal                            &gering                          \\\hline
\bf Metaprogrammlänge       &relativ kurz               &kurz            &sehr kurz                          &lang                            \\\hline
\bf Template-Aufruf         &nur über Engine-Aufruf     &Makro           &\icode{wert:template(args)}        &\icode{token<args>}             \\\hline
\bf Komponententrennung     &möglich                    &nein            &stark                              &keine                           \\\hline
\bf Template-Generierung    &aufwändig                  &nein            &aufwändig                          &nein                            \\\hline
\end{tabular} 
}\\
\subfloat{
\begin{tabular}{|l|l|l|l|} \hline
\bf Werkzeug                &\bf Template Haskell         &\bf XSLT                    &\bf Lisp              \\\hline\hline    
\bf Eingabemodell           & Objekt                      &XML                         &\sexp{}               \\\hline           
\bf Eingabevalidierung      & stark                       &mittel                      &mittel                \\\hline      
\bf Ausgabemodell           & Code als Objekt             &XML                         &\sexp{}               \\\hline      
\bf Ausgabevalidierung      & stark                       &mittel                      &mittel                \\\hline      
\bf Zielsprache             & Haskell                     &besliebig                   &Lisp                  \\\hline      
\bf Quasiquote              & implizit /\icode{[| .. |]}  &\icode{<xsl:template> ..}   &\icode{`( .. )}       \\\hline   
\bf Unquote                 & \icode{$( .. )}             &über \icode{xsl}-Namespace  &\icode{, .. }         \\\hline %$
\bf vollständiges Quasiquote& nein                        &ja                          &nur genau ein Ausdruck      \\\hline      
\bf Code-Objekt verfügbar   & ja                          &nein                        &ja                    \\\hline      
\bf Sprachmächtigkeit       & maximal                     &maximal                     &maximal               \\\hline      
\bf Metaprogrammlänge       & relativ kurz                &sehr lang                   &kurz                  \\\hline
\bf Template-Aufruf         & Funktion                    &Funktion / Makro            &Makro                 \\\hline      
\bf Komponententrennung     & möglich                     &umständlich                 &möglich               \\\hline      
\bf Template-Generierung    & nein                        &aufwändig                   &etwas kompliziert     \\\hline      
\end{tabular}
}
\caption{Vergleich der Verarbeitungsprozesse von Werkzeugen zur Code-Generierung}
\label{magicl:fig:comp_sum}
\end{sidewaysfigure}

String-basierte Systeme sind vermutlich am einfachsten in der Benutzung
und unterstützen direkt ohne Zusatzaufwand jede Zielsprache --
andererseits sind sie für die Vermeidung von Syntaxfehlern
ungeeignet. Während PHP eine mächtige Meta-Sprache bietet, erzwingt
StringTemplate eine starke Komponententrennung durch Reduzierung
dieser. C-Makros besitzen nur wenige Features, bieten aber als
Makro-System direkte, von Funktionen äußerlich ununterscheidbare
Spracherweiterungen -- auch wenn diese Gefahren wie Namenskonflikte mit
sich bringen.

\cpp{}-Templates sowie Template Haskell erweitern die Compiler je einer
Sprache um die Möglichkeit von Template-Aufrufen über eine spezielle
Syntax. Während Metasprache und Einsatzmöglichkeiten in \cpp{} recht
eingeschränkt sind, besitzt Template Haskell die komplette Sprachmächtigkeit
von Haskell -- ergänzt um die Möglichkeit, über Reifikation
Meta-Informationen über Quellcode derselben Datei abzufragen. Template
Haskell erzeugt aufgrund der starken Typisierung garantiert Code, der
frei von Syntaxfehlern ist -- dies hat allerdings zum Preis, dass nicht
jedes Template durch die verschiedenen Quasiquotes ausdrückbar ist, was
die Lesbarkeit des Meta-Codes senkt.

XSLT und Lisp arbeiten auf untypisierten Baumstrukturen und bieten so
einen Kompromiss zwischen Flexibilität und Typsicherheit. In beiden
Systemen ist die Metasprache selbst ebenfalls auf diese Weise
repräsentiert, wodurch die Möglichkeit zur Generierung und somit auch
Erweiterung der Metasprache selbst gegeben ist. Die Generierung von
Quasiquotes bringt allerdings das generelle Problem der Zuordnung eines
inneren Unquotes mit sich. In XML kann dieses nur umständlich erreicht
werden, während die Lisp-Lösung sehr kurz, aber etwas kompliziert
ist. Während XSLT neben XML auch beliebige ASCII-Formate ausgeben kann,
beschränkt sich der Lisp-Makroprozessor auf \sexps{}. Beide Frameworks
haben eine Turing-vollständige Metasprache. Komplexe Algorithmen lassen
sich in XSLT allerdings aufgrund der umständlichen Syntax nur mühsam
ausdrücken, so dass für diese meist auf eine externe Programmiersprache
zurückgegriffen wird. Lisp-Programme dagegen sind oft kurz und
elegant. Makro-gesteuerte Template-Aufrufe sind ebenfalls in beiden
Systemen möglich, wobei XSLT komplexere Patterns sowie alternativ
funktionale Makro-Aufrufe unterstützt. Ein weiterer Unterschied ist der
Aufwand für eine neue Spracherweiterung: In XSLT muss dafür eine eigene
Template-Datei mitsamt zusätzlichem Kompilationsaufruf angelegt
werden. Lisp dagegen erlaubt sogar die direkte Mischung von Makros und
Code, wodurch praktisch Compiler-Plugins mit minimalem Aufwand erzeugt
werden können. Dadurch lassen sich in Lisp leicht mächtige, voll
integrierte DSLs konstruieren.

Allgemein wächst der Aufwand für \cgen{} mit der Komplexität des
Ausgabemodells. Soll die Generierung typsicher sein, ist das Modell
desto umfangreicher, je aufwändiger die Syntax der zu generierenden
Sprache ist. Obwohl beispielsweise Haskell im Vergleich zu Sprachen wie
\cpp{} bereits eine sehr einfache Syntax besitzt, erweist sich diese für
Template-Haskell bereits als Problem, da nicht alles auf den
Quasiquote-Operator abgebildet werden kann. In einer String-basierten
Generierung von Haskell-Code wäre die Flexibilität größer, so dass hier
ein entsprechendes Quasiquote möglich gewesen wäre -- zum Preis von
möglichen Syntaxfehlern und verschleierter Struktur.

Ein Mittelweg wäre eine \sexp{}-Syntax für Haskell, die vom Framework
zunächst in eine typisierte Repräsentation überführt und daraufhin zur
Generierung verwendet wird. Diese Variante hätte folgende Vorteile:
\begin{itemize}
\item Das Ausgabemodell von Templates ist einfach, aber explizit
  strukturiert.
\item Quasiquotes können für jedes Template benutzt werden.
\item Es kann kein Code mit Syntaxfehlern erzeugt werden, da das
  \sexp{}-Modell bei der Umwandlung in ein typisiertes Objekt
  validiert wird.
\end{itemize}
Wenn nun standardmäßig die \sexp{}-Notation verwendet wird, ist auch
weiterhin die Metasprache mit der Zielsprache identisch. Dieser Ansatz
wird in \cref{sexphs} weiter verfolgt.

\lchapter[reqs]{Anforderungen}

Grundsätzlich soll mit MagicL ein sprachunabhängiges Framework für
generative \mprog{} entwickelt werden, das eine an Lisp angelehnte,
modulare und inkrementelle Compiler-Entwicklung durch kurzen und
prägnanten Meta-Code unterstützt. Zudem sollten allgemein eine möglichst
hohe Flexibilität und Einfachheit angestrebt werden.

Diese Grundanforderungen werden nun in Hinblick auf die Kriterien aus
\cref{template} konkretisiert.

\lsection[reqs:model]{Modelle}

Um sprachunabhängig zu sein, sollten beliebige Ein- und Ausgabesprachen
wie XML oder Java unterstützt werden. Da diese nicht alle von vornherein
Teil von MagicL selbst sein können, muss es dem Meta-Programmierer
möglich sein, selbst entsprechende Parser oder Generatoren in MagicL zu
definieren. Der Modelltyp String muss also in Form von Parser- und
Generator-Bibliotheken hinreichend unterstützt werden. Andererseits
sollten Zeichenketten nur ganz am Anfang oder Ende der
Verarbeitungskette liegen und im Idealfall -- wenn sprachspezifische
Backends bereits bestehen -- überhaupt nicht vom Meta-Programmierer
berührt werden. Stattdessen sollten möglichst viele
Verarbeitungsschritte strukturierte Modelle benutzen. 

Für typisierte Objekte spricht das automatische Finden von Fehlern
bereits während der Kompilation des Generators, wohingegen diese bei
einer Verarbeitungskette mit untypisierten Zwischenmodellen erst im
nächsten Schritt sichtbar werden -- oder gar noch später,
falls dieser unvorsichtig implementiert wurde. Für umfangreiche
Berechnungen sind typisierte Datenstrukturen generell
von Nöten. Modelldefinitionen mit Typsignaturen sind außerdem bereits zu
einem gewissen Grad selbstdokumentierend.

\sexps{} hingegen sind allgemein flexibler und ersparen die Phase der
Modellerstellung. Dies ist besonders dann von Vorteil, wenn eine
bestehende Modellsprache nur geringfügig erweitert oder angepasst werden
soll, so dass ein komplett neues, fast identisches Modell einen
übertriebenen Arbeitsaufwand bedeuten würde. Auch können \sexps{} ohne
weiteren Aufwand in Zeichenketten serialisiert und so zwischen
verschiedenen Programmen oder über das Netzwerk kommuniziert
werden. Zudem lassen sich Modelle in \sexps{} oft kürzer und
redundanzfreier notieren als in einer typisierten Form.

Da sowohl Objekte als auch \sexps{} in bestimmten Anwendungsfällen von
Vorteil sind, sollte MagicL beide Formen unterstützen. Auch die
einfache Umwandlung von einer Repräsentation in die andere sollte
möglich sein. DSLs werden dann üblicherweise in \sexps{}
repräsentiert, Modelltypen für die weitere Verarbeitung können variiert
werden.

Der verwendete \sexp{}-Datentyp sowie die konkrete Syntax sollten
zunächst möglichst einfach und domänenunabhängig gehalten werden,
weshalb beispielsweise auf eine automatische Typisierung beim Einlesen
von Zahlen verzichtet wird. Auch spezielle Syntax für Strings,
Kommentare, Quasiquotes oder Leerzeichen in Symbolnamen wird zunächst
nicht für nötig befunden, da auch dies alles bereits mittels primitiver
\sexps{} repräsentiert werden kann. Für den Fall, dass besondere Syntax
für einzelne Anwendungen dennoch erwünscht sein sollte, könnte diese
beispielsweise über einen Präprozessor in die entsprechende
\sexp{}-Darstellung überführt werden. Eine weitere Überlegung ist, ob der
\sexp{}-Datentyp eine "`kanonische Form"' erzwingen soll, bei der das
erste Element eines Knotens immer der Knotenname ist, indem ein
gesondertes Datenfeld für den Namen angelegt wird. Eine derartige Form
wäre analog zu XML, wo der Name ebenfalls einzeln behandelt wird. Zudem
wird die Semantik von \sexps{} so klarer und eine automatische
Visualisierung als Baum oder mittels Einrückung sinnvoller.  Wird hier
allerdings festgelegt, dass es sich bei diesen Namen ausschließlich um
Symbole handeln muss, werden die möglichen Modellierungssprachen unnötig
eingeschränkt. Beispielsweise könnte eine funktionale Programmiersprache
einen \sexp{} als Funktionsaufruf in Präfixnotation interpretieren und
die Möglichkeit zulassen wollen, die aufgerufene Funktion selbst durch
einen Funktionsaufruf zu erzeugen. Werden aber beliebige \sexps{} als
Namen zugelassen, ist der "`Missbrauch"' für nichtkanonische Strukturen
dennoch möglich -- wenn auch etwas aufwändiger. Generell wird die
Verarbeitung von \sexps{} durch das Sonderfeld allerdings komplexer,
weshalb die einfache Struktur bevorzugt wird: Ein \sexp{} ist entweder 
\begin{itemize}
\item ein Symbol oder 
\item eine Liste von \sexps{}.
\end{itemize}
Die Konvention, das erste Element als Knotennamen anzusehen, ist dennoch
sinnvoll und wird von MagicL vorausgesetzt.

\lsection[reqs:template]{Templates}

Templating in MagicL soll ähnlich aussehen wie in Lisp,
d.h. \sexp{}-basiert mittels Makros und Quasiquotierung. Wie in
\sref{template:lisp} diskutiert wurde, kann ein Lisp-Makro aber nur
mehrere Ausdrücke gleichzeitig zurückgeben, indem es diese in ein
\icode{progn} schachtelt. Dies funktioniert aber nicht für Zielsprachen
ohne einen Konstrukt wie \icode{progn}. Daher sollten MagicL-Makros und
der Quasiquote-Operator direkt mehrere Rückgaben ermöglichen,
welche vom Makrosystem durch Splicing eingefügt werden.

\lsection[reqs:metalang]{Meta-Programmiersprache}

Die bereitgestellte Meta-Programmiersprache sollte einfach und mächtig
sein. Da MagicL in Haskell geschrieben wird, ist eine Verwendung von
Haskell auch als Meta-Sprache naheliegend. Allerdings ist Haskell nicht
\sexp{}-basiert, so dass es ohne weiteres nicht in reinen
\sexp{}-Templates verwendet werden kann. Aus diesem Grund muss mit
\sexp{}-Haskell eine \sexp{}-Syntax für Haskell bereitgestellt werden,
die automatisch nach Haskell kompiliert wird. Daher muss MagicL selbst
bereits generative Meta-Programmierung betreiben.

\lsection[reqs:call]{Aufruf von Templates}

Makros in MagicL sollen wie in Lisp implizit über den Knotennamen
zugeordnet werden können. Allerdings wäre es interessant, wenn nicht nur
der Name, sondern der gesamte Knoten in einer Art Pattern-Matching
ähnlich XPath berücksichtigt werden könnte. Auch eine mit EBNF
\cite[S.43f]{EBNF} vergleichbare Grammatik auf \sexps{} wäre
wünschenswert. 

Der Kontrollfluss im Lisp-Makrosystem ist relativ unflexibel,
da lediglich eine globale Zuordnung von Namen zu Makros
besteht\footnote{Es gibt in Lisp zwar die Möglichkeit, Makros mittels
  \icode{macrolet} nur für einen bestimmten lexikalischen Skopus
  verfügbar zu machen, innerhalb dieses Bereichs ist das Makro dann
  allerdings nur Teil der globalen Liste, so dass ohne Weiteres keine
  feinere Steuerung möglich ist.}. In konkreten Sprachen hingegen gibt
es häufig Konstrukte, die nur im Kontext bestimmter Oberkonstrukte
verwendet werden können. Lisp-Makros, die solche Oberkonstrukte
verarbeiten, benutzen für die Unterkonstrukte keine weiteren Makros --
sonst wären die Konstrukte auch außerhalb verfügbar -- sondern zerlegen
die inneren \sexps{} manuell. Praktischer wäre ein Konzept von "`lokalen
Makros"', die nur an gewünschten Stellen aufgerufen werden. Dies ist
vergleichbar mit dem Aufruf von XSLT-Templates über Namen -- im Gegensatz
zu diesen sollte aber auch ein lokal aufgerufenes Makro seine
Anwendbarkeit durch Pattern-Matching überprüfen und im Falle eines
Scheiterns den Kontrollfluss an das nächste Lokalmakro weiterreichen.

Damit dies alles möglich wird, muss der Begriff ``Makro'' gegenüber Lisp
sinnvoll und theoretisch fundiert verallgemeinert werden, wofür einige
Grundlagenarbeit benötigt wird.

\lsection[reqs:sep]{Komponententrennung}

MagicL soll einen minimalen und modularen Entwurf von Compilern
unterstützen, um maximale Wiederverwendbarkeit von Komponenten und
minimalen Entwicklungsaufwand für neue DSLs zu ermöglichen. Daher müssen
verschiedene Parser, Compiler oder Generatoren einfach
hintereinandergeschaltet werden können, wofür eine allgemeine
Schnittstelle benötigt wird.

\lsection[reqs:gentemp]{Generierung von Templates}

Das Hauptproblem bei der Generierung von Templates aus Templates ist die
Uneindeutigkeit bei der Zuordnung eines inneren Unquote. In Common Lisp
müssen in diesem Fall daher komplizierte Konstrukte wie \icode{,',}
verwendet werden \sees{template:lisp}. 

Eine einfache Alternative hierzu ist die Bereitstellung verschieden
benannter Quote-Unquote-Paare, so dass sich nur noch eine
Zuordnungsmöglichkeit innerer Unquotes ergibt\footnote{Eine ähnliche
  Erweiterung hat Drew McDermott für Common Lisp implementiert
  \cite[S.21ff]{YTools}.}. Dies soll MagicL realisieren.

\lsection[reqs:sum]{Zusammenfassung}

\begin{figure}[h]
\begin{tabular}{|l|l|l|} \hline
\bf Werkzeug                 & \bf MagicL                    & \bf Lisp               \\\hline\hline    
\bf Eingabemodell            & \sexp{} / beliebig            & \sexp{}                \\\hline           
\bf Eingabevalidierung       & beliebig                      & mittel                 \\\hline      
\bf Ausgabemodell            & \sexp{} / beliebig            & \sexp{}                \\\hline      
\bf Ausgabevalidierung       & beliebig                      & mittel                 \\\hline      
\bf Zielsprache              & beliebig                      & Lisp                   \\\hline      
\bf vollständiges Quasiquote & ja                            & nur genau ein Ausdruck \\\hline      
\bf Code-Objekt verfügbar    & ja                            & ja                     \\\hline      
\bf Sprachmächtigkeit        & maximal                       & maximal                \\\hline      
\bf Metaprogrammlänge        & kurz                          & kurz                   \\\hline
\bf Template-Aufruf          & verallgemeinertes Makro       & Makro                  \\\hline      
\bf Komponententrennung      & unterstützt                   & möglich                \\\hline      
\bf Template-Generierung     & einfach                       & etwas kompliziert      \\\hline      
\end{tabular}
\caption{Anforderungen an MagicL im Vergleich zu Lisp}
\label{magicl:fig:reqs_sum}
\end{figure}

Das zu entwickelnde \cgen{}sframework soll eine makrobasierte,
baukastenartige Konstruktion von Compilern ähnlich Lisp ermöglichen,
dabei allerdings beliebige Zielsprachen unterstützen. Alle drei
erwähnten Modelltypen müssen in MagicL unterstützt werden: Interne DSLs
und Templating sollten ausschließlich auf \sexps{} basieren. Externer
Formate müssen dank integrierter Parser- und Generatorbibliotheken für
Zeichenketten einfach eingelesen und erzeugt werden können. Für komplexe
Algorithmen sollten typisierte Objekte verwendet werden können. Diese
verschiedenen Komponenten müssen durch eine allgemeine Schnittstelle
einfach hintereinandergeschaltet werden können.

Damit keine zusätzliche Syntax zu reinen \sexps{} erforderlich wird,
muss die Syntax von Quasiquote und Unquote gegenüber Lisp leicht
verändert werde. Zudem soll es möglich sein, eine beliebige Anzahl
\sexp{} zu quotieren, für die das Makrosystem automatisch ein Splicing
vornimmt. Darüber hinaus sollten mehrere verschieden benannte
Quote-Unquote-Paare bereitgestellt werden, um Template-generierende
Templates zu vereinfachen. Als Meta-Sprache soll eine \sexp{}-Version
von Haskell und damit eine vollständige Programmiersprache
angeboten werden.

Dazu soll der Makro-Begriff gegenüber Lisp verallgemeinert werden, so
dass die Zuordnung zu einem Makro nicht nur über den Knotennamen,
sondern durch beliebiges Pattern-Matching oder gar eine EBNF-ähnliche
Grammatik erfolgen kann. Auch soll es möglich sein, lokale Makros zu
definieren, die nur im Kontext eines anderen Makros aktiv sind.  

Die verallgemeinerten Makros sollten hinreichend theoretisch fundiert
werden. Dies wird durch eine Einbettung in die Kategorientheorie
erreicht, welche im folgenden Kapitel zunächst vorgestellt wird.

\lchapter[cats]{Kategorientheorie}

Die Kategorientheorie ist ein sehr abstrakter Zweig der Mathematik --
aber auch ein universeller, denn fast alle wichtigen mathematischen
Strukturen sind Kategorien. Kategorientheorie findet dank seiner
Allgemeinheit und Anwendbarkeit für Berechnungen auch in der Informatik
eine immer größer werdende Rolle -- unter anderem da sie eine generische
Schnittstelle für die Verschaltung beliebiger Verarbeitungsprozesse
liefert. Hierfür wird der Kompositionsoperator von Funktionen auf
beliebige Datentypen, welche Prozesse beschreiben, verallgemeinert.

Die Sprache Haskell benutzt kategorientheoretische Konzepte, um
Nebeneffekte elegant in eine ansonsten pur funktionale Sprache zu
integrieren. Die Architektur von MagicL basiert komplett auf der
Haskell-Umsetzung kategorientheoretischer Konstrukte -- beispielsweise
werden Parser als zusammengesetzte Funktoren konstruiert. Auf diese
Weise wird eine hohe Flexibilität, Eleganz, Modularität und
Wiederverwendbarkeit von Komponenten wie Parsern, Compilern oder Makros
erreicht.

Dieser Abschnitt führt in die Kategorientheorie ein und
stellt alle später verwendeten Konzepte vor. Die Definitionen sind
weitgehend aus \cite{Grundlagen} übernommen.

\lsection[cats:intro]{Einführung}

\fig{cat_funs}{Ein simples Funktionensystem}

Der Grundansatz der Kategorientheorie ist die Verallgemeinerung der
Art und Weise, wie mit Funktionstypen gerechnet wird -- insbesondere
hinsichtlich der Komposition von Funktionen. \abb{cat_funs} zeigt ein
kleines Funktionensystem zwischen den Mengen $\mathbb{R} \times
\mathbb{R}$, $\mathbb{R}$ und $\mathbb{Z}$. Es kommen folgende
Funktionen vor:
\begin{itemize}
\item $+ : \mathbb{R} \times \mathbb{R} \ato \mathbb{R}$ addiert zwei
  reelle Zahlen.
\item $\mathrm{round} : \mathbb{R} \ato \mathbb{Z}$ ist die
  Rundungsfunktion.
\item $+1 : \mathbb{Z} \ato \mathbb{Z}$ addiert $1$ zu einer ganzen Zahl.
\item $\mathrm{round} \circ + : \mathbb{R} \times \mathbb{R} \ato \mathbb{Z}$
  addiert zwei reelle Zahlen und rundet anschließend.
\end{itemize}

Die Komposition $\mathrm{round} \circ +$ (gesprochen "`round \textit{nach}
+"') lässt sich bilden, weil der Definitionsbereich von $\mathrm{round}$
mit dem Zielbereich von $+$ übereinstimmt (nämlich $\mathbb{R}$). Es
lassen sich also zwei im Diagramm aufeinander folgende Pfeile zu einem
direkten zusammenfassen. Die Kategorientheorie "`vergisst"' nun den
Bezug zu Mengen und Funktionen und arbeitet stattdessen mit Objekten
und Morphismen, welche vollkommen abstrakt definiert sind und mit
bestimmten Operationen eine Kategorie bilden.

\lsection[cats:cat]{Kategorien}

\defi{Kategorie}{
Eine Kategorie $\mathbf{C} = (\mathrm{Ob}^\mathbf{C}, \mathrm{Mor}^\mathbf{C},
\circ^\mathbf{C}, \mathrm{id}^\mathbf{C})$ ist gegeben durch
\begin{itemize}
\item eine Klasse $\mathrm{Ob}^\mathbf{C}$ von Objekten\footnote{Da Objekte selbst Mengen
    sein können, wäre eine Definition von $\mathrm{Ob}^\mathbf{C}$ als Menge problematisch.}.
\item eine Menge Morphismen $\mathrm{Mor}^\mathbf{C}_{A,B}$ für alle $ A,B \in
  \mathrm{Ob}^\mathbf{C}$, wobei $A$ und $B$ Domäne und Codomäne genannt werden,
\item einen Kompositionsoperator $\circ^\mathbf{C}_{A,B,C}$ für alle $
  A,B,C \in \mathrm{Ob}^\mathbf{C}$ mit \\
  $\circ^\mathbf{C}_{A,B,C} : \mathrm{Mor}^\mathbf{C}_{B,C} \times
  \mathrm{Mor}^\mathbf{C}_{A,B} \rightarrow \mathrm{Mor}^\mathbf{C}_{A,C}$,
\item eine Identität $\mathrm{id}^\mathbf{C}_A \in \mathrm{Mor}^\mathbf{C}_{A,A}$ für alle $ A \in \mathrm{Ob}^\mathbf{C}$,
\end{itemize}
wobei folgende Axiome erfüllt sein müssen:
\begin{itemize}
\item Neutralität der Identität: $$f \circ_{A,A,B} \mathrm{id}_A = \mathrm{id}_B \circ_{A,B,B} f = f$$
\item Assoziativität:
  $$f \circ_{A,C,D} (g \circ_{A,B,C} h) = (f \circ_{B,C,D} g) \circ_{A,B,D}h$$
\end{itemize}
}

\fig{cat_potence}{Eine von einer Potenzmenge gebildete Kategorie}

Indizes und Kategorien werden der Einfachheit halber weggelassen, wenn
sie aus dem Kontext hervorgehen. Wie von Funktionen gewohnt, lässt sich
$f \in \mathrm{Mor}_{A,B}$ auch schreiben als $f : A \ato B$. Sind $A$
und $B$ identisch, bezeichnet man f auch als Endomorphismus.

Wie das Einführungsbeispiel erwarten lässt, bilden Mengen und darauf
definierte Funktionen Kategorien. Die Kategorie, die alle denkbar
möglichen Mengen und Funktionen enthält, heißt $\mathbf{Set}$. Das
Einführungsbeispiel skizziert somit unvollständig eine Unterkategorie
von $\mathbf{Set}$. Es gibt allerdings durchaus auch andere Kategorien --
beispielsweise können alle Mengen einer Potenzmenge als Objekte und die
Teilmengenbeziehungen als Morphismen benutzt werden. \abb{cat_potence}
zeigt solch eine Potenzmengenkategorie über $\{1,2,3\}$, wobei die
Kompositionen nicht mit eingezeichnet sind. Im Folgenden wird die
konkrete Bedeutung einer Kategorie nicht näher betrachtet.

\fig{cat_simple}{Eine einfache vollständige Kategorie}

\abb{cat_simple} zeigt eine simple, vollständig eingezeichnete
Beispielkategorie $\mathbf{C}$, die aus den Objekten $A, B$ und den
Morphismen $f, g, \mathrm{id}_A, \mathrm{id}_B$ besteht. Alle
Kompositionen davon sind wieder einer dieser vier Morphismen -- ansonsten
wäre die Kategorie nicht unter Komposition geschlossen (und damit keine
Kategorie).

Wie in diesen Beispielen lassen sich Kategorien in Diagrammen
visualisieren, indem sie wie Multigraphen, also Graphen mit mehr als
einer möglichen Kante zwischen zwei Knoten, gezeichnet werden. Formal
sind allerdings nicht alle Kategorien Multigraphen, da letztere eine
Menge von Knoten, Kategorien jedoch eine Klasse von Objekten besitzen.

\fig{cat_comp}{Das Assoziativitätsaxiom als kommutatives Diagramm}

Ergeben alle in einem Diagramm möglichen Pfade zwischen je zwei Objekten
denselben Morphismus, wird das Diagramm als kommutativ bezeichnet:
\defi{Kommutatives Diagramm}{ Ein Diagramm kommutiert, wenn für je zwei
  eingezeichnete Pfade $f=f_1 \circ \cdots \circ f_n : A \rightarrow B$
  und $g=g_1 \circ \cdots \circ g_n : A \rightarrow B$ zwischen zwei
  Objekten $A$ und $B$ die Gleichung $f=g$ gilt.  }
Beispielsweise zeigt \abb{cat_comp} das Assoziativitätsaxiom als
kommutatives Diagramm. $g$ ist nur der Vollständigkeit halber
eingezeichnet und spielt für das kommutative Diagramm selbst keine
Rolle. Dieses Diagramm dient der Veranschaulichung, kann aber nicht für
die Definition der Assoziativität genutzt werden -- schließlich setzt die
Definition kommutativer Diagramme bereits Assoziativität von $\circ$
voraus.

\lsection[cats:prod]{Produkte und Coprodukte}

Die Kategorientheorie schafft es, Begriffe für Funktionseigenschaften
wie Injektivität sowie Mengenoperationen wie das kartesische Produkt auf
Kategorien zu verallgemeinern, indem sich die neuen Definitionen
ausschließlich auf Objekte und Morphismen beziehen und nicht von Mengen
oder Funktionen im speziellen Gebrauch machen. In der Kategorie
$\mathbf{Set}$ stimmen die neuen Begriffe dann genau mit den alten
überein. Dem kartesischen Produkt entspricht das Produkt von Objekten:

\defi{Produkt}{ Ein Objekt $A \times B$ mit zwei Projektionsmorphismen
  $\pi_1 : A \times B \ato A$ und $\pi_2 : A \times B \ato B$ ist ein
  Produkt von $A$ und $B$, wenn für jedes $X \in \mathrm{Ob}$ sowie für
  alle $f : X \ato A$ und alle $g : X \ato B$ genau ein Morphismus
  $\langle f,g \rangle : X \ato A \times B$ existiert, für den
  \abb{cat_product} kommutiert, d.h.  $\pi_1 \circ \langle f,g \rangle =
  f$ und $\pi_2 \circ \langle f,g \rangle = g$ gelten.}

\begin{figure}[h]
  \centering
  \subfloat[Produkt]{
    \includegraphics[scale=0.3]{images/cat_product}
    \label{magicl:fig:cat_product}
  }
  \subfloat[Coprodukt]{
    \includegraphics[scale=0.3]{images/cat_coproduct}
    \label{magicl:fig:cat_coproduct}
  }
  \caption{Kommutative Diagramme zur Definition von Produkt und Coprodukt}
\end{figure}

Man kann leicht nachvollziehen, dass das kartesische Produkt genau ein
Produkt für die Kategorie $\mathbf{Set}$ ist. $\langle f,g \rangle$ ist
hier die Funktion, die $x$ auf das Tupel $(f(x), g(x))$ abbildet.

Dreht man im Diagramm alle Pfeile um\footnote{Formal wird durch das
  ``Umdrehen'' aller Morphismen in $\mathbf{C}$ die duale Kategorie
  $\mathbf{C}^{\mathrm{op}}$ erzeugt. Entsprechend ist das Coprodukt der
  zum Produkt duale Operator.}, erhält man die Definition für das
Coprodukt:

\defi{Coprodukt}{ Ein Objekt $A + B$ mit zwei Injektionsmorphismen
  $\iota_1 : A \ato A + B$ und $\iota_2 : B \ato A + B$ ist ein
  Coprodukt von $A$ und $B$, wenn für jedes $X \in \mathrm{Ob}$ sowie
  alle $f : A \ato X$ und alle $g : B \ato X$ genau ein Morphismus
  $[f,g] : A + B \ato X$ existiert, für den \abb{cat_coproduct}
  kommutiert, d.h.  $[f,g] \circ \iota_1 = f$ und $[f,g] \circ \iota_2 =
  g$ gelten.  }

Das Coprodukt entspricht einer disjunkten Vereinigung von Mengen, also
einer Vereinigung von Mengen, die vorher explizit disjunkt gemacht
werden (sofern sie es nicht bereits sind). Dies kann beispielsweise durch
die Indizes $L$ und $R$ geschehen: $\{1,2,3\} + \{2,3,4\} =
\{1_L,2_L,3_L,2_R,3_R,4_R\}$. Der Morphismus $[f,g]$ entspricht einer
Fallunterscheidung: Auf Elemente aus $A$ wird $f$ angewendet, auf welche
aus $B$ entsprechend $g$.

\lsection[cats:func]{Funktoren}

Strukturerhaltende Abbildungen zwischen Objekten und Morphismen zweier
Kategorien werden Funktoren genannt:

\defi{Funktor}{
Ein Funktor $F=(F_{\mathrm{Ob}},F_{\mathrm{Mor}}) : \mathbf{C}
\rightarrow \mathbf{D}$ von Kategorie $C$ nach Kategorie $D$
    \begin{itemize}
    \item bildet jedes Objekt $A \in \mathrm{Ob}^{\mathbf{C}}$ auf $F_{\mathrm{Ob}}(A) \in
      \mathrm{Ob}^{\mathbf{D}}$ ab,
    \item bildet jeden Morphismus $f \in
      \mathrm{Mor}^{\mathbf{C}}_{A,B}$ auf $F_{\mathrm{Mor}}(f) \in
      \mathrm{Mor}^{\mathbf{D}}_{F_{\mathrm{Ob}}(A),F_{\mathrm{Ob}}(B)}$
      ab,
    \end{itemize}
    wobei für alle $A,B,C \in \mathrm{Ob}^{\mathbf{C}}$ und alle $f \in
    \mathrm{Mor^{\mathbf{C}}_{B,C}},g \in
    \mathrm{Mor^{\mathbf{C}}_{A,B}}$ folgende Axiome erfüllt sein
    müssen:
    \begin{itemize}
    \item Erhaltung der Komposition:
      $$F_{\mathrm{Mor}}(f \circ^{\mathbf{C}} g) =
      F_{\mathrm{Mor}}(f) \circ^{\mathbf{D}} F_{\mathrm{Mor}}(g)$$
    \item Erhaltung der Identität:
      $$F_{\mathrm{Mor}}(\mathrm{id}^{\mathbf{C}}_A) =
      \mathrm{id}^{\mathbf{D}}_{F_{\mathrm{Ob}}(A)}$$
    \end{itemize}
}

Statt $F_{\mathrm{Ob}}$ und $F_{\mathrm{Mor}}$ kann einfach $F$
geschrieben werden, wenn aus dem Kontext hervorgeht welche Abbildung
gemeint ist.

Kategorien als Objekte und Funktoren als Morphismen ergeben selbst
wieder eine Kategorie, die Kategorie der kleinen Kategorien. Kleine
Kategorien sind Kategorien, deren Klasse von Objekten eine Menge
ist. Diese Einschränkung ist nötig, da Klassen von Klassen in der
Mathematik ähnlich problematisch sind wie Mengen von Mengen.

\lsection[cats:nats]{Natürliche Transformationen}

Eine andere Möglichkeit, aus Funktoren eine Kategorien zu bilden,
besteht darin, diese als Objekte zu benutzen. Alle Funktoren $\mathbf{C}
\ato \mathbf{D}$ als Objekte bilden die sogenannte Funktorkategorie über
$\mathbf{C}$ und $\mathbf{D}$, deren Morphismen natürliche
Transformationen heißen.

\defi{Natürliche Transformation}{Eine natürliche Transformation $\alpha:F \nto
G$ ordnet jedem Objekt $A$ aus $\mathbf{C}$ einen Morphismus
$\alpha_A:F(A) \ato G(A)$ aus $\mathbf{D}$ zu, wobei für alle Objekte
$A,B$ und alle Morphismen $f:A \ato B$ aus $\mathbf{C}$ die
Gleichung
$$\alpha_B \circ F(f) = G(f) \circ \alpha_A $$
gelten muss, was dem kommutativen Diagramm in \abb{cat_nat}
entspricht.
}

Obwohl natürliche Transformationen in der Funktorkategorie Morphismen
sind, werden sie für die bessere Unterscheidung mit $\nto$ statt
$\ato$ notiert.

\fig{cat_nat}{Kommutatives Diagramm in Kategorie $\mathbf{D}$ für die Definition von
  natürlichen Transformationen}

\lsection[cats:monads]{Monaden}

Monaden setzen sich aus einem Endofunktor und zwei natürlichen
Transformationen zusammen:
\defi{Monade}{Eine Monade $(T,\eta,\mu)$ über der Kategorie $\mathbf{C}$ besteht aus
  \begin{itemize}
  \item einem Endofunktor $T:\mathbf{C} \ato \mathbf{C}$,
  \item einer natürlichen Transformation $\eta:\mathrm{id}_{\mathbf{C}} \nto T$,
  \item einer natürlichen Transformation $\mu:T^2 \nto T$,
  \end{itemize}
wobei für jedes Objekt $A$ folgende Axiome erfüllt sein müssen:
\begin{itemize}
\item Assoziativität: $$\mu_A \circ T(\mu_A) = \mu_A \circ \mu_{T(A)}$$
\item Neutrales Element: $$\mu_A \circ T(\eta_A) = \mu_A \circ \eta_{T(A)} = \mathrm{id}_{T(A)}$$
\end{itemize}
} $\mathrm{id}_\mathbf{C}:\mathbf{C} \ato \mathbf{C}$ bezeichnet hier
den Identitätsfunktor, $\mathrm{id}_{T(A)}:T(A) \ato T(A)$ dagegen den
Identitätsmorphismus. 

Das erste Axiom beschreibt zwei verschiedene Arten, einen Morphismus von
$T(T(T(A)))$ nach $T(A)$ zu bilden: $T(\mu_A):T(T(T(A))) \ato T(T(A))$
auf der linken Seite behält das äußere $T$ bei und verwendet $\mu$, um
das innen stehende $T(T(A))$ in $T(A)$ zu überführen. Rechts reduziert
$\mu_{T(x)}:T(T(T(A))) \ato T(T(A))$ dagegen von außen und lässt das
innere $T(A)$ unangerührt. Wird das Ergebnis dann in ein $\mu$
geschachtelt, sind innere und äußere Reduktion ununterscheidbar. Die
Gleichung lässt sich auch kurz als $\mu \circ T \mu = \mu \circ \mu T$
schreiben.

Das zweite Axiom funktioniert ähnlich, nur beschreiben diesmal beide
Seiten eine Art, den Identitätsmorphismus für das Objekt $T(A)$ zu
bilden. $T(\eta_A):T(A) \ato T(T(A)$ fügt das neue $T$ innen ein,
$\eta_{T(A)}:T(A) \ato T(T(A))$ hingegen außen.

Zu jeder Monade lässt sich eine neue Kategorie bilden, die Kleisli-Kategorie:
\defi{Kleisli-Kategorie}{
Die Kleisli-Kategorie $\mathbf{C}_K$ zur Kategorie $C$ und der
Monade $(T,\eta,\mu)$ besteht aus
\begin{itemize}
\item den Objekten von $\mathbf{C}$,
\item den Morphismen $f^{\mathbf{C}} \in
  \mathrm{Mor}^{\mathbf{C}}_{A,T(B)}$ aus $C$, die in $f \in
  \mathrm{Mor}^{\mathbf{C}_K}_{A,B}$ umbenannt werden,
\item der Identität $\mathrm{id}_A = \eta_A$,
\item der Komposition $f \circ^{\mathbf{C}_K}_{A,B,C} g = \mu_C
  \circ^{\mathbf{C}} T(f) \circ^{\mathbf{C}} g$.
\end{itemize}
}
Die Erfüllung der Kategorieaxiome wird hier nicht gezeigt, folgt aber
aus den Axiomen für Funktoren, natürliche Transformationen und Monaden.

Monaden sind in der Programmierung nützlich, da sie generisch das
Rechnen mit "`eingepackten"' Werten beschreiben. Beispielsweise könnte
$A$ für den Typ \icode{Int} und $T(A)$ für \icode{List of Int}
stehen. $\eta$ beschreibt dann die Erzeugung einer einelementigen Liste,
$\mu$ reduziert eine Liste von Listen auf eine flache Liste. Über die
Kleisli-Kategorie lassen sich damit beispielsweise nichtdeterministische
Funktionen, die eine Liste möglicher Resultate zurückliefern, elegant
Verknüpfen. Haskell \seec{haskell} benutzt Monaden unter
anderem, um Seiteneffekte in eine normalerweise pur funktionale Sprache
einzubauen, wie \sref{haskell:cats:monads} erläutert.

\lsection[cats:sum]{Zusammenfassung}

Kategorientheorie ist ein abstrakter Zweig der Mathematik, der sich mit
Morphismen (Pfeilen) zwischen Objekten (Knoten) und insbesondere der
Komposition von Morphismen befasst. Damit können unter anderem
Verarbeitungsprozesse formal und graphisch darstellbar beschrieben
werden, wobei die Möglichkeiten weit über mathematische Funktionen
hinausgehen. Über Produkte und Coprodukte können kartesische Produkte
und disjunkte Vereinigungen von Mengen auf Objekte in Kategorien
verallgemeinert werden. Mit Funktoren lassen sich Abbildungen zwischen
Kategorien beschreiben. Eine besondere Art von Funktoren sind Monaden,
welche unter anderem ``eingepackte'' Werte wie Listen beschreiben
können. Zu jeder Monade kann wiederum eine Kategorie gebildet werden,
die Kleisli-Kategorie.

Der Nutzen der Kategorientheorie für diese Arbeit besteht darin,
allgemein und abstrakt die Kombination von Verarbeitungsschritten
beschreiben zu können und somit ein formales Rahmenwerk für die
Zusammensetzung von Compilern zu liefern. Konkret zeigt sich dies in der
Umsetzung kategorientheoretischer Konzepte in Haskell.

\lchapter[haskell]{Die Sprache Haskell}

Haskell ist eine funktionale Programmiersprache, die generell sehr
mathematisch inspiriert ist. Beispielsweise sind Funktionen hier
grundsätzlich pur, d.h. ohne Nebeneffekte. Dank der Haskell-Umsetzung
von Monaden sind Berechnungen mit Nebeneffekten dennoch möglich. siehe
\sref{cats:monads} und \sref{haskell:cats:monads}. Auch
objektorientierte Konzepte gibt es hier in der Form nicht -- stattdessen
wird mittels algebraischer Datentypen und Typklassen
modelliert. Unterstützt wird dieser Ansatz durch ein statisches
Typsystem, welches praktische Features wie Typinferenz oder abhängige
Typen bereitstellt. Haskell arbeitet mit Lazy Evaluation, es werden also
Funktionen und Datenstrukturen erst dann ausgewertet, wenn diese
wirklich benötigt werden. Dies ermöglicht beispielsweise die
Konstruktion unendlicher Listen und Bäume, solange nur endliche
Teilmengen am Ende abgerufen werden.

\lsection[haskell:functions]{Funktionen}

Funktionsaufrufe in Haskell benötigen keine Klammern, sondern werden
einfach durch Leerzeichen in der Form \icode{funktion arg1 arg2 arg3}
notiert. Definitionen von Funktionen erfolgen gewöhnlich über
Gleichungen:
\begin{DIFnomarkup}\begin{code}
addTwo :: Int -> Int
addTwo x = x + 2  
\end{code}\end{DIFnomarkup}
Die erste Zeile deklariert den Typen von addTwo, welcher mit \icode{Int
  -> Int} eine Funktion ist, die einen \icode{Int} als Eingabe bekommt
und ebenfalls einen \icode{Int} zurückgibt. Typdeklarationen sind
weitestgehend optional, da die Typinferenz diese fast immer
selbstständig erschließen kann -- andererseits bieten Typdeklarationen
bereits eine gewisse Dokumentation für den Programmierer und werden
deshalb meist verwendet.

Typen von Funktionen mit mehreren Parametern erscheinen
zunächst verwirrend:
\begin{DIFnomarkup}\begin{code}
add :: Int -> Int -> Int
add x y = x + y  
\end{code}\end{DIFnomarkup}
Der Typoperator \icode{->} ist rechtsassoziierend, weshalb \icode{Int ->
  Int -> Int} äquivalent ist zu \icode{Int -> (Int -> Int)}. Streng
genommen besitzt eine Funktion in Haskell nämlich immer nur genau einen
Parameter -- eine "`Funktion mit zwei Parametern"' ist deshalb in
Wirklichkeit eine Funktion (mit einem Parameter), die eine zweite
Funktion (mit ebenfalls einem Parameter) zurückgibt. Dieses Konzept wird
als Currying bezeichnet und ermöglicht zusammen mit Funktionen höherer
Ordnung sehr elegante Formulierungen von Algorithmen. Beispielsweise
bekommt die Funktion \icode{map} mit Typsignatur \icode{(a -> b) -> [a]
  -> [b]} eine Funktion und wendet diese Elementweise auf eine Liste an
- \icode{a} und \icode{b} stehen hier für beliebige Typen. Um nun zu
jedem Element einer Liste die Zahl 5 zu addieren, kann nun der Code
\begin{DIFnomarkup}\begin{code}
map (add 5) [1, 2, 3, 4]  -- ergibt [6, 7, 8, 9]
\end{code}\end{DIFnomarkup}
verwendet werden -- \icode{add 5} erzeugt also eine Funktion, die 5 zu
ihrem Parameter addiert. Auch Funktionen können direkt auf diese Art
definiert werden:
\begin{DIFnomarkup}\begin{code}
addFiveToList :: [Int] -> [Int]
addFiveToList = map (add 5)
\end{code}\end{DIFnomarkup}
Anonyme Funktionen können mit \icode{\\} erzeugt werden -- das Zeichen
soll an ein Lambda erinnern. Ohne Currying und \icode{add}-Funktion
könnte beispielsweise
\begin{code}
addFiveToList = \list -> map (\x -> x + 5) list
\end{code}
als äquivalente Funktionsdefinition benutzt werden.

Infixoperatoren wie \icode{+} können ebenfalls vom Programmierer selbst
definiert werden -- auch Links- oder Rechtsassoziativität sowie
Operatorpräzedenz können angepasst werden, wobei Infixoperatoren
grundsätzlich eine niedrigere Präzedenz als Präfixfunktionen
haben. Mittels Klammerung kann ein Infixoperator in eine Präfixfunktion
umgewandelt werden, so dass z.B. \icode{(+) 2 3} geschrieben werden
kann. Auch Infixoperatoren unterstützen direkt Currying, so dass
beispielsweise mit \icode{(-2)} eine Funktion erzeugt wird, die vom
Argument 2 subtrahiert. Für die obige, sogenannte
punktfreie\footnote{Punktfrei bedeutet, dass für Zwischenergebnisse
  keine benannten Variablen oder Parameter benötigt werden, sondern
  diese -- beispielsweise durch Currying -- implizit bleiben.} Art der
Funktionsdefinition ist auch der Kompositionsoperator \icode{.}
nützlich:
\begin{DIFnomarkup}\begin{code}
(.) :: (b -> c) -> (a -> b) -> (a -> c)
(g . f) x = g (f x)

addFiveThenMultiplyByThree :: Int -> Int
addFiveThenMultiplyByThree = (*3) . (+5)
\end{code}\end{DIFnomarkup}

Lokale Funktionen können über das Schlüsselwort \icode{where} definiert
werden:
\begin{DIFnomarkup}\begin{code}
sumSquare x y = square (x + y)
  where
    square x = x * x
\end{code}\end{DIFnomarkup}

Funktionsaufrufe werden grundsätzlich linksassoziativ interpretiert,
d.h. \icode{foo a b c d} und \icode{((((foo a) b) c) d)} sind
äquivalent. Manchmal gibt es aber verschachtelte Funktionsaufrufe, für
die auf diese Weise sehr viele Klammern benötigt würden, z.B. 
\begin{code}
a (b c (d (e f)))
\end{code}
In solchen Fällen kann der \icode{$}-Operator benutzt werden, wobei
\icode{a $ b c d} dasselbe ist wie \icode{a (b c d)}. Das Beispiel wird
daher zu
\begin{code}
a $ b c $ d $ e f
\end{code}%$
und damit etwas einfacher zu lesen.

\lsection[haskell:data]{Datentypen}

Es gibt in Haskell vier Arten von Typen: Zunächst gibt es primitive
Typen wie \icode{Char}, \icode{Int} oder \icode{Float} sowie
zusammengesetzte Typen wie Listen (Schweibweise \icode{[a, b, c]}) und Tupel (Schreibweise \icode{(a,
  b)}). Eine Sonderrolle hat hier das leere Tupel \icode{()} -- auch
"`Unit"' genannt, welches dem Typ \icode{void} in C entspricht und in
eine der beiden obigen Kategorien einzuordnen ist.

Daneben gibt es Typaliase -- beispielsweise ist der Typ String lediglich
ein Alias für Listen von Buchstaben:
\begin{DIFnomarkup}\begin{code}
type String = [Char]
\end{code}\end{DIFnomarkup}

Die letzte Kategorie sind algebraische Datentypen, welche mit dem
\icode{data}-Schlüsselwort definiert werden:
\begin{DIFnomarkup}\begin{code}
data Shape = Point
           | Circle Float
           | Rectangle Float Float
\end{code}\end{DIFnomarkup}
Hier sind \icode{Point}, \icode{Circle} und \icode{Rectangle}
verschiedene Konstruktoren, mit denen Instanzen vom Typ Shape erzeugt
werden können. Konstruktoren in Haskell können sowohl als Funktionen --
z.B. \icode{Rectangle :: Float -> Float -> Shape} -- als auch zum Pattern
Matching verwendet werden:
\begin{DIFnomarkup}\begin{code}
shapeArea :: Shape -> Float

-- Pattern Matching in Gleichungen
shapeArea Point           = 0
shapeArea (Circle r)      = pi * r * r
shapeArea (Rectangle x y) = x * y

-- Alternative mit case-Syntax
shapeArea s = case s of
                Point         -> 0
                Circle r      -> pi * r * r
                Rectangle x y -> x * y
\end{code}\end{DIFnomarkup}

Datentypen können auch durch Typvariablen parametrisiert sein,
beispielsweise beschreibt der eingebaute Typ \icode{Maybe} Werte, die
nicht immer vorhanden sind:
\begin{DIFnomarkup}\begin{code}
data Maybe a = Nothing | Just a

tryFindRecord :: Database -> ID -> Maybe Record
tryFindRecord db id = if hasRecord db id
                      then
                        Just (fetchRecord db id)
                      else
                        Nothing
\end{code}\end{DIFnomarkup}
\icode{Nothing} entspricht also in etwa \icode{null} in anderen Sprachen
-- mit dem Unterschied, dass in Haskell ganz klar definiert ist, wo dies
vorkommen kann und wo nicht.

Für den Fall, dass nur ein Konstruktor mit nur einem Argument benutzt
wird, kann statt \icode{data} auch \icode{newtype} verwendet
werden, welches vom Compiler effizienter behandelt wird, da es sich
lediglich um eine Verpackung für einen bestehenden Typen handelt. Dies
wird vor allem zusammen mit Typklassen benutzt.

\lsection[haskell:typeclasses]{Typklassen}

Oben wurden bereits Funktionen und Datentypen präsentiert, die auf
beliebige Typen anwendbar sind. Oft ist es allerdings erforderlich, die
Menge der möglichen Typen einzuschränken, beispielsweise auf Typen mit
Plus-Operator oder solche, die in Strings umgewandelt werden
können. Dies kann mit Hilfe von Typklassen erreicht werden, welche
vergleichbar mit Interfaces in objektorientierten Sprachen sowie
polymorphen Funktionen sind. Beispielsweise ist das Haskell-Äquivalent
zu Javas \icode{toString()} die Typklasse \icode{Show} gegeben:
\begin{DIFnomarkup}\begin{code}
class Show a where
  show :: a -> String
\end{code}\end{DIFnomarkup}
Algebraische Datentypen (nicht aber Typaliase) können Typklassen mittels
\icode{instance} implementieren:
\begin{DIFnomarkup}\begin{code}
instance Show Shape where
  show Point           = "point"
  show (Circle r)      = "circle with radius " ++ show r
  show (Rectangle x y) = "rectangle
\end{code}\end{DIFnomarkup}
\icode{++} ist der Haskell-Operator für Konkatenation von Listen.
Arithmetische Operationen sind ebenfalls durch Typklassen definiert, so
dass diese auch für beispielsweise komplexe Zahlen überladen werden
können.

Typvariablen können nun mittels \icode{=>} auf bestimmte Typklassen
eingeschränkt werden:
\begin{DIFnomarkup}\begin{code}
formatList :: (Show a) => [a] -> String
formatList xs = "{" ++ concat listWithSeparators ++ "}"
  where listWithSeparators :: [String]
        listWithSeparators = intersperse " - " stringList
        stringList :: [String]
        stringList = map show xs

showList [1, 2, 3] -- ergibt "{1 - 2 - 3}"
\end{code}\end{DIFnomarkup}

Derartige Typabhängigkeiten werden in dieser Arbeit in
Beispielprogrammen der Einfachheit halber oft ausgelassen - an deren
Stelle wird dann \icode{(...) =>} geschrieben.

Darüber hinaus besitzt Haskell ``Multi Type Classes'', die durch eine
Kombination von Typem implementiert werden. Auch können die Typvariablen
selbst parametrisiert sein. Letzteres ist unter anderem für einige
kategorientheoretische Begriffe nützlich, die in Haskell durch
Typklassen ausgedrückt werden.

\lsection[haskell:cats]{Kategorien in Haskell}

Die Haskell-Bibliotheken bieten viele kategorientheoretische Begriffe an,
die allerdings alle bestimmten Einschränkungen
unterliegen. Beispielsweise sind die Objekte einer Kategorie hier immer
Haskell-Typen. Die Typklasse \icode{Category} ist wie folgt definiert:
\begin{DIFnomarkup}\begin{code}
class Category cat where
  id   :: cat a a
  (.)  :: cat b c -> cat a b -> cat a c
\end{code}\end{DIFnomarkup}
Ein Typ \icode{cat}, der selbst zwei Typparameter benötigt, ist also eine
Instanz von \icode{Category}, wenn es generische Identitäts- und
Kompositionsoperatoren gibt, die für beliebige Typen $a,b,c$ benutzt
werden können. Genau genommen bestimmt \icode{Category} also keine
Kategorien, sondern vielmehr die Morphismen bestimmter Kategorien. Auch
die Axiome werden hier nicht gefordert -- vielmehr liegt es am
Programmierer, dies für eine "`vernünftige"' Programmsemantik selbst zu
verifizieren. Man sieht hier schon, dass die Haskell-Begriffe nur sehr
vage mit den mathematischen übereinstimmen -- dies wird auch bei den
weiteren Definitionen so bleiben. Die einfachste Instanz von
\icode{Category} ist \icode{(->)}, also die Kategorie der
Haskell-Funktionen, bezeichnet als $\mathbf{Hask}$.
Oft wird statt \icode{.} der \icode{>>>}-Operator (genannt "`vor"') %<<
benutzt mit \icode{f >>> g = g . f}. %<<

\lsubsection[haskell:cats:arrows]{Arrows}

Die Typklasse \icode{Arrow} beschreibt (die Morphismen von) Kategorien,
für die ein Funktor aus der Kategorie $\mathbf{Hask}$ existiert, wo man
also jeder Haskell-Funktion vom Typ \icode{a -> b} einen Morphismus vom
Typ \icode{cat a b} zuordnen kann. Dies ist deshalb sinnvoll, da viele
(Haskell-)Kategorien "`mehr"' können als normale Funktionen, formal eine zu
$\mathbf{Hask}$ isomorphe Unterkategorie besitzen. Beispielsweise
benutzt MagicL "`Funktionen, die fehlschlagen können"' oder "`Funktionen
mit Nebeneffekten"' als Kategorien, die jeweils auch normale Funktionen
enthalten. Zusätzlich wird eine Operation auf Tupeln gefordert, aus der
sich ein Produkt zusammensetzen lässt -- ein Coprodukt wird zunächst nicht gefordert:
\begin{DIFnomarkup}\begin{code}
class (Category ar) => Arrow ar where
  arr   :: (a -> b) -> ar a b
  first :: ar a b  -> ar (a, c) (b, c)
\end{code}\end{DIFnomarkup}
\icode{arr} ist der Funktor, der jede Funktion auf einen Arrow
abbildet\footnote{Die Typen werden hierbei auf sich selbst abgebildet.}.
\icode{first} ist eine Funktion, die aus einem Arrow einen Arrow auf
Tupeln macht, der nur auf dem ersten Element arbeitet, das zweite
dagegen unverändert durchschleift. Somit lassen sich zusätzliche Werte
weiterreichen, außerdem lassen sich aus \icode{first} sinnvolle
Operationen ableiten:

\begin{DIFnomarkup}\begin{code}
  second :: ar a b -> ar (c, a) (c, b)
  second = arr swap >>> first f >>> arr swap
    where swap (x, y) = (y, x)

  (***) :: ar a b -> ar a' b' -> ar (a, a') (b, b')
  f *** g = first f >>> second g

  (&&&) :: ar a b -> ar a b' -> ar a (b, b')
  f &&& g = arr diag >>> (f *** g)
    where diag x = (x,x)
\end{code}\end{DIFnomarkup} % <<

\begin{itemize}
\item \icode{second} ist analog zu \icode{first}, reicht allerdings das erste
Element unverändert weiter.
\item \icode{f *** g} wendet \icode{f} auf das
erste Element, danach \icode{g} auf das zweite Element eines Tupels
an.
\item \icode{f &&& g} ist nun die Haskell-Entsprechung von $\langle f,g
\rangle$ in \dref{Produkt}. \icode{f} und \icode{g} werden also beide
auf die Eingabe angewendet und deren Ergebnisse zu einem Tupel
zusammengesetzt.
\end{itemize}

Möchte man einen Arrow mit einer Funktion verknüpfen, gibt es mit
\begin{DIFnomarkup}\begin{code}
f >>^ func = f >>> arr func
\end{code}\end{DIFnomarkup}% <<
noch etwas syntaktischen Zucker.

\lsubsection[haskell:cats:coproducts]{Coprodukte: Die Klasse \texttt{ArrowChoice}}

Die Haskell-Entsprechung zu einer disjunkten Vereinigung ist der
\icode{Either}-Datentyp, der folgendermaßen definiert ist:
\begin{DIFnomarkup}\begin{code}
data Either a b = Left a | Right b
\end{code}\end{DIFnomarkup}
Coprodukte für Arrows werden durch die Klasse \icode{ArrowChoice} beschrieben:
\begin{DIFnomarkup}\begin{code}
class (Arrow ar) => ArrowChoice ar where
  left :: ar a b -> ar (Either a c) (Either b c)
\end{code}\end{DIFnomarkup}
Auch hier wird mit \icode{left} nur eine einfache Operation gefordert,
aus der sich anschließend alles weitere konstruieren lässt. Diese
Funktion wandelt einen Arrow von \icode{a} nach \icode{b} um in
einen Arrow von \icode{Either a c} nach \icode{Either b c}. Bei einem
\icode{Left}-Wert wird also der ursprüngliche Arrow angewendet, ein
\icode{Right}-Wert wird dagegen unverändert weitergereicht.
\begin{DIFnomarkup}\begin{code}
  right :: ar a b -> ar (Either c a) (Either c b)
  right f = arr swap >>> left f >>> arr swap
    where swap (Left x)  = Right x
          swap (Right x) = Left x

  (+++) :: ar a b -> ar a' b' -> ar (Either a a') (Either b b')
  f +++ g = left f >>> right g

  (|||) :: ar a c -> ar b c -> ar (Either a b) c
  f ||| g = (f +++ g) >>> arr dropEither
    where dropEither (Left x)  = x
          dropEither (Right x) = x

\end{code}\end{DIFnomarkup} %<<
Die Definitionen sind weitgehend analog zu den entsprechenden
Produkt-Operationen:
\begin{itemize}
\item \icode{right} bearbeitet nur \icode{Right}-Werte, während
  \icode{Left}-Werte unverändert bleiben.
\item \icode{f +++ g} wendet auf \icode{Left}-Werte \icode{f} an, auf
  die anderen \icode{g}.
\item Haben \icode{f} und \icode{g} denselben Rückgabetyp, kann
  \icode{f ||| g} verwendet werden, welches das in diesem Fall unnötige
  \icode{Either} verschwinden lässt. Dies entspricht $[f,g]$ in
  \dref{Coprodukt}
\end{itemize}

\lsubsection[haskell:cats:functors]{Funktoren}

Die Haskell-Bibliotheken definieren eine Klasse \icode{Functor}, welche
allerdings nur Endofunktoren über der Kategorie $\mathbf{Hask}$ repräsentieren:
\begin{DIFnomarkup}\begin{code}
class Functor f where
  fmap :: (a -> b) -> f a -> f b
\end{code}\end{DIFnomarkup}
Ein Datenkonstruktor \icode{f} ist also Instanz von \icode{Functor},
wenn die Operation \icode{fmap} Funktionen von \icode{a} nach \icode{b}
auf Funktionen von \icode{f a} nach \icode{f b} abbildet. Der
mathematische Funktor besteht hier also aus \icode{(f,fmap)}.

Diese Arbeit benutzt stattdessen eine eigene \icode{Functor}-Klasse,
die verschiedene Kategorien zulässt:
\begin{DIFnomarkup}\begin{code}
class Functor f ar | f -> ar where
  lift :: ar a b -> f a b
\end{code}\end{DIFnomarkup}
Die Arrows \icode{f} und \icode{ar} bilden eine Instanz von
\icode{Functor}, wenn eine \icode{lift}-Operation \icode{ar}-Arrows auf
\icode{f}-Arrows zwischen den gleichen Typen abbildet -- wobei der Typ
\icode{f} den Typ \icode{ar} bestimmt. Der mathematische Funktor
hier ist also \icode{(id,lift)}. Im Vergleich zu Haskells
Standard-\icode{Functor} ist diese Version also in den Kategorien
allgemeiner, aber dafür spezieller in der Abbildung der Objekte, da hier
die Identität vorgeschrieben ist. Man könnte auch dies allgemein
formulieren -- aber im Rahmen von MagicL reicht die spezielle Version
bisher aus.

Alle hier verwendeten \icode{Functor}-Instanzen konstruieren aus einem
\icode{Arrow}-Typ einen zweiten mit zusätzlichen Eigenschaften,
z.B. erweitert der \icode{FailFunctor} einen Arrow-Typ um mögliches
Scheitern. Die Instanz-Deklaration dafür sieht im Gerüst folgendermaßen
aus (die Details werden in \sref{arrowparser:fail} erläutert):
\begin{DIFnomarkup}\begin{code}
newtype FailFunctor ar a b = ...

instance (Arrow ar) => Functor (FailFunctor ar) ar where
  lift f = ...
\end{code}\end{DIFnomarkup}

\lsubsection[haskell:cats:monads]{Monaden}

Die Typklasse \icode{Monad} aus den Haskell-Bibliotheken beschreibt
Monaden über der Kategorie $\mathbf{Hask}$. $\eta$ aus
\sref{cats:monads} heißt hier \icode{return}, statt $\mu$ wird der
Operator \icode{>>=} %<<
mit anderer Signator gefordert:
\begin{DIFnomarkup}\begin{code}
class Monad m where
  return :: a -> m a
  (>>=)  :: m a -> (a -> m b) -> m b
\end{code}\end{DIFnomarkup} % <<
Es gibt auch eine genaue Entsprechung von $\mu$, die hier \icode{join}
heißt:
\begin{DIFnomarkup}\begin{code}
join :: (Monad m) => m (m a) -> m a
join x = x >>= id
\end{code}\end{DIFnomarkup} % <<

Zu jeder Haskell-Monade \icode{m} lässt sich wieder die
Kleisli-Kategorie bilden, die die Datentypen als Objekte sowie die
Funktionen \icode{a -> m b} als Morphismen enthält. Die
Haskell-Bibliotheken stellen hierfür den Datentyp \icode{Kleisli}
bereit:
\begin{DIFnomarkup}\begin{code}
newtype Kleisli m a b = Kleisli (a -> m b)

instance (Monad m) => Category (Kleisli m)
  where id = Kleisli return
        Kleisli f . Kleisli g = Kleisli composed
          where composed x = g x >>= f

instance (Monad m) => Arrow (Kleisli m)
  where arr fun = Kleisli (return . fun)
        first (Kleisli f) = Kleisli tupleF
          where tupleF (x, z) = f x >>= (\ y -> return (y, z))
\end{code}\end{DIFnomarkup} %<<

Arrows und Monaden werden beide verwendet, um abstrakt Verknüpfungen von
speziellen Operationen zu beschreiben. Arrows sind allgemeiner, denn
jede Monade lässt sich beispielsweise mittels \icode{Kleisli} auf einen
entsprechenden Arrow abbilden. Auf der anderen Seite entspricht aber
nicht jedem Arrow eine Monade, denn aus den Arrow-Operationen allein
lässt sich \icode{>>=} % <<
nicht konstruieren. Hierfür wird zusätzlich die Operation \icode{app}
benötigt, die von der Typklasse \icode{ArrowApply} definiert wird (für
Details siehe \cite[S. 18f]{Hughes}):
\begin{DIFnomarkup}\begin{code}
class (Arrow ar) => ArrowApply ar where
  app :: ar (ar a b, a) b
\end{code}\end{DIFnomarkup}
Mit \icode{app} wird also ein Arrow bereitgestellt, der als Parameter
einen weiteren Arrow sowie eine Eingabe bekommt, um dann den übergebenen
Arrow auf die Eingabe anzuwenden. Damit ist es möglich, Arrows
einzusetzen, die erst im Verarbeitungsprozess und in Abhängigkeit der
Eingabedaten erzeugt werden -- eine Eigenschaft, die Monaden generell
besitzen. Dies wird beispielsweise in \sref{arrowparser} wichtig für
die Konstruktion von kontextsensitiven Parsern.

Instanzen der Klasse \icode{ArrowChoice} sind vollständig äquivalent zu
Monaden.  Dies wirft die Frage auf, weshalb Haskell überhaupt Monaden
benutzt und nicht alles über Arrows realisiert. Zum einen gibt es dafür
historische Gründe: Monaden waren bereits 1993 in Haskell präsent
\cite[S.23ff]{HaskellHistory}, während Arrows erst 1998 von John Hughes
vorgeschlagen wurden, da sich spezielle Parser mit statischen
Komponenten nicht durch Monaden ausdrücken lassen \cite{Hughes}. Zum
anderen bieten Monaden aber auch Vorzüge: Die Definition einer Monade
ist etwas kürzer, da keine \icode{first}-Funktion für Produkte
bereitgestellt werden muss -- wie obiger Code zeigt lässt sich dies
bereits mittels \icode{>>=} % <<
ausdrücken. Zudem gibt es für Monaden in Haskell die praktische
\icode{do}-Notation:
\begin{DIFnomarkup}\begin{code}
do x <- foo
   y <- bar x
   return (x, y)
\end{code}\end{DIFnomarkup}
ist syntaktischer Zucker für
\begin{DIFnomarkup}\begin{code}
foo >>= (\ x ->
  bar x >>= (\ y ->
    return y))
\end{code}\end{DIFnomarkup} % <<
und ermöglicht eine Schreibweise, die imperativen Programmen ähnelt --
dies ist kein Zufall, denn Nebeneffekte werden in Haskell ebenfalls mit
einer Monade beschrieben (siehe \sref{haskell:cats:monads:examples:io}),
so dass auch dort die \icode{do}-Notation benutzt werden kann. Diese
Verwendung erklärt auch nachträglich den Namen \icode{return}, wobei es
sich noch immer um die $\eta$-Transformation handelt und nicht etwa ein
syntaktisches \icode{return}-Statement wie in imperativen Sprachen
üblich.

Für Arrows gibt es mit \icode{proc} auch eine Notation, mit der
Zwischenergebnisse benannt werden können. Diese ist aber weniger simpel
und elegant als das Monadenäquivalent. Auf der anderen Seite eignen sich
Arrows besser als Monaden für eine punktfreie Schreibweise, d.h. einer
Schreibweise ohne Zwischenvariablen, bei der ausschließlich auf
Komposition zurückgegriffen wird. Punktfreie Notation wird auch bei
Definitionen von Funktionen oft verwendet und ist für viele
Haskell-Programmierer natürlicher und eleganter.

\lsubsubsection[haskell:cats:monads:examples]{Beispiele für Monaden}

\lparagraph[haskell:cats:monads:examples:maybe]{\icode{Maybe}}

Funktionen, die fehlschlagen können, lassen sich in der Form \icode{a
  -> Maybe b} darstellen. Möchte man mehrerer solcher Funktionen
verketten, werden normalerweise viele Fallunterscheidungen benötigt, da
bei jeder Funktion die Rückgabe geprüft und nur im Erfolgsfall die
nächste aufgerufen muss. Haskell vereinfacht dies, indem \icode{Maybe}
zur Monade erklärt wird:
\begin{DIFnomarkup}\begin{code}
instance Monad Maybe
  where return = Just
        (Nothing >>= _) = Nothing
        (Just x  >>= f) = f x
\end{code}\end{DIFnomarkup} % <<
Obiges Code-Beispiel, mit einer Typanschrift auf die Maybe-Monade
festgelegt 
\begin{DIFnomarkup}\begin{code}
(do x <- foo
    y <- bar x
    return (x, y)) :: Maybe (Integer, Integer)
\end{code}\end{DIFnomarkup}
wird wie folgt interpretiert: Wenn \icode{foo} erfolgreich ist, wird das
Ergebnis (lokal) in \icode{x} gespeichert. Ist daraufhin \icode{bar x}
ebenfalls erfolgreich, wird dieses in \icode{y} gespeichert und
schließlich der Wert \icode{Just (x, y)} zurückgegeben. Schlägt eine der
Funktionen fehl, ist das Ergebnis \icode{Nothing}.

\lparagraph[haskell:cats:monads:examples:io]{\icode{IO}}

Jede Programmiersprache benötigt für die reale Welt Möglichkeiten,
Operationen mit Nebeneffekten wie das Schreiben von Dateien oder solche,
die von externen Nebeneffekten abhängen, wie das Lesen von Dateien,
auszuführen. Dies lässt sich zunächst schwer in eine puren Sprache wie
Haskell integrieren. Die \icode{IO}-Monade bietet hier eine Lösung: Man
stelle sich einen fiktiven Datentyp \icode{World} vor, der den gesamten
Zustand der externen Welt enthält. \icode{IO a} ist nun eine Funktion,
die die Welt liest und eine andere Welt sowie ein a zurückgibt:
\begin{DIFnomarkup}\begin{code}
newtype IO a = World -> (World, a)
\end{code}\end{DIFnomarkup}
Zum Verketten zweier \icode{IO}-Operationen wird die von der ersten
zurückgegebene Welt an die zweite übergeben. Damit dies nicht von Hand
geschehen muss, wird \icode{IO} wieder als Monade deklariert. Nun gibt
es aber natürlich keinen wirklichen \icode{World}-Typen -- in
Wirklichkeit wird also der Haskell-Compiler alles, was mit \icode{IO}
verpackt ist, in imperativen Code übersetzen. Dennoch gelingt dadurch
die saubere Trennung von puren Code und solchem, der Nebeneffekte
enthalten kann. Da ist nicht möglich ist, eine "`Auspack-Funktion"'
\icode{IO a -> a} zu definieren\footnote{Es gibt eine solche Funktion in
  Haskell, die aber normalerweise nicht verwendet werden sollte.}, das
Gegenteil aber mit \icode{return} möglich ist, kann imperativer Code
immer funktionalen, funktionaler Code aber niemals imperativen
enthalten. Die äußerste Funktion jedes Haskell-Programms, \icode{main},
wird deshalb immer in der \icode{IO}-Monade ausgeführt.

Dank der Kleisli-Kategorie lassen sich mittels \icode{IO} auch Arrows
bereitstellen, die Nebeneffekte enthalten:
\begin{DIFnomarkup}\begin{code}
type IOArrow = Kleisli IO
\end{code}\end{DIFnomarkup}

\lsection[haskell:sum]{Zusammenfassung}

Haskell ist eine pur funktionale, statisch typisierte Programmiersprache
mit Typinferenz. Konzepte wie Currying und Funktionen höherer Ordnung
ermöglichen einen eleganten, modularen und punktfreien
Programmierstil. Für die Definition eigener Datenstrukturen stehen
algebraische Datentypen bereit, die in etwa die Rolle einer Klasse in
objektorientierten Sprachen einnehmen. Es können auch Typvariablen
verwendet werden, die deutlich mächtiger und präziser sind als
beispielsweise Java-Generics \cite{JavaGenerics}. Die Rolle von
Interfaces nehmen in Haskell Typklassen ein.

In Haskell werden mit Arrows und Monaden auch einige
kategorientheoretische Konzepte umgesetzt und in Form von Typklassen
bereitgestellt. Während Arrows allgemeiner und konzeptionell einfacher
sind und optimal für eine punktfreie Formulierung von Algorithmen sind,
können Monaden teilweise einfacher implementiert werden und ermöglichen
mittels do-Notation eine punktierte Schreibweise mit benannten
Zwischenvariablen. Alle Monaden lassen sich über die Kleisli-Kategorie
in Arrows umwandeln und viele Arrows in Monaden.

Haskell selbst nutzt Monaden, um Funktionen mit Seiteneffekten sauber in
die ansonsten pure Sprache integrieren zu können. Die Monade \icode{IO}
lässt sich als verstecktes Weiterreichen eines \icode{World}-Zustandes von
Funktion zu Funktion veranschaulichen.

MagicL legt den Schwerpunkt auf Arrows und beschreibt so allgemein
Compiler. Parser werden hier als Spezialform eines Compilers gesehen.

\lchapter[arch]{Architektur von MagicL}

Dieses Kapitel gibt einen grundlegenden Überblick über die Architektur
und Verwendung von MagicL. Zunächst wird der prinzipielle Aufbau von
Compilern diskutiert und eine Übersicht über Hilfsmittel zur
Compilerdefinition in Abhängigkeit von Ein- und Ausgabemodellen
gegeben. Anschließend wird auf die von MagicL angebotene DSL für
Compilerdefinitionen eingegangen, die mit der Haskell-DSL eine
funktionale Programmiersprache enthält. Zuletzt wird eine Übersicht über
die Programmkomponenten gegeben, aus denen MagicL selbst besteht.

\lsection[arch:comp]{Aufbau von Compilern}

Compiler sind in MagicL allgemein Übersetzungsprozesse (und damit
Morphismen). Es kann sich dabei um elementare Teilschritte handeln wie
ein Makro, das lediglich eine Aufzählungsliste verarbeitet, als auch um
große, komplexe Übersetzer wie den kompletten Compiler von
Slide-DSL-Quelltext nach Latex. Compiler können baukastenartig mit
Kombinatoren wie dem Kompositionsoperator zusammengesetzt werden.

\fig{magicl_model_poss}{Mögliche Ein- und Ausgabemodelle von Compilern}

Ein- und Ausgaben von Compilern können jeweils die drei Modelltypen
Zeichenketten, \sexps{} und Objekte sein, so dass sich insgesamt neun
mögliche Compilertypen ergeben, welche in \abb{magicl_model_poss} als
Pfeile eingezeichnet sind. MagcicL bietet in Abhängigkeit der
Modelltypen verschiedene Hilfsmittel für die Erstellung von Compilern
an:

\lsubsubsection[arch:comp:string]{Zeichenketten}

Für das Einlesen von Zeichenketten steht eine Parser-Bibliothek zur
Verfügung. Parser sind wie Compiler spezielle Morphismen und lassen sich
ebenfalls durch Komposition und andere Kombinatoren aus kleinen,
atomaren Bausteinen zusammensetzen. Die Erzeugung von Quelltext
geschieht mit Hilfe einer funktionalen Generator-Bibliothek.

\lsubsubsection[arch:comp:sexp]{\sexps}

\sexps{} werden in MagicL ebenfalls durch Parser verarbeitet, da diese
genau wie Strings als Listen von Token gesehen werden können -- auch
wenn die Token hier nicht immer atomar sind. Eine
\sexp{}-Parser-Bibliothek erweitert daher die allgemeine
Parser-Bibliothek um \sexp{}-spezifische Funktionalität. Die Anforderung
``verallgemeinerter Makros'' erfüllt MagicL genau durch das Konzept der
\sexp{}-Parser. \sexp{}-Parser, die selbst \sexps{} generieren, werden
als Lisp-Makros\footnote{Es handelt sich hierbei nicht exakt um eine
  Nachbildung von Makros in Lisp -- sie sind aber bereits deutlich näher
  an Lisp-Makros als allgemeine \sexp{}-Parser.} bezeichnet und werden
durch einige Hilfsfunktionen und eine spezielle Syntax besonders
unterstützt. Das Erzeugen von \sexps{} erfolgt durch einen
Quasiquote-Operator.

\lsubsubsection[arch:comp:object]{Objekte}

Die Verarbeitung von Objekten erfolgt durch gewöhnliche
Haskell-Funktionen, so dass MagicL hier keine eigene Funktionalität
bereitstellen muss. 

\medskip{}

\abb{magicl_model_support} zeigt, welche Hilfsmittel für die Erstellung
der neun verschiedenen Compiler-Typen verwendet werden können.

\fig{magicl_model_support}{Hilfsmittel für Compilerdefinitionen nach
  Ein- und Ausgabemodellen}

\lsubsubsection[arch:comp:example]{Beispiel: Übersetzung der Slide-DSL}

\fig{magicl_latex_compiler}{Mögliche Übersetzung der Slide-DSL}

Ein Compiler von der Slide-DSL nach Latex wird in Hinblick auf
Wiederverwendbarkeit sinnvollerweise aus zwei Komponenten
zusammengesetzt: Eine eigene Latex-DSL -- praktisch eine ``geklammerte
Version'' von Latex -- muss nach Latex-Quelltext übersetzt werden.
Dieser Compiler wird mittels \sexp{}-Parser und Generator-Bibliothek
implementiert. Der eigentliche Slide-Compiler übersetzt die Slide-DSL in
die Latex-DSL und wird mit Lisp-Makros und Quasiquote-Notation
realisiert, wodurch ein relativ kurzes und lesbares Programm zu erwarten
ist. Aufgrund der Modularisierung können weitere Latex-basierte DSLs --
beispielsweise eine Book-DSL für das Schreiben von Büchern -- mit sehr
geringem Aufwand eingefügt werden \seea{magicl_latex_compiler}. Hierfür
ist lediglich ein weiterer, mit Lisp-Makros und Quasiquote realisierter
Compiler von Book-DSL nach Latex-DSL nötig. Da alle DSLs auf \sexps{}
basieren, wird kein eigener String-Parser benötigt -- stattdessen wird
der Standardparser für \sexp{}-Syntax wiederverwendet. Weiterhin ist es
auch möglich, die Slide-DSL mit einer anderen Backend-Sprache wie HTML
zu verbinden, so dass derselbe derselbe Folien-Quelltext für mehrere
Zwecke benutzt werden kann. Typisierte Objekte wurden in diesem Beispiel
nicht verwendet -- es wäre aber auch möglich, ein typisiertes
Latex-Modell zu definieren, wodurch einerseits die Suche nach möglichen Fehlern
vereinfacht wird, andererseits aber auch der Entwicklungsaufwand für den
Latex-Compiler steigt. Dieser Ansatz wird in der Implementierung
einer Haskell-DSL verwendet.

\lsection[arch:lang]{Bereitgestellte DSLs}

MagicL-Nutzer definieren neue Compiler ausschließlich in einer
bereitgestellten Compiler-DSL. Diese enthält den Quasiquote-Operator und
Konstrukte zur einfachen Makro-Definition und integriert mit der
Haskell-DSL eine komplette funktionale Programmiersprache, die eine
\sexp{}-Version von Haskell darstellt. Dieser Abschnitt stellt zunächst
die Haskell-DSL und anschließend die Compiler-DSL genauer vor.

\lsubsection[arch:lang:hask-dsl]{Haskell-DSL}

Da die Compiler-DSL von MagicL letztlich nach Haskell übersetzt werden
soll, ist es wie im Latex-Beispiel sinnvoll, eine eigene Haskell-DSL als
Zwischenstufe anzubieten, so dass Nutzer weitere DSLs direkt mit
Lisp-Makros und Quasiquote nach Haskell übersetzen können. Die
Haskell-DSL ist im Wesentlichen eine auf \sexp{}-Syntax angepasste
Version von Haskell. Beispielsweise würde die
Haskell-Funktionsdefinition
\begin{DIFnomarkup}
\begin{code}
sumOfSquares x y = (x2 + y2)
  where
    x2 = (x * x)            
    y2 = (y * y)
\end{code}
\end{DIFnomarkup}
in der Haskell-DSL als
\begin{DIFnomarkup}
\begin{code}
(= (sumOfSquares x y)
   (+ x2 y2)
  (where
    (= x2 (* x x))
    (= y2 (* y y))))
\end{code}
\end{DIFnomarkup}
geschrieben werden. Intern wird die Haskell-DSL zunächst in ein getyptes
Modell und anschließend nach Haskell übersetzt, wie
\abb{magicl_hask_compiler} zeigt. In \cref{sexphs} werden Spezifikation und Umsetzung
der Haskell-DSL genauer vorgestellt und die Vor- und Nachteile des
Zwischenschritts über ein getyptes Modell diskutiert.

\fig{magicl_hask_compiler}{Übersetzung der Haskell-DSL}

\lsubsection[arch:lang:comp-dsl]{Compiler-DSL}

Obwohl es im Prinzip möglich ist, eigene Compiler direkt in Haskell zu
implementieren, ist für Anwendungscode die Compiler-DSL angedacht. Diese
beinhaltet zunächst die Haskell-DSL als Subsprache, so dass dem
Meta-Programmierer die volle Haskell-Funktionalität zur Verfügung steht.
Darüber hinaus enthält die Compiler-DSL einen Quasiquote-Operator und
Operatoren für die gegenüber Haskell leicht vereinfachte Definition von
Makros und zusammengesetzten Compilern.

Die Syntax von Quasiquote und Unquote unterscheidet sich etwas von Lisp:
Statt \icode{`(1 2 ,x 3)} wird beispielsweise \icode{(' (1 2 (, x) 3))}
verwendet. Auf diese Art kann die normale \sexp{}-Syntax verwendet
werden, während Lisp-Parser dies als Sonderfall berücksichtigen
müssen. Zudem passt diese Syntax gut zur Anforderung einer beliebigen
Anzahl von zurückgegebenen Ausdrücken -- beispielsweise können mit
\icode{(')} kein Ausdruck oder mit \icode{(' a b c d)} vier Ausdrücke
erzeugt werden. Die Compiler-DSL von von einem Compiler-Compiler in die
Haskell-DSL übersetzt und anschließend vom Haskell-Backend
weiterverarbeitet, wie in \abb{magicl_comp_compiler}
dargestellt. Definition und Implementation der Compiler-DSL finden sich
in \cref{sexpcomp}.

\fig{magicl_comp_compiler}{Übersetzung der Compiler-DSL}

\lsection[arch:comps]{Komponenten des Frameworks}

Intern besteht MagicL aus einer Reihe von Komponenten, die alle in
Haskell implementiert sind. Grundlegend ist eine Arrow-Bibliothek, auf
der die Parser-Bibliothek aufbaut. Für Erzeugen von Quelltext steht eine
Generator-Bibliothek bereit. Darauf aufbauend stellt eine
\sexp{}-Bibliothek spezielle Parser und Hilfsfunktionen für den Umgang
mit \sexps{} zur Verfügung. Zudem enthält MagicL ein minimales
Test-Framework für Compiler sowie ein eigenes Build-Tool.

\lsubsection[arch:comps:interface]{Arrow-Bibliothek}

Arrows sind die grundlegende Abstraktion, auf der Compiler und Parser in
MagicL basieren. Eine Arrow-Bibliothek definiert daher abstrakt
Arrow-Kombinatoren wie z.B. \icode{many}, welches eine Wiederholung
entsprechend dem Operator \icode{*} in regulären Ausdrücken enthält,
welche in \sref{arrowparser:lib} gemeinsam mit der Parser-Bibliothek
detailierter vorgestellt werden.  Darüber hinaus wird mit den Typklassen
\icode{Executable} und \icode{Compilable} sehr allgemeine
Compiler-Schnittstellen definiert, die es beispielsweise ermöglichen,
Standardcompiler fest mit bestimmten Ein- und Ausgabetypen zu
verdrahten, so dass diese nicht explizit aufgerufen, sondern automatisch
durch Haskells Typinferenz gefunden werden können. Diese Schnittstelle
wird in \sref{magicl:compinterface} erläutert.

\lsubsection[arch:comps:parser]{Parser-Bibliothek}

Parser werden in \cref{arrowparser} als Arrows einer speziellen
Kategorie definiert, die das Weiterreichen eines Eingabestreams sowie
die Möglichkeit eines Scheiterns beinhaltet. Diese Kategorie realisiert
der Typ \icode{ParseFunctor} \sees{arrowparser:parse}. Zudem bietet
die Parser-Bibliothek einige Funktionen, mit denen elementare Parser
definiert werden können. Beispielsweise erzeugt \icode{member "aeiou"}
einen Parser, der genau einen Vokal einliest. 

\lsubsection[arch:comps:generator]{Generator-Bibliothek}

Die Generatorbibliothek definiert eine Reihe von Funktionen, um die
Erzeugung von formatiertem Quelltext zu vereinfachen. Hierfür wird
zunächst durch verschachtelte Aufrufe von Konstruktor-Funktionen wie
\icode{lines}, welche eine Liste von Texten mit Zeilenumbrüchen
verbindet, ein Qellcode-Modell aufgebaut, das anschließend mit
\icode{layout} für eine bestimmte Zeilenlänge\footnote{Die Zeilenlänge
  ist für Gruppierungen relevant, welche in diesem Beispiel nicht
  verwendet werden.} formatiert wird. Beispielsweise lässt sich mittels
\begin{code}
layout 80 (braces 
           (indent2 
            (lines [text "foo",
                    words [text "hello", text "world"],
                    commaSep [text "1", text "2", text "3"]])))
\end{code}
der Quelltext
\begin{code}
{foo
  hello world
  1, 2, 3}
\end{code}
erzeugen. Dies erscheint auf den ersten Blick deutlich aufwändiger als
eine direkte Erzeugung mit einer Templating-Bibliothek wie
StringTemplate. Der funktionale Ansatz bietet allerdings mehrere Vorteile:
Zum einen können die Quellcode-Erzeugung auf diese Weise auf viele
Komponenten aufgeteilt und so beispielsweise direkt in (Sub-)Parsern
benutzt werden. Zum anderen ist es möglich, eigene sprachspezifische
Layout-Funktionen wie beispielsweise für \icode{for}-Schleifen in Java
zu definieren. Zudem passieren Syntaxfehler im generierten Code auf
diese Weise nicht so schnell -- beispielsweise können mit Funktionen wie
\icode{braces} niemals unbalancierte Klammern erzeugt werden. Die
Generator-Bibliothek wird in \sref{magicl:code} besprochen.

\lsubsection[arch:comps:sexp]{\sexp{}-Bibliothek}

Eine Bibliothek enthält eine Reihe von Hilfsmitteln für die Verarbeitung
von \sexps{}. Hierzu gehören ein String-Parser sowie ein Pretty-Printer
für \sexp{}-Syntax. Darüber hinaus werden einige spezielle Kombinatoren
für das Verarbeiten von \sexps{} durch Parser
bereitgestellt. Beispielsweise kann mit \icode{macro} ein \sexp{}-Parser
definiert werden, der wie ein Lisp-Makro nur aktiv wird, wenn das erste
Element eines Ausdrucks mit dem Knotennamen übereinstimmt. Die
\sexp{}-Bibliothek wird in \sref{magicl:sexp} erläutert.

\lsubsection[arch:comps:test]{Test-Framework}

MagicL enthält ein primitives Unit-Test-Framework für die Überprüfung
einzelner Compiler (und damit auch Parser und Makros). Zunächst werden
dafür die Eingaben und erwarteten Ausgaben als Strings in Listen
notiert -- zum Beispiel ist die Übersetzung einiger Haskell-DSL-Ausdrücke
nach Haskell wie folgt spezifiziert:
\begin{DIFnomarkup}\begin{code}
exprCases = [ ( "(Str 42)"                    -- Haskell-DSL 
                , "\"42\"" )                  -- Haskell 

              , ( "(Str a  b c)"              -- Haskell-DSL 
                , "\"a b c\"" )               -- Haskell 

              , ( "(List a b (Str c))"        -- Haskell-DSL 
                , "[a, b, \"c\"]" )           -- Haskell 

              , ( "(foo a (bar b c) d)"       -- Haskell-DSL 
                , "(foo a (bar b c) d)" )     -- Haskell 

              , ( "(map + myList)"            -- Haskell-DSL 
                , "(map (+) myList)" )        -- Haskell 
              ]
\end{code}\end{DIFnomarkup}

Ein Makro, was diese Ausdrücke übersetzt, kann dann mit dem Aufruf
\begin{DIFnomarkup}\begin{code}
testMacro "Expressions" exprMacro exprCases  
\end{code}\end{DIFnomarkup}
getestet werden. Der erste Parameter dient der Dokumentation und wird
für die Formatierung etwaiger Fehlermeldungen benutzt. Da es sich
hierbei um keine essentielle Komponente handelt, wird auf das
Test-Framework in dieser Arbeit nicht weiter eingegangen.

\lsubsection[arch:comps:build]{Build-Tool}

Das Kompilieren des MagicL-Projektes ist relativ kompliziert, da für die
Übersetzung des Compiler-Compilers bereits \cgen{} benötigt wird. Aus
diesem Grund wurde ein kleines Build-Tool in Haskell geschrieben, was
Standardfunktionen wie bedingten Aufruf eines Compilers, falls die
Quelldatei neuer ist als die Zieldatei, beinhaltet und damit die
Übersetzung und das Testen von MagicL per Kommandozeile steuert. Das
Build-Tool wird ebenfalls in dieser Arbeit nicht weiter behandelt.

\lsection[arch:sum]{Zusammenfassung}

Benutzerdefinierte Compiler werden in einer bereitgestellten DSL
geschrieben, die unter anderem eine \sexp{}-Version von Haskell
beinhaltet. Damit können Compiler zwischen beliebigen Modelltypen
konstruiert werden, wobei je nach Modelltyp verschiedene Hilfsmittel
verwendet werden. Während typisierte Objekte mit gewöhnlichen
Haskell-Funktionen verarbeitet werden, stehen für Zeichenketten Parser-
und Generator-Bibliotheken zur Verfügung. Parser -- die als Arrows
realisiert sind -- werden auch für die Verarbeitung von \sexps{}
verwendet und sind MagicL's Umsetzung der Anforderung verallgemeinerter
Makros. Für das Generieren von \sexps{} steht ein gegenüber Lisp
syntaktisch leicht veränderter Quasiquote-Operator bereit, mit dem es
unter anderem möglich ist, eine beliebige Anzahl von Ausdrücken zu
erzeugen.

\lchapter[arrowparser]{Arrow-basierte Parser}

Parser sind für die Umwandlung von Zeichenketten in Objekte
verantwortlich und werden deshalb für Code-Generatoren benötigt, die
ihre Eingaben aus Text-Dateien beziehen. In vielen Programmiersprachen
ist die direkte Implementation von Parsern relativ aufwändig, weshalb
der entsprechende Code häufig selbst aus einer DSL wie JavaCC
generiert wird, die eine EBNF-ähnliche Notation mit bestimmten
Abschnitten kombiniert, die Code in der Zielsprache enthalten.

Die Haskell-Bibliothek Parsec \cite{Parsec} hingegen beschreitet einen
anderen Weg: Hier werden Parser als monadische Funktionen konstruiert,
so dass diese direkt in Haskell und ohne spezielle Syntax beschrieben
werden können. Parser-Kombinatoren wie \icode{<|>} oder \icode{many}
entsprechen den EBNF-Operationen. Darüber hinaus können sogar eigene
Kombinatoren definiert werden -- beispielsweise könnte \icode{sepBy}
Listen mit Trennzeichen einlesen, wenn ein Parser für die Elemente und
einer für die Trennzeichen übergeben werden. Aus diesem Grund können
komplexe Parser in Parsec oft deutlich eleganter konstruiert werden als
mit anderen Parser-Generatoren -- außerdem können hier auch
kontextsensitive Sprachen wie XML ausnahmslos verarbeitet werden (siehe
\cite[S. 3]{Parsec}), was mit anderen Bibliotheken nicht möglich ist.

Es wäre möglich gewesen, Parser in MagicL mittels Parsec zu
konstruieren. Dennoch wurde für diese Arbeit entschieden, ein eigenes,
allgemeineres Framework für die Parser-Konstruktion zu
entwickeln. Dadurch wird neben der freien Auswahl des
Token-Typs\footnote{Auch Parsec lässt es allerdings zu, dass statt
  Zeichenketten auch Listen beliebiger Token eingelesen werden können.}
auch eine freie Auswahl der Kategorie ermöglicht, in der Parser
ausgeführt werden. Beispielsweise kann \icode{IOArrow} benutzt werden,
um Debug-Ausgaben oder andere Nebeneffekte in Parser einzubauen. Dies
ist in Parsec nicht möglich.

MagicL benutzt Arrows und Funktoren, um möglichst allgemein zu
sein. Alles, was im Rahmen dieser Arbeit implementiert wurde, hätte zwar
auch wie in Parsec über Monaden und Monaden-Transformatoren konstruiert
werden können. Dennoch besteht die Möglichkeit, dass später Ergänzungen
vorgenommen werden sollen, die sich nicht mittels Monaden ausdrücken
lassen -- beispielsweise ein effizienterer Parsing-Algorithmus, der
sowohl statische als auch dynamische Komponenten enthält, wie ihn
Swierstra und Duponcheel entworfen haben (siehe
\cite[S. 8ff]{Hughes}). Zudem sind Arrows als programmiersprachliche
Umsetzung von Morphismen anschaulicher als Monaden und besitzen eine
praktische graphische Repräsentation.

Wenn allerdings kontextsensitive Parser wie in Parsec konstruiert werden
sollen, müssen die zugrundeliegenden Arrows äquivalent zu Monaden sein,
also die Typklasse \icode{ArrowApply} implementieren.

Dieses Kapitel entwickelt nun schrittweise einen Parser-Datentyp durch
die Kombination einfacher Funktoren. Parser zeichnen sich hauptsächlich
durch zwei Eigenschaften aus:
\begin{itemize}
\item Sie können fehlschlagen sowie Alternativmöglichkeiten im Falle des
  Scheiterns besitzen.
\item Sie bearbeiten einen Zustand, der die Position im Eingabe-Stream
  beschreibt.
\end{itemize}
Diese beiden Eigenschaften werden von den Datentypen \icode{FailFunctor}
und \icode{StateFunctor} umgesetzt.

\lsection[arrowparser:fail]{Fehlschlagende Arrows}

Berechnungen von $A$ nach $B$, die fehlschlagen können, sollen zwei
mögliche Resultate haben. Im Erfolgsfall wird ein normaler Rückgabewert
aus $B$ geliefert, während im Falle eines Scheiterns eine Fehlermeldung
als String zurückgegeben wird -- im Gegensatz zur \icode{Maybe}-Monade,
die im Fehlerfall nur ein \icode{Nothing} liefert. Der Rückgabetyp ist
deshalb das Coprodukt $\mathrm{String}+B$. Statt Morphismen von $A$ nach
$B$ werden nun Morphismen von $A$ nach $\mathrm{String}+B$ benutzt. Um
den aufrufenden Code nicht komplizierter zu machen, empfiehlt es sich,
diese Änderung in einer neuen Kategorie $\mathbf{C}_f$ zu
verstecken. $f_{f} : A \rightarrow B$ aus der neuen Kategorie wird
abgebildet auf $f : A \rightarrow \mathrm{String} + B$. Der Arrow
$\mathrm{fail}_{f} : \mathrm{String} \rightarrow a$ in $C_{f}$ schlägt
immer fehl und entspricht $fail : \mathrm{String} \rightarrow
\mathrm{String} + a$ in $C$.

Der Operator $\bigvee : Mor_{A,B} \times Mor_{A,B}
\rightarrow Mor_{A,B} $ bietet Alternativen, wodurch ein Backtracking im
Fehlerfall möglich wird. Um Morphismen aus
$\mathbf{C}$ in $\mathbf{C}_f$ benutzen zu können, gibt es den Funktor
$\mathrm{lift}_f:\mathbf{C} \ato \mathbf{C}_f$, welcher die
unveränderte, d.h. gelingende Operation für die neue Kategorie
übernimmt.

Die Haskell-Entsprechung von $\mathrm{String}+B$ ist \icode{Either
  String b}, was sich mit \icode{Failable b} abkürzen lässt, wenn man
den parametrisierten Typ \icode{Failable} einführt:

\begin{DIFnomarkup}\begin{code}
type Failable a = Either String a
\end{code}\end{DIFnomarkup}

Der Fehlerfall wird durch \icode{Left String} ausgedrückt, ein Erfolg
durch \icode{Right a}. Fehlschlagende Arrows nun sind in MagicL durch den
Typ \icode{FailFunctor} implementiert:

\begin{DIFnomarkup}\begin{code}
newtype FailFunctor ar a b = FailF (ar a (Failable b))

instance (Arrow ar) => Functor (FailFunctor ar) ar where
    lift f = FailF (f >>> arr Right)
\end{code}\end{DIFnomarkup} % <<

Arrows von \icode{a} nach \icode{b}, die fehlschlagen können, sind also
Arrows von \icode{a} nach \icode{Failable b}, die in den zusätzlichen
Konstruktor \icode{FailF} eingebettet wurden. Um einen normalen Arrow
\icode{f} aus \icode{ar} nach \icode{FailFunctor ar} zu "`liften"', wird
der Rückgabewert in ein \icode{Right} gebettet und der resultierende
Arrow in \icode{FailF}.
Der Arrow \icode{fail} wird in eine \icode{Arrow} erweiternde Typklasse
ausgegliedert, so dass dieser auch in anderen Kategorien bereitgestellt
werden könnte:

\begin{DIFnomarkup}\begin{code}
class (Arrow ar) => ArrowFail ar where
  fail :: ar String a

instance (ArrowChoice ar) => ArrowFail (FailFunctor ar) where
  fail = FailF (arr Left)
\end{code}\end{DIFnomarkup}

Dem Oder-Operator $\bigvee$ entspricht in Haskell \icode{<+>}, welcher
von der Typklasse \icode{ArrowPlus} aus den Haskell-Bibliotheken
bereitgestellt wird und für \icode{FailFunctor} wie folgt implementiert
ist:

\begin{DIFnomarkup}\begin{code}
instance (ArrowChoice ar) => ArrowPlus (FailFunctor ar) where
  FailF f <+> FailF g = FailF ((f &&& id) >>> arr proc >>> (g ||| arr Right))
   where proc :: (Either a b, c) -> Either c b
         proc (Left  _, y) = Left y
         proc (Right x, _) = Right x
\end{code}\end{DIFnomarkup} % <<

Es werden also zunächst \icode{f} und die Identität parallel evaluiert --
dies ist nötig, um die Eingabe "`durchzuschleifen"'. Anschließend
erfolgt ein Verarbeitungsschritt um das Tupel aufzulösen: Scheitert
\icode{f}, wird dessen Ausgabe weggeschmissen, im Erfolgsfall die
Eingabe. Anschließend wird im Fehlerfall \icode{g} auf die Eingabe
angewendet, bei Erfolg wird das Ergebnis wieder in ein \icode{Right} eingepackt.

\fig{cat_fail}{Komposition beim Fail-Funktor}

Die Typabhängigkeit von \icode{ArrowChoice} ist nötig, weil
\icode{FailFunctor ar} nur dann ein \icode{Arrow} ist, wenn \icode{ar}
ein Coprodukt anbietet. Denn die Komposition in $C_{f}$ ist definiert
durch $g_{f} \circ f_{f} = ([fail,g] \circ f)_{f}$, was in Haskell
\begin{DIFnomarkup}\begin{code}
FailF g . FailF f = FailF (f >>> (arr Left ||| g))
\end{code}\end{DIFnomarkup} %<<
entspricht. Tritt in \icode{f} ein Fehler auf, wird dieser also wieder
in ein \icode{Left} eingepackt und zurückgegeben. Ansonsten wird das
durch \icode{|||} implizit aus dem \icode{Right}-Konstruktor ausgepackte
Ergebnis an \icode{g} weitergereicht.

\abb{cat_fail} zeigt die Komposition in $\mathbf{C}_f$ und deren
Zurückführung auf ein Coprodukt in $\mathbf{C}$. Die Funktion, die $f_f$
auf $f$ abbildet, kann nicht Teil eines Funktors sein. Ein solcher
müsste nämlich das Objekt $B$ sowohl auf $\mathrm{String}+B$ (bei der
Transformation von $f$ als auch auf $B$ selbst (bei $g$) abbilden.

Als Verwendungsbeispiel werden zwei Arrows definiert, die ungerade
Zahlen bzw. Zahlen größer als 10 unverändert weiterreichen, ansonsten
jedoch eine Fehlermeldung erzeugen:
\begin{code}
checkOdd :: FailFunctor (->) Integer Integer
checkOdd = ifArrow (arr odd) 
             id
             (fail "Odd number expected")

checkBig :: FailFunctor (->) Integer Integer
checkBig = ifArrow (arr (>10))
             id
             (fail "Number larger then 10 expected")
\end{code}
Hier wird als unterliegende Kategorie $\mathbf{Hask}$, die Kategorie der
puren Funktionen, verwendet und sowohl Ein- als auch Ausgabe sind vom
Typ \icode{Integer}. \icode{ifArrow} ist eine in MagicL's
Arrow-Bibliothek definierte Hilfsfunktion, die ein Prädikat und zwei
Arrows erwartet, wovon bei Zutreffen des Prädikats der erste, ansonsten
der zweite Arrow verwendet wird. Diese Arrows werden nun einmal per
Komposition, welche sich in diesem Fall wie ein ``Und'' verhält, und
einmal mit dem Oder-Operator verknüpft:
\begin{code}
checkOddAndBig = checkOdd >>> checkBig
checkOddOrBig  = checkOdd <+> checkBig
\end{code}
Mit \icode{execFail} können aus den Arrows wieder normale Funktionen erzeugt
werden, die Im Fehlerfall einen Haskell-Error erzeugen. Diese Funktionen
können nun mit einigen Beispielzahlen aufgerufen werden: 
\begin{code}
execFail checkOddAndBig 41    ==> 41
execFail checkOddAndBig 42    ==> Error: Odd number expected  
execFail checkOddAndBig 9     ==> Error: Number larger then 10 expected  
execFail checkOddAndBig 8     ==> Error: Odd number expected

execFail checkOddOrBig 41     ==> 41
execFail checkOddOrBig 42     ==> 42
execFail checkOddOrBig 9      ==> 9
execFail checkOddOrBig 8      ==> Error: Number larger then 10 expected
\end{code}
Interessant sind die Aufrufe mit 8, die in beiden Fällen zu
verschiedenen Fehlermeldungen führt. Werden also zwei Arrows, die beide
Fehler erzeugen, mit \icode{>>>} verknüpft, erscheint die erste
Fehlermeldung -- mit \icode{<+>} verknüpft hingegen die zweite. Dieses
Verhalten entspricht in etwa der Short-Circuit-Evaluation von Und- und
Oder-Operatoren in Programmiersprachen.

\lsection[arrowparser:state]{Arrows mit Zuständen}

Zustände lassen sich ähnlich zu einem Arrow hinzufügen. Über Produkte
wird der Zustandstyp $S$ (z.B. eine Stream-Position oder der
\textit{Seed} eines Zufallszahlengenerators) an Domäne und Codomäne
heran gehängt, was wieder in einer neuen Kategorie $C_{s}$ versteckt
wird. Ein Morphismus $f_{s} : A \rightarrow B$ der neuen Kategorie
wird entsprechend abgebildet auf $f = A \times S \rightarrow B \times
S$. Da hier im Gegensatz zum Fail-Funktor Domäne und Codomäne gleich
abgebildet werden, ist diese Abbildung Teil eines Funktors $F_s: C_{s}
\ato C$. \abb{cat_state} zeigt die Komposition in $\mathbf{C}_s$ und die
Rückführung auf die ursprüngliche Kategorie.

\fig{cat_state}{Komposition in $\mathbf{C}_s$ und Rückführung auf
  $\mathbf{C}$ durch $F_s$}

In MagicL gibt es die Typklasse \icode{StateFunctor}, die einen weiteren
Typparameter \icode{s} für den Zustand bekommt:

\begin{DIFnomarkup}\begin{code}
newtype StateFunctor s ar a b = StateF (ar (a, s) (b, s))

instance (Arrow ar) => Functor (StateFunctor s ar) ar where
    lift = StateF . first
\end{code}\end{DIFnomarkup} % <<

Die "`geliftete"' Version eines Arrows soll den Zustandsparameter
unverändert weitergeben -- dies entspricht genau der
\icode{first}-Funktion aus \sref{haskell:cats:arrows}.

Das Lesen und Schreiben von Zuständen wird von den Funktionen \icode{get} und
\icode{put} bereitgestellt, welche in der Typklasse \icode{ArrowState}
definiert werden:

\begin{DIFnomarkup}\begin{code}
class (Arrow ar) => ArrowState s ar | ar -> s where
  get :: ar a s
  put :: ar s ()

instance (Arrow ar) => ArrowState s (StateFunctor s ar)
  where
    get = StateF (arr (\ (_, state) -> (state, state)))
    put = StateF (arr (\ (state, _) -> ((), state)))
\end{code}\end{DIFnomarkup}

\icode{get} ignoriert also den Eingabewert und gibt den aktuellen
Zustand zurück, während \icode{put} den übergebenen Zustand
"`abspeichert"' und (bis auf diesen) nichts zurückgibt.

Hier ein kleines Beispielprogramm, welches Zustände verwendet:
\begin{code}
incState :: StateFunctor Integer (->) a a
incState = skip (get >>> arr (+1) >>> put)

double :: StateFunctor a (->) Integer Integer
double = arr (*2)

process :: StateFunctor Integer (->) () (Integer, Integer)
process = (get          >>>
           incState     >>> 
           double       >>> 
           incState     >>> 
           double       >>> 
           (id &&& get))

execState process 5     ==> (20, 7)
\end{code}
\icode{incState} ist ein Arrow, der die normale Eingabe -- welche von
einem beliebigen Typ \icode{a} sein kann -- unverändert zurückgibt (dies
erledigt \icode{skip}), dabei allerdings den versteckt durchgereichten
Zustand vom Typ \icode{Integer} um eins erhöht. \icode{double} hingegen
benutzt den Zustand nicht -- der diesmal einen beliebigen Typ haben kann
-- sondern verdoppelt die Eingabe. \icode{process} ist ein
zusammengesetzter Arrow, der keine Eingabe, jedoch einen vorhandenen
Zustand erwartet, und zunächst den Zustand ausliest, dann je zweimal die
beiden anderen Arrows aufruft und zum Schluss in einem Tupel die normale
Ausgabe sowie den Zustand zurückgibt. Nun wird \icode{process} mittels
\icode{execState} in eine Funktion konvertiert, die ihr Argument als
Zustand benutzt, und mit 5 als Parameter aufgerufen. Da \icode{incState}
und \icode{double} keinerlei Wechselwirkungen miteinander aufweisen, ist
der Effekt ein zweimaliges Verdoppeln der Eingabe (die am Anfang gleich
dem Zustand 5 war) sowie ein Erhöhen des Zustandes um 2.

\lsection[arrowparser:parse]{Der Parse-Funktor}

Parser benötigen sowohl einen Zustand, der die Position im Eingabestream
beinhaltet, als auch die Möglichkeit zu Scheitern sowie die Verwendung
von Alternativen. Daher werden obige Kategorie-Erweiterungen zu einer
Parser-Kategorie $\mathbf{C}_p = \mathbf{C}_{fs}$ zusammengesetzt,
d.h. die ursprüngliche Kategorie wird zunächst um Fehler zu
$\mathbf{C}_f$, danach um Zustände zu $\mathbf{C}_p$ erweitert. Die
Reihenfolge hier ist wichtig, damit ein Morphismus $A \ato B$ aus
$\mathbf{C}_p$ auf $A \times S \ato \mathrm{String} + B \times S$ in
$\mathbf{C}$ abgebildet wird und nicht auf $A \times S \ato
(\mathrm{String} + B) \times S$, wie es andersherum wäre. Denn das
Coprodukt muss "`außen"' stehen, um im Kontrollfluss zuerst bearbeitet
zu werden und somit ein Backtracking im Fehlerfall -- welches allein
durch den Fail-Funktor ermöglicht wird -- zu ermöglichen.

Backtracking wird allerdings zu einem Problem, wenn sinnvolle
Fehlermeldungen produziert werden sollen. Man stelle sich einen Parser für die
(als regulärer Ausdruck beschriebene\footnote{Hierbei sollen eckige und
  geschweifte Klammern keine besondere Bedeutung besitzen, der Punkt für
  ein beliebiges Zeichen und der Stern für beliebige Wiederholungen
  stehen.}) Grammatik \texttt{\{.*\}|[.*]} vor, die eine beliebige
Zeichenkette in geschweiften oder eckigen Klammern beschreibt. Beim
Eingabewort \texttt{\{ABC} scheitert zunächst aufgrund der fehlenden
schließenden Klammer die erste Alternative, woraufhin die zweite
probiert wird. Das Wort beginnt aber nicht mit \texttt{[}, so dass der
  Parser beispielsweise mit der Meldung \texttt{"'Expected [, got \{"'}
    scheitert. Diese Meldung beschreibt den Fehler schlecht --
    stattdessen möchte man nach dem Lesen von \texttt{\{} das
    Backtracking deaktivieren, denn bereits hier ist klar, dass die
    andere Alternative nicht mehr in Betracht kommt. Dies führt zu einer
    besseren Fehlermeldung wie \texttt{"'Expected \}, got end of
      stream"'}.

Ein derartiger "`nicht-auffangbarer"' Fehler lässt sich durch das
Einbauen einer weiteren Möglichkeit des Scheiterns ermöglichen, wir
definieren also $\mathbf{C}_p = \mathbf{C}_{ffs}$ und bieten eine
Funktion \icode{forceParser} an, die einen (Sub-)Parser derart
modifiziert, dass, falls dieser scheitert, der Fehler in die "`innere"'
und damit nicht-recover-fähige Fail-Kategorie übernommen wird. Hiervon
wird beispielsweise bei der Funktion \icode{macro}
\sees{magicl:sexp:sexpparser} Gebrauch gemacht.

Der \icode{ParseFunctor} ist in MagicL wie folgt definiert::
\begin{DIFnomarkup}\begin{code}
newtype ParseFunctor t ar a b =
  P (StateFunctor
     [t]
     (FailFunctor (FailFunctor ar))
     a
     b)
\end{code}\end{DIFnomarkup}
Als Zustandstyp wird ein Stream (als Liste repräsentiert) vom frei
wählbaren Token-Typ \icode{t} benutzt, so dass nicht nur Zeichenketten,
sondern beliebige Listen durch Parser verarbeitbar sind.  Dank der
Implementation als Funktor ist die Kategorie, in der der Parser
ausgeführt wird, frei wählbar. So können rein funktionale Parser in
$\mathbf{Hask}_p$ konstruiert werden. Benötigt man
aber Debug Outputs (z.B. bei der Suche einer Endlosschleife) oder andere
Seiteneffekte, kann $\mathbf{IO}_p$ benutzt werden. In MagicL werden
diese Kategorien durch die Typaliase \icode{FunParser} sowie
\icode{IOParser} bereitgestellt:
\begin{DIFnomarkup}\begin{code}
type FunParser t a b = ParseFunctor t (->) a b
type IOParser  t a b = ParseFunctor t IOArrow a b
\end{code}\end{DIFnomarkup}
Eine geeignete innere Kategorie könnte
sogar interaktive Debugger, Netzwerktransparenz oder sonstige Features
anbieten. Auch der variable Token-Typ erzeugt viele Möglichkeiten:
Textdateien können mit \icode{Char}, Bit-Streams mit \icode{Bool} oder
\sexp{}-Streams mit \icode{Sexp} verarbeitet werden.

\lsection[arrowparser:lib]{Parser-Bibliothek}

MagicL beinhaltet eine Parser-Bibliothek, in der u.a. viele simple
Parser-Konstruktoren definiert sind. Hier ein paar
Beipiele\footnote{Abhängigkeiten der Typparameter werden hier der
  Übersichtlichkeit halber weggelassen.}:
\begin{itemize}
\item \icode{empty :: ParseFunctor t ar a a}\\
  gibt seinen Eingabewert unverändert zurück, wenn der Stream leer ist.
\item \icode{takeWhen :: (t -> Bool) -> (t -> String) -> ParseFunctor t ar a
    t}\\
  testet den ersten Token mit einem Prädikat. Im Erfolgsfall (\icode{True}) wird der
  Token zurückgegeben, ansonsten wird der Token an eine Funktion
  übergeben, die daraus eine Fehlermeldung aufbaut.
\item \icode{member :: [t] -> ParseFunctor t ar a t}\\
  testet, ob der erste Token in der übergebenen Liste vorkommt.
\item \icode{streamEq ::  [t] -> ParseFunctor t ar a [t]}\\
  prüft, ob die ersten $n$ Token mit den Elementen der übergebenen Liste
  übereinstimmen, und gibt diese im Erfolgsfall zurück. Für \icode{t =
    Char} wird hier also ein String gelesen.
\end{itemize}

Alle diese Funktionen (und deren Negationen) geben Parser mit nützlichen
Fehlermeldungen zurück.

Weiterhin gibt es viele Arrow-Kombinatoren, mit denen Parser,
vergleichbar mit den Operationen der Erweiterten Backus-Naur-Form (EBNF)
\cite[S.43ff]{EBNF}, verschaltet werden können. Mit den bisher eingeführten
Operatoren sind bereits Konkatenation (\icode{>>>}) %<<
und Alternative (\icode{<+>}) abgedeckt, darüber hinaus gibt es für
Instanzen von \icode{ArrowPlus} unter anderem folgende Funktionen:

\begin{DIFnomarkup}\begin{code}
optional :: (...) => ar a b -> ar a (Maybe b)
optional f = (f >>^ Just) <+> constArrow Nothing
  where constArrow x = arr (\ _ -> x)

many :: (...) => ar a b -> ar a [b]
many f = many1 f <+> constArrow []

many1 :: (...) => ar a b -> ar a [b]
many1 f = consArrow f (many f)
  where consArrow :: ar a b -> ar a [b] -> ar a [b]
        consArrow f g = (f &&& g) >>^ (\ (x,xs) -> x : xs)

skip :: (...) => ar a b -> ar a a
skip f = (f &&& id) >>^ snd

sepBy :: (...) => ar a c -> ar a b -> ar a [b]
sepBy sep item =
  optional (consArrow item (many (skip sep >>> item))) >>^ unMaybeList
    where
      unMaybeList  Nothing  = []
      unMaybeList (Just xs) = xs
\end{code}\end{DIFnomarkup} % <<

\icode{optional} erzeugt einen Arrow, der, sollte der übergebene Arrow
scheitern, \icode{Nothing} zurückgibt -- dabei aber "`erfolgreich"'
bleibt. Dies entspricht \icode{[ ]} in EBNF. Hierbei erzeugt
\icode{constArrow Nothing} einen Arrow, der die Eingabe ignoriert und
konstant \icode{Nothing} zurückgibt. Eine (optionale) Wiederholung (in EBNF
\icode{\{ \}}) erzeugt \icode{many}, \icode{many1} verlangt mindestens
ein Vorkommen. Die Hilfsfunktion \icode{consArrow} nimmt zwei
Arrows an und erzeugt daraus einen, der das Element, welches der erste
zurückgibt, vor die Liste hängt, die der zweite zurückliefert.
\icode{skip} ignoriert das Resultat eines Arrows und gibt
stattdessen seine Eingabe zurück -- Zustandsänderungen kann der
ignorierte Arrow aber dennoch bewirken. \icode{sepBy} ist ein
komplizierteres Beispiel und ermöglicht das Parsen von Listen mit
Trennzeichen. Dafür bekommt die Funktion zwei Arrows übergeben:
\icode{sep} soll ein Trennzeichen, \icode{item} ein Element lesen. Es
wird zunächst ein \icode{item}, dann beliebig viele, von (ignorierten)
\icode{sep} angeführte \icode{item}-Elemente gelesen. Das ganze ist noch
in ein \icode{optional} gebettet, damit auch eine leere Liste gelesen
werden kann. Die Rückgabe wird mittels \icode{unMaybeList} vom durch
\icode{optional} erzeugten \icode{Maybe}-Datentyp befreit, so dass statt
\icode{Nothing} eine leere Liste zurückgegeben wird, wenn nichts gelesen
werden kann.

\lsection[arrowparser:example]{Beispiel: Einlesen von CSV-Dateien}

Als Beispiel wird ein Parser definiert, der CSV-Dateien (Comma-Separated
Values) in Listen von Listen einliest. Eine CSV-Datei besteht aus
vielen, durch \icode{'\n'} getrennten Zeilen:
\begin{code}
parseCSV = sepBy (eq '\n') line
\end{code}
Jede Zeile besteht aus durch Kommas getrennten Zellen:
\begin{code}
line = sepBy (eq ',') cell
\end{code}
Eine Zelle beinhaltet eine beliebige Anzahl von Zeichen, die allerdings
nicht die Trennzeichen sein dürfen:
\begin{code}
cell = many (notMember ",\n")
\end{code}
Damit ist der Parser vollständig spezifiziert und kann mit einem
Beispieldatensatz getestet werden:
\begin{code}
runParser parseCSV "Erika,Mustermann,Karlsruhe\nSven,Schmidt,Mannheim"

-- ergibt [["Erika", "Mustermann", "Karlsruhe"]
           ["Sven",  "Schmidt",    "Mannheim"]]
\end{code}

\lsection[arrowparser:sum]{Zusammenfassung}

Parser werden in MagicL durch die Verschachtelung zweier Funktoren
implementiert, die bestehende Arrows um bestimmte Möglichkeiten
erweitern. Der \icode{FailFunctor} realisiert die Möglichkeit, mit einer
Fehlermeldung zu Scheitern und per Backtracking Alternativen zu
probieren. Der \icode{StateFunctor} setzt das Durchreichen von Zuständen
um und wird benutzt, um den noch zu lesenden Stream als Liste zu
verwalten. Der \icode{ParseFunctor} kombiniert beides, wobei der
\icode{FailFunctor} doppelt verwendet wird, um auch Fehler zu
ermöglichen, die nicht durch Backtracking zu beheben sind. Dies ist
hilfreich, um teilweise sinnvollere Fehlermeldungen zu erhalten.

Eine Parser-Bibliothek stellt neben Konstruktoren wie \icode{member}
auch Kombinatoren wie \icode{many} bereit, die eine EBNF-artige
Formulierung ermöglichen. Damit ist die Anforderung einer Bibliothek
für String-Parser erfüllt. Allerdings sind MagicL-Parser so allgemein
definiert, dass neben Buchstaben auch andere Token-Typen verwendet
werden können. Damit bildet die Parser-Bibliothek auch das Fundament für
MagicL's Makrosystem, denn verallgemeinerte Makros werden in
\sref{magicl:sexp} als Parser auf \sexps{} definiert.

\lchapter[magicl]{Weitere Komponenten}

In diesem Kapitel werden die weiteren Kernkomponenten von MagicL
vorgestellt. Zunächst wird die Generator-Bibliothek für Zeichenketten
erläutert. Anschließend wird auf \sexp{}-spezifische Funktionalität
mit dem Schwerpunkt verallgemeinerter Makros eingegangen. Zuletzt wird
die allgemeine Schnittstelle behandelt, mit der sich die verschiedenen
Compiler-Typen in MagicL zusammenfügen lassen und feste Standardcompiler
definiert werden können.

\lsection[magicl:code]{Generator-Bibliothek}

Die meisten Frameworks für \cgen{} erzeugen Quelltext aus
String-basierten Templates und daher mit
Low-Level-Methoden. Syntaktische Konstrukte werden daher oft wiederholt,
was zu häufigen Syntaxfehlern und einem relativ hohen Wartungsaufwand
führt. Es würde beispielsweise viel Arbeit bedeuten, alle in einer
generierten Java-Klasse definierten Arrays in Collections umzuwandeln,
wenn die \icode{\{A, B, C\}}-Syntax überall direkt benutzt
wurde. Hilfreich wäre es, wenn stattdessen überall ein Sub-Template
\icode{genList} aufgerufen würde -- nun müsste nur noch eine Stelle
verändert werden um die erwünschte Anpassung durchzuführen. Diese
Abstraktion ist auch mit einigen String-basierten Templates
realisierbar. Ein weiteres Problem aber ist die Formatierung -- denn auch
generierter Quelltext wird eventuell gelesen werden. Ein Template für
\icode{for}-Schleifen kann den Schleifenkörper nicht korrekt einrücken,
da der Einrückungslevel immer relativ zur -- leider im Template
unbekannten -- äußeren Einrückung ist.  Wenn vorhanden, kann der erzeugte
Code daher an einen Formatierer wie Jalopy \cite{Jalopy} übergeben werden --
für ein sprachunabhängiges Framework ist diese Option aber nicht
zufriedenstellend.

MagicL verfolgt einen anderen Ansatz und definiert ein typisiertes
Modell für formatierten Quelltext, welches durch eine Reihe von
Generatorfunktionen konstruiert und anschließend von einem Compiler in
eine Zeichenkette überführt wird. Hierbei handelt es sich um einen Nachbau
des von Philip Wadler in \cite[S.223ff]{FunOfProgramming} vorgestellten
Pretty-Printers. Die elementaren Konstruktor-Funktionen sind:
\begin{DIFnomarkup}\begin{code}
newline :: Code
text    :: String -> Code
append  :: Code   -> Code -> Code
group   :: Code   -> Code
indent  :: Int    -> Code -> Code
\end{code}\end{DIFnomarkup}

\icode{newline}, \icode{text} und \icode{append} sollten selbsterklärend
sein. \icode{group} versucht den übergebenen \icode{Code} auf eine Zeile
zu bekommen, indem es alle Zeilenumbrüche durch Leerzeichen
ersetzt. Wird dabei allerdings die geforderte Zeilenlänge (im
Standard-Compiler 70) überschritten, wird die ursprüngliche Version mit
Zeilenumbrüchen genommen. \icode{indent} rückt den übergebenen
\icode{Code} bei jedem Zeilenumbruch um $n$ Zeichen ein, z.B. würde
\begin{DIFnomarkup}\begin{code}
indent 2 (conc [text "hallo", newline, text "welt"])
\end{code}\end{DIFnomarkup}
den Text
\begin{DIFnomarkup}\begin{code}
hallo
  welt
\end{code}\end{DIFnomarkup}
ergeben -- dabei verbindet \icode{conc :: [Code] -> Code} eine Liste
mittels \icode{append}. Darüber hinaus gibt es viele weitere allgemeine
Funktionen wie
\begin{DIFnomarkup}\begin{code}
  joinBy :: Code -> [Code]
\end{code}\end{DIFnomarkup}
-- welche einen Separator benutzt, um eine Liste zusammenzufügen.
\begin{DIFnomarkup}\begin{code}
joinBy "; " [text "foo", text "bar", text "baz"]
\end{code}\end{DIFnomarkup}
würde also
\begin{DIFnomarkup}\begin{code}
foo; bar; baz
\end{code}\end{DIFnomarkup}
ergeben. Aus diesen allgemeinen Funktionen werden dann Abkürzungen für
syntaktische Programmiersprachenelemente abgeleitet, wie
\icode{commaSep} für eine Komma-separierte Liste oder \icode{parens},
\icode{braces}, \icode{brackets} und \icode{angleBrackets} für die vier
gängigen Arten der Klammerung.

\lsubsubsection[magicl:code:example]{Beispiel: Generierung von XML}

Als Beispiel soll ein vereinfachter XML-Generator definiert werden. Als
Eingabe wird dabei ein XML-Modell wie folgt definiert:
\begin{code}
data XmlNode = Node String [Attribute] XmlInner
data Attribute = Attr String String
type XmlInner = Either [XmlNode] String
\end{code}
Ein Knoten besteht aus einem Namen, einer Attributliste und einem
Inhalt. Jedes Attribut enthält einen Schlüssel und einen Wert. Das
Innere eines Knotens kann entweder eine Liste von Kindknoten oder ein
String sein. Ein Knoten soll wie folgt formatiert werden:
\begin{code}
<node key1="value1" key2="value2">
  <inner-node></inner-node>  
  <inner-node></inner-node>
</node>
\end{code}
Der Inhalt wird um zwei Zeichen eingerückt -- es sei denn der Knoten
passt komplett auf die aktuelle Zeile. Die Formatierungsfunktion ist
durch folgendes Programm gegeben:
\begin{code}
formatNode (XmlNode tagName attrs inner) =
  group (lines [indent2 (lines [openTag, innerCode]), closeTag])
  where openTag  = angleBrackets (words [text tagName, attrCode])
        closeTag = angleBrackets (append (text "/") (text tagName))
        attrCode = words (map formatAttr attrs)
        formatAttr (Attr key value) =
          conc [text key, text "=", string (text value)]
        innerCode = case inner of
                      Left childNodes -> lines (map formatNode childNodes)
                      Right str       -> text str    
\end{code}
Auf eine detailierte Erklärung des Programms wird an dieser Stelle
verzichtet -- ein einfacheres Beispiel wird mit dem Pretty Printer für
\sexps{} in \sref{magicl:sexp:pretty} ausführlich erläutert.

\lsection[magicl:sexp]{\sexp{}-Bibliothek}

\sexps{} sind in MagicL wie folgt definiert:
\begin{DIFnomarkup}\begin{code}
data Sexp = Symbol String
          | Node [Sexp]
\end{code}\end{DIFnomarkup}
Die \sexp{}-Bibliothek enthält einen Parser und einen Generator, welche
zwischen \sexp{}-Syntax und dem Typen \icode{Sexp} konvertieren
können. Außerdem wird die Parser-Bibliothek um Funktionalität für
Parser, die auf \sexps{} operieren, bereichert, wodurch Makros als
Parser definiert werden können.

\lsubsection[magicl:sexp:syntax]{Ein- und Ausgabe von \sexp{}-Syntax}

Aufgrund der Einfachheit der \sexp{}-Syntax ist es mit der
Parser-Bibliothek möglich, in wenigen Zeilen einen Parser zu entwerfen,
der als Text repräsentierte \sexps{} in die typisierte Repräsentation
überführt:

\begin{DIFnomarkup}\begin{code}
whitespace = skip (many (member " \t\n"))
\end{code}\end{DIFnomarkup}
Zunächst wird Whitespace als beliebige Anhäufung von Spaces, Tabs und
Newlines definiert, die ignoriert werden soll.
\begin{DIFnomarkup}\begin{code}
parseSymbol = many1 (notMember " \t\n()") >>^ Symbol
\end{code}\end{DIFnomarkup} % <<
Ein Symbol ist eine Kette von Zeichen, die weder Whitespace noch
Klammern sind. Dieses wird gleich an den \icode{Symbol}-Konstruktor
übergeben, um den Typ \icode{Sexp} zu erhalten.
\begin{DIFnomarkup}\begin{code}
parseNode = skip (eq '(') >>> (many parseSexp >>^ Node) >>> skip (eq ')')
\end{code}\end{DIFnomarkup} % <<
Ein Knoten ist eine von Klammern umgebene Liste von \sexps{}, die
mittels \icode{Node}-Konstruktor zu einem \sexp{} wird.
\begin{DIFnomarkup}\begin{code}
parseSexp = whitespace >>> (parseSymbol <+> parseNode) >>> whitespace
\end{code}\end{DIFnomarkup} % <<
Ein \sexp{} ist nun entweder ein Symbol oder ein Knoten, wobei davor und
danach Whitespace auftreten darf.
\begin{figure}[h]
\begin{DIFnomarkup}\begin{code}
whitespace  = skip (many (member " \t\n"))
parseSymbol = many1 (notMember " \t\n()") >>^ Symbol
parseNode   = skip (eq '(') >>> (many parseSexp >>^ Node) >>> skip (eq ')')
parseSexp   = whitespace >>> (parseSymbol <+> parseNode) >>> whitespace    
  \end{code}\end{DIFnomarkup}
  \caption{Ein kompletter \sexp{}-Parser in vier Zeilen}
  \label{magicl:fig:sexp_parser}
\end{figure}
\abb{sexp_parser} zeigt noch einmal den gesamten Parser. Ein
Beispielaufruf könnte wie folgt aussehen:
\begin{code}
runParser parseSexp "(this is (an s-expr))"  

ergibt: 
Node [Symbol "this", Symbol "is", Node [Symbol "an", Symbol "s-expr"]]
\end{code}
Tritt bei Lesen ein Fehler auf, wird automatisch eine brauchbare
Fehlermeldung ausgegeben, z.B.
\begin{DIFnomarkup}\begin{code}
runParser parseSexp "(test) )"  ==>  Empty stream expected: ")"
\end{code}\end{DIFnomarkup}
Dieser Parser -- um \sexp{}-spezifische Fehlermeldungen erweitert --
wird in MagicL zum Einlesen aller \sexp{}-DSLs verwendet.

Neben dem Parser enthält MagicL einen Generator für \sexp{}-Syntax,
welcher beispielsweise zum Debuggen neuer Compiler nützlich ist, da als
Zwischenschritte erzeugte DSLs leserlich ausgegeben werden können.
\sexps{} werden wie folgt formatiert: Passt der gesamte Ausdruck noch
auf die aktuelle Zeile, werden normal Leerzeichen verwendet:
\begin{DIFnomarkup}\begin{code}
(a b (c d) e)
\end{code}\end{DIFnomarkup}
Wird die gewünschte Breite aber überschritten, soll jeder Subausdruck
auf einer eigenen Zeile stehen, wobei alle bis auf den ersten um zwei
Zeichen eingerückt werden:
\begin{DIFnomarkup}\begin{code}
(a
  b
  (c d)
  e)
\end{code}\end{DIFnomarkup}
Dies lässt sich mit dieser rekursiven Funktion erreichen:
\begin{DIFnomarkup}\begin{code}
layoutSexp :: Sexp -> Code
layoutSexp (Symbol sym)    = text sym
layoutSexp (Node children) = format (map layoutSexp children)
  where format = group . parens . indent2 . lines
\end{code}\end{DIFnomarkup} %<<

Um einen Knoten zu formatieren, werden zunächst die Unterknoten
formatiert \\ (\icode{map layoutSexp children}) und jeweils auf eine eigene
Zeile (\icode{lines}) gesetzt, wobei nach Zeilenumbrüchen um zwei
Zeichen eingerückt werden soll (\icode{indent2}). Anschließend wird
der Ausdruck geklammert (\icode{parens}) und zuletzt überprüft
\icode{group}, ob der ganze Ausdruck nach Ersetzen der Zeilenumbrüche
durch Leerzeichen noch auf die aktuelle Zeile passt - ansonsten werden
die Zeilenumbrüche beibehalten.

\lsubsection[magicl:sexp:sexpparser]{Parser auf \sexps}

Mit dem Begriff \sexp{}-Parser werden in dieser Arbeit Parser
bezeichnet, die Listen von \sexps{} als Eingabe und einen beliebigen Typ
als Ausgabe haben -- und nicht etwa der String-Parser für \sexp{}-Syntax
wie im vorigen Abschnitt. Entsprechend ist der Typ \icode{SexpParser} in
MagicL definiert als \icode{IOParser} (für Seiteneffekten wie
Debug-Ausgaben) vom Token-Typ \icode{Sexp} ohne explizite Eingabe und
mit beliebigem Rückgabewert:
\begin{DIFnomarkup}\begin{code}
type SexpParser a = IOParser Sexp () a  
\end{code}\end{DIFnomarkup}
Die Parser-Bibliothek an sich kann bereits Streams von \sexps{}
verarbeiten. Es gibt allerdings bisher keine komfortablen Operationen,
um das Innere einer \sexp{} zu testen oder zu verarbeiten. Da ein
\sexp{} selbst wieder eine Liste und damit ein Stream ist, bietet es
sich an, diesen ebenfalls über einen "`inneren Parser"' zu verarbeiten.

Beispielsweise könnte eine Liste von Personen folgenderweise
repräsentiert sein\footnote{Dieses Format ist unnötig redundant und
  sollte vermutlich besser durch \icode{(persons Franz Walter Heinz)}
  ersetzt werden -- aber es handelt sich ja lediglich um ein Beispiel.}:
\begin{DIFnomarkup}\begin{code}
(person Franz)
(person Walter)
(person Heinz)
\end{code}\end{DIFnomarkup}

Ein Parser, der aus dieser Eingabe eine Liste von Namensstrings
produzieren soll, würde mit der bisherigen Bibliothek so aussehen:

\begin{DIFnomarkup}\begin{code}
parsePerson :: SexpParser String
parsePerson = take >>^ proc >>> (fail ||| id)
  where proc (Node [Symbol "person", Symbol x]) = Right x
        proc y = Left ("Not a person: " ++ show y)
parsePersons :: SexpParser [String]
parsePersons = many parsePerson
\end{code}\end{DIFnomarkup} % <<
Hierbei liest der Befehl \icode{take} den nächsten Token bedingungslos
ein.

Die Verarbeitung von Hand mittels \icode{Node} und \icode{Symbol} im
Pattern-Matching ist relativ umständlich. Deswegen gibt es eine Reihe
nützlicher Hilfsfunktionen für die Konstruktion von \sexp{}-Parsern:

\begin{itemize}
\item \icode{takeSexp} liest eine \sexp{} vom Stream und wandelt diese
  für die Unterscheidung zwischen Symbolen und Knoten mittels
  \icode{|||} in das Coprodukt \icode{Either String [Sexp]} um.
\item \icode{takeSymbol} erwartet ein Symbol und gibt dieses als String
  zurück -- ansonsten wird eine Fehlermeldung ausgegeben.
\item \icode{symbolMacro name = skip (eq (Symbol name))} akzeptiert nur
  das Symbol mit Namen \icode{name}.
\item \icode{takeNode} erwartet einen Knoten und gibt diesen als Liste
  von \sexps{} zurück.
\item \icode{compNode innerComp} verarbeitet einen Knoten, indem der
  übergebene Parser \icode{innerComp} auf das Knoteninnere angewendet
  wird. Da Parser in MagicL immer als Compiler definiert werden (siehe
  \sref{magicl:compinterface}), heißt diese Funktion nicht
  \icode{parseNode}
\item \icode{macro name innerComp} % <<
  konstruiert nun einen Parser, der wie ein Makro das erste Element des
  Knotens mit dem Symbol \icode{name} vergleicht und im Erfolgsfall die
  restlichen Elemente mit \icode{innerComp} verarbeitet. Danach wird
  sichergestellt, dass der Knoten auch wirklich vollständig gelesen
  wurde -- will man dies nicht, da man den Rest ignoriert, gibt es die
  Funktion \icode{looseMacro} mit identischer Signatur.
\end{itemize}
Das obige Beispiel lässt sich nun umschreiben:
\begin{DIFnomarkup}\begin{code}
parsePerson  = macro "person" takeSymbol
parsePersons = many parsePerson
\end{code}\end{DIFnomarkup}

\icode{macro} benutzt \icode{forceParser} aus
\sref{arrowparser:parse}, um das Backtracking auszuhebeln, sobald das
Symbol übereinstimmt, was wieder für bessere Fehlermeldungen
sorgt. Allerdings bedeutet dies, dass Code wie
\begin{DIFnomarkup}\begin{code}
macro "foo" (symbolMacro "bar") <+> macro "foo" (symbolMacro "baz")
\end{code}\end{DIFnomarkup}
nicht erwartungsgemäß funktioniert:
\begin{DIFnomarkup}\begin{code}
(foo bar)   => ()  d.h. Erfolg, kein Ergebnis
(foo baz)   => Symbol bar expected: baz
\end{code}\end{DIFnomarkup}
Es sollte deshalb immer nur ein Makro für jeden Begriff benutzt und
eine etwaige Oder-Verknüpfung ins Innere verlegt werden -- hier also:
\begin{DIFnomarkup}\begin{code}
macro "foo" (symbolMacro "bar" <+> symbolMacro "baz")
\end{code}\end{DIFnomarkup}

\lsection[magicl:compinterface]{Generische Compiler-Schnittstelle}

Mit Parsern und Funktionen gibt es derzeit in MagicL zwei Typen, mit
denen Compiler realisiert werden können -- es könnten auch zukünftig
noch weitere hinzukommen. Damit verschieden implementierte miteinander
kombiniert werden können, müssen diese in einen allgemeineren
Compiler-Typ überführt werden. Der allgemeinste Compilertyp in MagicL
ist \icode{IOArrow a b} -- die Menge der Funktionen mit möglichen
Nebeneffekten -- dessen Elemente mit Arrow-Kombinatoren wie \icode{>>>}
verknüpft werden können. Alle Typen \icode{x}, die sich mit der
polymorphen Funktion \icode{toIO} in IO-Arrows umwandeln lassen,
implementieren die Typklasse \icode{Executable x a b}:
\begin{DIFnomarkup}\begin{code}
class Executable x a b | x -> a b where
  toIO :: x -> IOArrow a b
\end{code}\end{DIFnomarkup}
Dabei ist \icode{x} selbst ein parametrisierter Typ, der die Ein- und
Ausgabetypen \icode{a} und \icode{b} vollständig festlegt. Die
einfachsten Instanzen von \icode{Executable} werden durch IOArrows
selbst sowie pure Funktionen gebildet:
\begin{DIFnomarkup}\begin{code}
instance Executable (IOArrow a b) a b where
  toIO = id

instance Executable (a -> b) a b where
  toIO f = Kleisli (return . f)
\end{code}\end{DIFnomarkup}
Um hier einen \icode{IOArrow} in einen \icode{IOArrow} zu überführen,
reicht die Identitätsfunktion. Eine pure Funktion hingegen wird zunächst
mit \icode{return} in die \icode{IO}-Monade überführt und dann durch die
Kleisli-Transformation in einen Arrow umgewandelt.

Auch Parser sind ausführbar, sofern der zugrundeliegende Arrow-Typ es
ist:
\begin{DIFnomarkup}\begin{code}
instance (...) => Executable (ParseFunctor t ar () a) [t] a where
  toIO = toIO . execParser
\end{code}\end{DIFnomarkup}
Ein Parser von \icode{()} nach \icode{a} mit Token-Typ \icode{t} wird
demnach beim Ausführen zu einem \icode{IOArrow} von \icode{[t]} nach
\icode{a}. Der bei der Parser-Komposition noch implizite
Stream-Parameter wird hier also explizit gemacht -- der vom Parser
implizit zurückgegebene Stream wird verworfen. Sollte es erforderlich
sein, einen Parser mit weiteren Parametern aufzurufen oder auch den
Rest-Stream zu erhalten, muss statt \icode{Executable} direkt mit dem
Parser-Typ gearbeitet werden.

Die Ausgabe von einem Parser kann beispielsweise wie folgt an einen als
Funktion spezifizierten Compiler weitergeleitet werden:
\begin{code}
toIO someParser >>> toIO someFunction
\end{code}

Darüber hinaus bietet die Compilerschnittstelle die Möglichkeit,
spezielle Compiler fest mit einer Kombination von Ein- und Ausgabetyp zu
verbinden, so dass für den Aufruf eines Compilers weder Name noch
Implementationstyp bekannt sein müssen. In MagicL sind Parser und
Generator für \sexp{}-Syntax fest verdrahtet, daher kann beispielsweise
der -- in einen IOArrow umgewandelte -- Parser mit \\
\icode{compile :: IOArrow String Sexp} referenziert werden. Sind Ein-
und Ausgabetyp durch den Kontext klar, kann die Typanschrift weggelassen
werden.

Das Festlegen eines Standardcompilers von \icode{a} nach \icode{b} durch
den Implementationstyp \icode{x} -- welcher \icode{Executable}
implementieren muss -- erfolgt mit der Typklasse \icode{Compilable}:
\begin{DIFnomarkup}\begin{code}
class (Executable x a b) => Compilable x a b | a b -> x where
  comp :: x
\end{code}\end{DIFnomarkup}
Da es nur einen ausgezeichneten Compiler von \icode{a} nach \icode{b}
geben kann, legen \icode{a} und \icode{b} gemeinsam \icode{x} fest --
gleichzeitig bestimmt \icode{x} auch \icode{a} und \icode{b}, da dies
bereits in \icode{Executable} festgelegt ist. Es handelt sich also um
eine 1:1-Beziehung.

Festverdrahtete Compiler können ebenfalls mittels \icode{toIO} in
IO-Arrows konvertiert werden. Dies geschieht bereits automatisch beim
Aufruf mit \icode{compile} aus der Typklasse \icode{Compiler}, die
automatisch für jede Instanz von \icode{Compilable} instanziiert wird:
\begin{DIFnomarkup}\begin{code}
class Compiler a b where
  compile :: IOArrow a b

instance (Compilable x a b) => Compiler a b where
  compile = toIO comp
\end{code}\end{DIFnomarkup}

Als Beispiele können der Generator für \sexp{}-Syntax aus
\sref{magicl:sexp:syntax} mit
\begin{DIFnomarkup}\begin{code}
instance Compilable (Sexp -> String) Sexp String where
  comp x = layout 70 (layoutSexp x)
\end{code}\end{DIFnomarkup}
und der entgegengesetzte Parser mit
\begin{DIFnomarkup}\begin{code}
instance Compilable (FunParser Char () Sexp) String Sexp where
  comp = parseSexp
\end{code}\end{DIFnomarkup}
als Standardcompiler festgelegt werden, woraufhin beide mit typisierten
\icode{compile}-Aufrufen als IO-Arrows angesprochen werden
können. Manchmal ist es auch nützlich, den noch nicht mit \icode{toIO}
umgewandelten Compiler durch einen typisierten Aufruf von \icode{comp}
zu referenzieren.

Da Listen- und Maybe-Datentypen von Parsern fast immer mit \icode{many}
und \icode{optional} verarbeitet werden, stellt MagicL mit jeden
Standardcompiler nach \icode{a} automatisch auch Standardparser nach \icode{[a]} und
\icode{Maybe a} bereit, die auf diese Weise aus dem ursprünglichen
Parsern erzeugt wurden:
\begin{DIFnomarkup}\begin{code}
instance (Compilable (ParseFunctor t ar () a) [t] a, ...) =>
  Compilable (ParseFunctor t ar () [a]) [t] [a] where
    comp = many comp

instance (Compilable (ParseFunctor t ar () a) [t] a. ...) =>
  Compilable (ParseFunctor t ar () (Maybe a)) [t] (Maybe a) where
    comp = optional comp
\end{code}\end{DIFnomarkup}
Die \icode{comp}-Aufrufe auf der rechten Seite beziehen sich auf den
ursprünglichen Parser, welcher von Haskell aus dem Typkontext zugeordnet
wird. Damit können beispielsweise auch Streams von \sexps{} durch den
Aufruf von \icode{compile :: IOArrow String [Sexp]} geparst werden,
obwohl nur der Parser für einzelne \icode{sexps} spezifiziert wurde.

Leider ist es mit MagicL nicht möglich, sogar Kombinationen aus
Compilern selbstständig zu finden. Hierfür müsste das Haskell-Typsystem
eine Prolog-artige Tiefensuche unterstützen, was zumindest derzeit nicht
der Fall ist. Auf der Compiler-Schnittstelle bauen einige
Hilfsfunktionen für das konkrete Aufrufen von Compilern auf:

Um die Kompilation von Textdateien zu vereinfachen, wird die Funktion
\icode{compileStr} definiert, welche ein \icode{Executable} von
\icode{a} nach \icode{b} in eine imperative Haskell-Funktion von
\icode{String} nach \icode{String} umwandelt, falls bereits
Standardcompiler von \icode{String} nach \icode{a} und von \icode{b}
nach \icode{String} bekannt sind.   
\begin{DIFnomarkup}\begin{code}
compileStr :: (Compiler String a, Executable x a b, Compiler b String) =>
               x -> String -> IO String
compileStr f = runKleisli $ compile >>> toIO f >>> compile
\end{code}\end{DIFnomarkup} % $
Beispielsweise kann \icode{a} für \icode{Sexp} und \icode{b} für
\icode{Code} stehen, da bereits Standard-Compiler von \icode{String}
nach \icode{Sexp} (der normale \sexp{}-Parser) sowie von \icode{Code}
nach \icode{String} (der Layouter für eine Zeilenlänge von 70 Zeichen)
existieren. Mit \icode{compileStr layoutSexp} könnte daher der
\sexp{}-Syntax-Generator in eine (imperative) Funktion umgewandelt
werden, die zunächst aus einem String einen \sexp{} parst, anschließend
\icode{layoutSexp} aufruft und das Ergebnis für 70 Zeichen layoutet. Man
beachte, dass Parser und Generator automatisch durch die Typinferenz
gefunden werden und nicht beim Aufruf angegeben werden müssen.

Für die Erzeugung von Compilern, die als eigenständiges Programm laufen
können, benutzt \icode{compiler} stdin als Eingabe- und stdout als
Ausgabe-Stream:
\begin{DIFnomarkup}\begin{code}
compiler :: (Compiler String a, Executable x a b, Compiler b String) => x -> IO ()
compiler f = do
  input <- getContents
  output <- compileStr f input
  putStr output  
\end{code}\end{DIFnomarkup}
Um beispielsweise aus dem \sexp{}-Formatierer ein Kommandozeilenprogramm
zu erstellen, muss lediglich ein Modul mit einem Compiler als
\icode{main}-Funktion erstellt werden:
\begin{DIFnomarkup}\begin{code}
module SexpFormatter where
-- einige Import-Anweisungen

main = compiler layoutSexp
\end{code}\end{DIFnomarkup}
Dieses Modul kann dann kompiliert und von der Kommandozeile
aufgerufen werden, wobei Ein- und Ausgabedateien per Umleitung angegeben
sind:
\begin{DIFnomarkup}\begin{code}
bash$ ghc SexpFormatter.hs
bash$ ./SexpFormatter <inFile >outFile
\end{code}\end{DIFnomarkup}

\lsection[magicl:sum]{Zusammenfassung}

Die Erzeugung von Quelltext erfolgt in MagicL mit einer
Generator-Bibliothek, indem funktional ein typisiertes
\icode{Code}-Modell erzeugt und anschließend mittels \icode{layout} für
eine bestimmte Zeilenlänge formatiert wird. Damit wurde unter anderem
ein Generator für \sexp{}-Syntax implementiert, mit dem generierter
\sexp{}-Code benutzerfreundlich formatiert werden kann. Darüber hinaus
enthält die \sexp{}-Bibliothek neben einem Parser für \sexp{}-Syntax --
der praktisch die Umkehrfunktion zum Generator ist --
eine Reihe von Funktionen, die die Parser-Bibliothek um Funktionalität
für das Einlesen von \sexps{} bereichert -- wie beispielsweise
\icode{macro}, welches einen Parser erzeugt, der wie Lisp-Makros das
erste Symbol eines Ausdrucks auf Übereinstimmung prüft. Damit ist die
Anforderung von \sexp{}-Verarbeitung durch verallgemeinerte Makros
teilweise erfüllt - was noch fehlt sind der Quasiquote-Operator zur
praktischen \sexp{}-Generierung und die Möglichkeit, automatisch
rekursiv absteigende Makros wie in Lisp zu definieren. Außerdem ist die
Meta-Sprache noch Haskell und nicht selbst eine \sexp{}-DSL, so dass es
nicht möglich ist, Compiler selbst zu generieren und die Metasprache so
zu erweitern.

Um die Anforderung der Kombinierbarkeit beliebiger Compiler zu
entsprechen, stellt MagicL die Typklasse \icode{Executable} bereit, mit
der Parser und funktional spezifizierte Compiler in den Typ
\icode{IOArrow} überführt und anschließend mit den gewöhnlichen
Arrow-Kombinatoren miteinander verknüpft werden können. Darüber hinaus
kann jeder Kombination von Ein- und Ausgabetyp mit Hilfe der Typklasse
\icode{Compilable} ein Standardcompiler fest zugeordnert werden, so dass
dieser anschließend durch einen typisierten Aufruf von \icode{compile}
als IOArrow angesprochen werden kann. Dieses zusätzliche Feature kommt
in den Anforderungen nicht vor und kann als experimentell betrachtet
werden.

\lchapter[sexphs]{Haskell-DSL}

Die meisten Anforderungen sind mit den vorhergehenden Kapiteln bereits
erfüllt worden. Was noch fehlt ist eine \sexp{}-basierte DSL für die
Definition von Compilern, die Konstrukte wie den Quasiquote-Operator,
aber auch eine komplette Meta-Programmiersprache enthält. Damit in der
DSL die in Haskell geschriebenen MagicL-Bibltiotheken verwendet werden
können, muss diese selbst nach Haskell übersetzt werden. Aus diesem
Grund wird zunächst eine Haskell-DSL definiert, die Haskell möglichst
eins zu ein abbildet. Diese kann dann direkt als Metasprache verwendet
werden, eignet sich aber auch für die \sexp{}-gestützte Generierung von
Haskell-Code, wodurch in \cref{sexpcomp} unter anderem der
Quasiquote-Operator realisiert wird. Dieses Kapitel spezifiziert
zunächst die Haskell-DSL genauer und stellt anschließend den Compiler
vor, der ein typisiertes Haskell-Modell als Zwischenschritt benutzt und
daher in zwei Kompenenten aufgeteilt wurde. Typisierte Modelle erhöhen
den Entwicklungsaufwand\footnote{Die zukünftige Entwicklung einer
  geeigneten DSL zur Modellbeschreibung, aus der sowohl das typisierte
  Modell als auch Compiler generiert werden, könnte den
  Entwicklungsaufwand wieder reduzieren.}, führen aber zu früherer
Fehlererkennung in Compilern und ermöglichen feste Standardcompiler. Der
Haskell-DSL-Compiler beschreitet diesen Weg und dient damit gleichzeitig
als Anschauungsbeispiel für die Benutzung typisierter Modelle. Rein
\sexp{}-gestützte Kompilation hingegen wird in \cref{sexpcomp}
behandelt.

\lsection[sexphs:spec]{Spezifikation}

Die Haskell-DSL soll im Wesentlichen eine in \sexp{} gegossene Version
von Haskell sein -- mit nur wenigen Anpassungen, wo diese sinnvoll
erscheinen. Eine vollständige Abdeckung aller Haskell-Konzepte muss im
Prototyp nicht gegeben sein, da diese bei Bedarf nachgepflegt werden
können. Zudem sind einige Konzepte wie \icode{let} und \icode{where}
redundant, so dass nur eines von beiden benötigt wird. 

\lsubsection[sexphs:spec:funs]{Funktionen}
Funktions- oder Konstruktoraufrufe müssen in der DSL immer
geklammert werden, können aber unverändert nach Haskell übernommen
werden:
\begin{DIFnomarkup}\begin{code}
(myFun 1 4 52)              Haskell-DSL
=>
(myFun 1 4 52)              Haskell
\end{code}\end{DIFnomarkup}
Die Pseudo-Syntax \icode{=>} steht für ``soll übersetzt werden
nach''. Haskell-Infixoperatoren werden in Präfixnotation überführt und
können in dieser beliebig viele Argumente annehmen wie in Lisp üblich:
\begin{DIFnomarkup}\begin{code}
(+ 1 4 (- 52 10 4))         Haskell-DSL
=>
(1 + 4 + (52 - 10 - 4))     Haskell
\end{code}\end{DIFnomarkup}
Als Infixoperatoren werden Symbole interpretiert, die ausschließlich
aus Zeichen der Liste \icode{!\$\%&/=\?*+-.:<|>^}
bestehen. Kommt ein solcher Operator jedoch nicht am Anfang eines
Ausdrucks, sondern im Inneren vor, ist die (binäre) Funktion selbst
gemeint, was in Haskell der Präfixformulierung durch Klammerung
entspricht:
\begin{DIFnomarkup}\begin{code}
(foldr1 * xs)               Haskell-DSL
=>
(foldr1 (*) xs)             Haskell

ergibt 24 mit xs = [1, 2, 3, 4]
\end{code}\end{DIFnomarkup}
Die Definition neuer benannter Funktionen erfolgt weiterhin mit
\icode{=}, wobei mit \icode{where} weiterhin lokale Definitionen
eingeführt werden können:
\begin{DIFnomarkup}\begin{code}
(= (sumOfSquares x y)
   (+ x2 y2)
 (where                     Haskell-DSL
  (= x2 (* x x))
  (= y2 (* y y))))

=>

sumOfSquares x y = (x2 + y2)
  where
    x2 = (x * x)            Haskell
    y2 = (y * y)
\end{code}\end{DIFnomarkup}
Anonyme Funktionen werden mit \icode{fun} definiert:
\begin{DIFnomarkup}\begin{code}
(map 
  (fun x (+ x 5))           Haskell-DSL
  xs)

=>

(map
  (\ x -> (x + 5))          Haskell
  xs)
\end{code}\end{DIFnomarkup}
Anonyme Funktionen mit mehreren Parametern können in der Form
\icode{(fun (args x y z) ...)} definiert werden.

\lsubsection[sexphs:spec:pats]{Patterns}

Wie in Haskell können Konstrukturen mittels Pattern Matching zerlegt
werden:
\begin{DIFnomarkup}\begin{code}
(= (countMaybe (Just x)) x)
(= (countMaybe Nothing)  0)      Haskell-DSL

=>

countMaybe (Just x) = x
countMaybe Nothing  = 0          Haskell
\end{code}\end{DIFnomarkup}
Für Listen etc. stehen die ``Pseudo-Konstruktoren'' \icode{List},
\icode{Cons}, \icode{Tuple} und \icode{Str} bereit, die wie die
entsprechenden Haskell-Konstrukte sowohl zum Erzeugen als auch zum
Matching verwendet werden können:
\begin{DIFnomarkup}\begin{code}
(= (listTo3Tuple (List x y z)) 
   (Tuple x y z))

(= (dropTwo (Cons x y xs))             Haskell-DSL
  xs)

(= helloWorld (Str Hello World))

=>

listTo3Tuple [x, y, z] = (x, y, z)

dropTwo (x : y : xs) = xs              Haskell

helloWorld = "Hello World"
\end{code}\end{DIFnomarkup}
Im Gegensatz zu richtigen Konstruktoren können diese Operatoren eine
beliebige Anzahl von Parametern verarbeiten.

\lsubsection[sexphs:spec:types]{Typen}

Typen werden eins zu eins in die Haskell-DSL übernommen, dabei werden
parametrisierte Typen geklammert. Typdeklarationen erfolgen mit
\icode{hasType} anstelle des \icode{::}-Operators in Haskell:
\begin{DIFnomarkup}\begin{code}
(hasType x Int)
                                      Haskell-DSL
(hasType m (Maybe a))

=>

x :: Int
                                      Haskell
m :: Maybe a
\end{code}\end{DIFnomarkup}
Funktionstypen werden mit \icode{Fun}, Listentypen mit \icode{List}
denotiert. Letzteres erwartet im Gegensatz zum gleichnamigen
Konstruktor nur einen Parameter und verhält sich somit wie der
\icode{[]}-Operator in Haskell:
\begin{DIFnomarkup}\begin{code}
(hasType map (Fun (Fun a b) (List a) (List b)))
=>
map :: (a -> b) -> [a] -> [b]                  
\end{code}\end{DIFnomarkup}
Typabhängigkeiten können mit \icode{dep} eingebunden werden:
\begin{DIFnomarkup}\begin{code}
(hasType print (dep (Show a)) (Fun a (IO Unit)))
=>
print :: (Show a) => a -> IO ()
\end{code}\end{DIFnomarkup}
Der Typ \icode{Unit} entspricht in Haskell \icode{()} und damit \icode{void}
in anderen Sprachen. Typklassen und --instanzen sind ebenfalls direkt
übernommen worden:
\begin{DIFnomarkup}\begin{code}
(class 
  (MyClass a)
  (where
    (hasType printIt (Fun a (IO Unit)))
    (hasType isEqual (Fun a a Bool))))
                                                     Haskell-DSL
(instance (dep (Show a) (Eq a))
  (MyClass (List a))
  (where
    (= (printIt x)   ...)
    (= (isEqual x y) ...)))

=>

class MyClass a
  where
    printIt :: a -> IO Unit
    isEqual :: a -> a -> Bool
                                                     Haskell
instance (Show a, Eq a) => MyClass [a]
  where
    printIt x   = ...
    isEqual x y = ...
\end{code}\end{DIFnomarkup}

\lsubsection[sexphs:spec:modules]{Module}

Am Anfang jeder Haskell-Datei wird gewöhnlich das aktuelle Modul
benannt und eine Liste referenzierter Module importiert. Darüber
hinaus kann eine Liste zu exportierender Symbole angegeben werden,
welche dann in anderen Modulen sichtbar sind -- ansonsten sind alle
Symbole sichtbar. Um Namenskonflikte auflösen zu können, gibt es vier
mögliche Arten, ein Modul zu importieren:
\begin{itemize}
\item Es können alle (im anderen Modul exportierten) Symbole verfügbar gemacht
  werden.
\item Es können nur bestimmte Symbole importiert werden.
\item Es können bis auf bestimmte alle Symbole importiert werden.
\item Das Modul kann qualifiziert importiert werden, so dass alle
  Symbole daraus über einen vorangestellten Modul-Kurznamen
  referenziert werden können.
\end{itemize}
Die folgende Moduldefinition zeigt alle diese Möglichkeiten in der
Haskell-DSL und die erforderliche Übersetzung nach Haskell:
\begin{DIFnomarkup}\begin{code}
(module MyModule
  (export myFun MyClass MyDataType)
  Prelude
  (Control.Category (only id))                       Haskell-DSL
  (Control.Monad (hiding liftM forM))
  (Control.Exception (qualified E)))

=>

module MyModule (myFun, MyClass, MyDataType) where
import Prelude
import Control.Category (id)
import Control.Monad hiding (liftM, forM)            Haskell
import qualified Control.Exception as E
\end{code}\end{DIFnomarkup}


\lsection[sexphs:model]{Typisiertes Modell}

Als erster Schritt ist das Haskell-Modell zu entwickeln. Der Einfachheit
halber wird hier nur ein kleiner Ausschnitt des Modells vorgestellt --
alle nicht näher beschriebenen Datenstrukturen können dem
MagicL-Quelltext entnommen werden.

Eine Haskell-Codedatei enthält eine optionale Modulbeschreibung sowie
eine Liste von Toplevel-Definitionen:
\begin{DIFnomarkup}\begin{code}
data Haskell = Haskell (Maybe Module) [Toplevel]
\end{code}\end{DIFnomarkup}
Man beachte, dass hier sowohl der Typ als auch der Konstruktor
\icode{Haskell} heißen -- ein übliches Vorgehen, falls ein Datentyp nur
einen Konstrukter besitzt.

Eine Modulbeschreibung besteht aus einem Namen, einer optionalen Liste
exportierter Symbole sowie einer Liste von Imports, wobei hier obige
vier Arten vorkommen können:
\begin{DIFnomarkup}\begin{code}
data Module = Module String (Maybe Export) [Import]
data Export = Export [String]
data Import = Import String ImportArgs
data ImportArgs = Simple
                | Qualified String
                | Only [String]
                | Hiding [String]
\end{code}\end{DIFnomarkup}
Auf Toplevel-Ebene können Typzuweisungen, Funktionsdefinitionen,
Typaliase sowie Deklarationen von Datentypen, Klassen und Instanzen stehen:
\begin{DIFnomarkup}\begin{code}
data Toplevel = TopHasType HasType
              | TopDef Def
              | TopTypeAlias TypeAlias
              | TopData Data
              | TopClass Class
              | TopInstance Instance
\end{code}\end{DIFnomarkup}
Hier wird lediglich auf Funktionen weiter eingegangen. Die linke Seite der
Funktionszuweisung besteht aus einem Pattern, die rechte aus einem
Ausdruck. Zusätzlich können mittels \icode{where} lokale Definitionen
erfolgen.
\begin{DIFnomarkup}\begin{code}
data Def = Def Pattern Expr (Maybe Where)
\end{code}\end{DIFnomarkup}
Ein Pattern kann eine Liste, ein Tupel, ein String oder ein
Funktionsaufruf\footnote{Streng genommen dürfen in Patterns nur
  Konstruktoren (großgeschrieben) aufgerufen werden, in Ausdrücken
  hingegen Konstruktoren und Funktionen. Dies wird im Modell zur
  Vereinfachung nicht unterschieden, könnte allerdings beim Einlesen
  überprüft werden.} sein.
\begin{DIFnomarkup}\begin{code}
data Pattern = ListPattern [Pattern]
             | TuplePattern [Pattern]
             | ConsPattern [Pattern]
             | StringPattern String
             | CallPattern Call
\end{code}\end{DIFnomarkup}
Ein Ausdruck kann eine Lambda-Funktion definieren, ein
\icode{do}-Ausdruck für Monaden\footnote{Die Umsetzung der
  \icode{do}-Notation in der DSL wird in diesem Kapitel nicht
  näher erläutert -- auch diese ist allerdings sehr nah am
  Original.}, eine Typdeklaration oder ein Pattern sein. Die
Parameterliste anonymer Funktionen benutzt ebenfalls Patterns.
\begin{DIFnomarkup}\begin{code}
data Expr = LambdaExpr  [Pattern] Expr
          | DoExpr      [DoCmd]
          | TypeExpr    HasType
          | PatternExpr Pattern
\end{code}\end{DIFnomarkup}

Als nächstes wird ein Parser benötigt, der die DSL in das
Haskell-Modell überführt.

\lsection[sexphs:parser]{DSL-Parser}

Compiler und Parser für größere, aus vielen Datentypen zusammengesetzte
Modelle sollten möglichst immer in kleine Kompilationseinheiten (in Form
von Arrows) aufgeteilt werden, die jeweils nur für einen Datentyp
zuständig sind. Diese können auf zwei Arten definiert werden: Zum einen
können benannte Arrows verwendet und von Hand verknüpft werden, was für
den Haskell-DSL-Parser wie folgt aussehen könnte:
\begin{DIFnomarkup}\begin{code}
compHaskell = liftA2 Haskell (optional compModule) (many compToplevel)

compModule = macro "module" (liftA3 Module
                                    compString
                                    (optional compExport)
                                    (many compImport))

compToplevel = (liftA1 TopHasType   compHasType)   <+>
               (liftA1 TopDef       compDef)       <+>
               (liftA1 TopTypeAlias compTypeAlias) <+>
               (liftA1 TopData      compData)      <+>
               (liftA1 TopClass     compClass)     <+>
               (liftA1 TopInstance  compInstance)
\end{code}\end{DIFnomarkup}
Um optionale Ausdrücke und Listen einzulesen, werden die benutzten Parser
mittels \icode{many} und \icode{optional} transformiert.

Alternativ ist es auch möglich, die Typklasse \icode{Compilable} aus
\sref{magicl:compinterface} zu verwenden und den polymorphen
Arrow \icode{comp} zu überladen. Dadurch erfolgt die Auswahl des
passenden Parsers zur Kompilationszeit mittels Typinferenz anhand der
Modelldefinitionen. Dies hat unter anderem den Vorteil, dass Aufrufe von
\icode{many} und \icode{optional} nicht mehr nötig sind. Andererseits
bedeuten die vielen Instanzdeklarationen einen erhöhten Schreibaufwand
\footnote{Auch hier wäre also eine DSL wünschenswert, die diese Arbeit
  sowie ein automatisches Funktionsliften erledigt.}. Der Haskell-Parser
ist auf diese Art implementiert worden. Wie das Modell selbst wird
dieser hier nur ausschnittsweise vorgestellt -- konkret wird
hauptsächlich das Parsen der Moduldefinition erläutert:
\begin{DIFnomarkup}\begin{code}
instance Compilable (SexpParser Haskell) [Sexp] Haskell where
    comp = liftA2 Haskell comp comp

instance Compilable (SexpParser Module) [Sexp] Module where
    comp = macro "module" (liftA3 Module comp comp comp)

instance Compilable (SexpParser Export) [Sexp] Export where
    comp = macro "export" (liftA1 Export comp)

instance Compilable (SexpParser Import) [Sexp] Import where
    comp  = (comp >>^ \ n -> Import n Simple) <+>
             compNode (liftA2 Import comp compArgs)
        where compArgs =
                  ((empty >>> constArrow Simple)               <+>
                   (macro "qualified" comp >>> arr Qualified)  <+>
                   (macro "only" (many comp) >>> arr Only)     <+>
                   (macro "hiding" (many comp) >>> arr Hiding))

instance Compilable (SexpParser Toplevel) [Sexp] Toplevel where
    comp = (liftA1 TopHasType comp)   <+>
           (liftA1 TopDef comp)       <+>
           (liftA1 TopTypeAlias comp) <+>
           (liftA1 TopData comp)      <+>
           (liftA1 TopClass comp)     <+>
           (liftA1 TopInstance comp)
\end{code}\end{DIFnomarkup}
Der Import-Parser ist so konstruiert, dass als Import sowohl Symbole,
welche automatisch in einen \icode{Simple}-Import übersetzt werden, als
auch Listen übergeben werden können. Der Aufruf \icode{comp >>^ \ n ->
  Import n Simple} liest ein Symbol ein\footnote{MagicL beinhaltet einen
Standard-Parser von \icode{Sexp} nach \icode{String}, welcher nur
Symbole akzeptiert und ebenfalls durch Typinferenz aus \icode{comp}
erzeugt wird.} und leitet dies an eine anonyme Funktion weiter, die den
\icode{Import}-Aufruf erzeugt.

Als Beispiel sei folgende Moduldefinition gegeben:
\begin{DIFnomarkup}\begin{code}
(module MyModule
  Data.List
  (Prelude (hiding id Functor))
  (Control.Exception (qualified E)))
\end{code}\end{DIFnomarkup}
Hier wird ein Modul \icode{MyModule} definiert, welches keine Exports
angibt und drei Module importiert: \icode{Data.List} wird komplett
importiert, während aus \icode{Prelude} die Funktion \icode{id} und der
Datentyp \icode{Functor} ignoriert werden, um einen Namenskonflikt mit
eigenen Definitionen gleichen Namens zu vermeiden. Das Modul
\icode{Control.Exception} wird benannt als \icode{E} importiert, so dass
beispielsweise die Funktion \icode{throw} mittels \icode{E.throw}
angesprochen werden kann.

Der Parser erzeugt daraus nun ein typisiertes Haskell-Objekt:
\begin{DIFnomarkup}\begin{code}
(Module "MyModule"
         Nothing
         [Import "Data.List" Simple,
          Import "Prelude" (Hiding ["id", "Functor"]),
          Import "Control.Exception" (Qualified "E")])
\end{code}\end{DIFnomarkup}
Dieses Objekt kann nun von weiterverarbeitet werden und schließlich in
Haskell-Quelltext überführt werden.

\lsection[sexphs:code]{Haskell-Generator}

Für die eigentliche Quelltext-Erzeugung wird die Generator-Bibliothek
verwendet, so dass das Haskell-Modell in den
Datentyp \icode{Code} aus \sref{magicl:code} umgewandelt wird, woraufhin
es je nach erforderlicher Zeilenlänge formatiert wird. Dieser
Kompilationsschritt kann ebenfalls auf verschiedene Arten durchgeführt
werden. Am simpelsten und pragmatischsten wäre wohl eine direkte
Verwendung in Haskell-Funktionen, die sich gegenseitig
referenzieren. Stattdessen wurde der Compiler allerdings wieder
anhand der Typklasse \icode{Compilable} konstruiert, um zu
demonstrieren, wie neben Parsern auch Funktionen in diesem Rahmen
verwendet werden können -- generell können alle Typen verwendet werden,
für die die Klasse \icode{Executable} aus \sref{magicl:compinterface}
implementiert ist. Dies bedeutet wieder einen erhöhten Aufwand, da für
jede Funktion, die einen Datentyp verarbeitet, eine umständliche
Instanziierung von \icode{Compilable} benötigt wird. Dies wird auch
durch den Vorteil, wieder eine generische \icode{comp}-Funktion
benutzen zu können, vermutlich nicht ausgeglichen. Im Gegensatz zu
Parsern gibt es hier auch keine Standard-Compiler für Listen und
\icode{Maybe}-Datentypen, da diese nicht zwangsläufig für jede Sprache
auf die gleiche Art verarbeitet werden. Listen von Funktionen
beispielsweise werden im Haskell-Modell auf Toplevel-Ebene als Absätze
mit Leerzeilen formatiert, Listen von lokalen Definitionen hingegen
als Zeilen ausgegeben und Listen von Tupel-Elemente mittels Kommas
auf einer einzigen Zeile verknüpft. Der eigentliche Vorteil dieses
Ansatzes ist die Einheitlichkeit, die damit erreicht wird, wenn
jegliche Verarbeitung typisierter Modelle in einem gemeinsamen
Interface angesprochen wird.

Konkret wird ein Haskell-Objekt in eine Reihe von Absätzen formatiert
-- das geschieht mittels \icode{paragraphs}, was je zwei Zeilenumbrüche
zwischen seine Argumente einfügt. Der erste Absatz ist die kompilierte
Modulbeschreibung, falls vorhanden. Anschließend kommen alle
kompilierten Toplevel-Konstrukte:
\begin{DIFnomarkup}\begin{code}
instance Compilable (Haskell -> Code) Haskell Code where
  comp (Haskell mayMod tops) =
    paragraphs $ compMod mayMod ++ map comp tops
      where compMod Nothing  = []
            compMod (Just m) = [comp m]
\end{code}\end{DIFnomarkup} %$
Um den Rahmen dieses Kapitels nicht zu sprengen, wird hier ebenfalls
nur die Verarbeitung der Modulbeschreibung vertieft. Die
Modulbeschreibung wird mit \icode{lines} auf mehrere Zeilen verteilt:
\begin{DIFnomarkup}\begin{code}
instance Compilable (Module -> Code) Module Code where
  comp (Module name exports imports) = 
    (lines $
     [words $ [text "module", text name] ++ compExports exports ++ [text "where"]]
     ++ map comp imports)
    where compExports Nothing              = []
          compExports (Just (Export funs)) = [tuple $ map text funs]
\end{code}\end{DIFnomarkup}%$
Das Schlüsselwort \icode{module}, der Modulname, die Exports (falls
vorhanden) sowie das Schlüsselwort \icode{where} kommen in die erste
Zeile -- jeweils durch Leerzeichen getrennt, was durch \icode{words}
geschieht. Alle Imports belegen ebenfalls je eine Zeile. Exportierte
Symbole werden durch die Funktion \icode{tuple} mit Kommas getrennt
und zusammen in runde Klammern gesetzt. Um streng einheitlich zu
bleiben, müsste die Umwandlung von \icode{Export} in ein Tupel in
einer separaten \icode{comp}-Funktion erfolgen -- da es sich aber um
eine sehr kurze Funktion handelt, wurde diese einfach in den Compiler
von \icode{Module} eingebettet.

Jede Import-Zeile besteht aus dem Schlüsselwort \icode{import} sowie
dem Modulnamen. Je nach Import-Art gibt es dazwischen
(\icode{betweenElts}) sowie am Ende (\icode{endElts}) noch
weitere Elemente:
\begin{DIFnomarkup}\begin{code}
instance Compilable (Import -> Code) Import Code where
  comp (Import modName impArgs) = 
    words $ [text "import"] ++ betweenElts ++ [text modName] ++ endElts
      where (betweenElts, endElts) = case impArgs of
        Simple        -> ([], [])
        Qualified abb -> ([text "qualified"], [text "as", text abb])
        Only onlys    -> ([], [tuple (map text onlys)])
        Hiding hides  -> ([], [text "hiding", tuple (map text hides)])  
\end{code}\end{DIFnomarkup}%$
Beim einfachen Import sind beide Listen leer. Qualifizierte Imports
beinhalten das Schlüsselwort \icode{qualified} sowie am Ende
\icode{as} und die Modul-Abkürzung. Sollen nur bestimmte Symbole
importiert oder nicht importiert werden, werden diese in
Tupel-Notation angefügt, wobei in letzterem Fall noch das
Schlüsselwort \icode{hiding} nötig ist.

Da MagicL bereits einen Standard-Compiler von \icode{Code} nach
\icode{String} bereitstellt, kann ein vollständiger Datei-Compiler von
der Haskell-DSL nach Haskell durch Verkettung von Parser
und Generator sowie Einbettung in einen Aufruf von \icode{compiler}
bereitgestellt werden:
\begin{DIFnomarkup}\begin{code}
compiler ((compile :: IOArrow [Sexp] Haskell) >>> 
          (compile :: IOArrow Haskell Code))  
\end{code}\end{DIFnomarkup}

\lsection[sexphs:sum]{Zusammenfassung}

Mit der Haskell-DSL stellt MagicL eine funktionale Programmiersprache
bereit, welche im Wesentlichen eine geklammerte Haskell-Teilmenge
darstellt und nach Haskell übersetzt wird. Diese DSL dient einerseits
als \sexp{}-basierte Meta-Programmiersprache für MagicL-Benutzer,
erleichtert andererseits aber auch die Generierung von Haskell-Code, was
in \cref{sexpcomp} für die Compiler-DSL genutzt wird. Gegenüber Haskell
beinhaltet die DSL nur wenige Umbenennungen und andere Anpassungen wie
beispielsweise die Erweiterung aller binärer Operatoren auf beliebig
viele Argumente\footnote{Als Operator werden Symbole interpretiert, die
  keine Buchstaben oder Zahlen enthalten. Beispielsweise würde
  \icode{(<+> a b c)} nach \icode{(a <+> b <+> c)} übersetzt werden. Die
  Entscheidung über Links- oder Rechtsassoziativität eines Operators
  trifft anschließend Haskell.}.

\fig{flow_sexphs}{Kompilationsprozess der Haskell-DSL}

Implementiert wurde die Sprache durch ein typisiertes
\icode{Haskell}-Modell sowie zwei Compiler zur Verarbeitung: Der erste
ist ein Parser von \sexps{}, der zweite ein rein funktionaler Compiler
nach \icode{Code}, woraus das MagicL-Framework letztlich den Quellcode
generiert. \abb{flow_sexphs} zeigt den Vorgang als Kategoriendiagramm,
wobei die Framework-interne Vor- bzw. Weiterverarbeitung auf
String-Ebene grau eingezeichnet ist. Der gesamte
Haskell-DSL-Compiler ist die Komposition all dieser Compiler und
damit ein Arrow von \icode{String} nach \icode{String}.

Sowohl Parser als auch Generator sind mittels
\icode{Compilable}-Implementationen für jeden Datentyp des
Haskell-Modells konstruiert. Dies hat neben einer hohen Einheitlichkeit
den Vorteil, dass beliebige Sub-Compiler mit \icode{comp} angesprochen
und durch Haskell anhand der Modelldefinition gefunden werden
können. Bei Parsern können auch Listen und \icode{Maybe}-Datentypen ohne
Mehraufwand verarbeitet werden -- bei anderen Compilern allerdings nicht,
da hier das gewünschte Verhalten nicht für alle Modelle gleich ist. Die
Kehrseite dieses Ansatzes sind die umständlichen
\icode{Compilable}-Instanzdefinitionen, die vor allem für kleine
Compiler nicht sinnvoll erscheinen -- eine DSL für Modellverarbeitung
könnte dies in Zukunft allerdings vereinfachen.

Allgemein haben statisch typisierte Compiler den Vorteil einer
frühzeitigen Typfehlererkennung und erlauben komplexe Algorithmen im
Rahmen der Verarbeitung -- auf der anderen Seite steht immer mit
Modelldefinitionen und der Aufteilung in mehrere Compiler verbundene
Aufwand, der insbesondere für kleine Sprachen oder Spracherweiterungen
nicht sinnvoll erscheint. Deswegen stellt MagicL alternativ die
Möglichkeit der direkten, untypisierten Verarbeitung von \sexps{}
bereit, welche im folgenden Kapitel präsentiert wird. Auch die
Haskell-DSL hätte auf diese Weise vermutlich einfacher verarbeitet
werden können, wurde aber als Verwendungsbeispiel für typisierte
Verarbeitung in dieser Form beibehalten.

\lchapter[sexpcomp]{Compiler-DSL}

MagicL-Benutzer sollen neue Compiler für weitere DSLs ausschließlich in
einer Compiler-DSL\footnote{Es ist durchaus möglich, wie im
  Haskell-DSL-Compiler direkt Haskell als Implementationssprache zu
  verwenden - im Normalfall sollte aber die Compiler-DSL praktischer
  sein.} schreiben. Diese DSL ist eine echte Erweiterung der
Haskell-DSL, so dass letztere an beliebigen Stellen vorkommen
und so als Meta-Programmiersprache verwendet werden kann.

Zunächst werden die Bestandteile der Compiler-DSL im nächsten Abschnitt
spezifiziert. Anschließend wird ein Compiler-Compiler entwickelt, der
die Compiler-DSL in die Haskell-DSL übersetzt. Der Compiler-Compiler lässt sich
selbst am besten in der Compiler-DSL formulieren, so dass die
Implementation meta-rekursiv erfolgt.

\lsection[sexpcomp:spec]{Spezifikation}

Die wesentlichen Bestandteile der Compiler-DSL sind das Quasiquote sowie
die Möglichkeit, automatisch rekursiv absteigende Makros wie in Lisp zu
spezifizieren. Darüber hinaus sind einige Operatoren enthalten, mit
denen sich Makros und zusammengesetzte Compiler kürzer als mit den
bisherigen Konstrukten definieren lassen.

\lsubsection[sexpcomp:spec:gen]{Quasiquote}

Während das Einlesen von \sexps{} dank der in
\sref{magicl:sexp:sexpparser} vorgestellten Funktionen bereits recht
komfortabel geht, ist die Erzeugung von Instanzen des
\icode{Sexp}-Datentyp bisher noch sehr umständlich. Soll beispielsweise eine
Funktion \icode{genSlide title content}, mit den Parametern
\icode{\"Hello\"} und \icode{(list one two)} (als bereits fertig
konstruierter \sexp{}) aufgerufen, den Ausdruck
\begin{DIFnomarkup}\begin{code}
(slide (title Hello) (list one two))
\end{code}\end{DIFnomarkup}
zurückliefern, wäre mit der Haskell-DSL folgende Funktionsdefinition
erforderlich:
\begin{DIFnomarkup}\begin{code}
(= (genSlide title content)
   (Node (List (Symbol (Str slide))
               (Node (List (Symbol (Str title)) (Symbol title)))
               content)))
\end{code}\end{DIFnomarkup}
Der entsprechende Haskell-Code liest sich aufgrund der syntaktischen
Konstrukte \icode{\"\"} und \icode{[]} statt \icode{(Str)} und
\icode{(List)} etwas leichter, ist aber davon abgesehen genauso komplex:
\begin{DIFnomarkup}\begin{code}
genSlide title content =
   Node [Symbol "slide",
         Node [Symbol "title" , Symbol title],
         content]
\end{code}\end{DIFnomarkup}
Um die Konstruktion von \sexp{}-Objekten zu vereinfachen, bieten
Lisp-Dialekte die Quasiquote-Syntax mit \icode{`} und \icode{,} an
\sees{template:lisp}. In Common Lisp beispielsweise ließe sich diese
Funktion sehr elegant formulieren:
\begin{DIFnomarkup}\begin{code}
(defun gen-slide (title content)
  `(slide (title ,title) content))
\end{code}\end{DIFnomarkup}
Ein derartiger Operator soll nun konstruiert werden. Da MagicL die
einfachstmögliche \sexp{}-Syntax und damit keine syntaktischen
Erweiterungen wie \icode{`} benutzt, muss die Notation allerdings im
Rahmen der gewöhnlichen \sexp{}-Syntax erfolgen. Zudem wird nicht
zwischen Quote und Quasiquote unterschieden\footnote{Ein statisches
  Quote, das nicht auf innere Unquotes reagiert, wird in Lisp nur für
  verschachtelte Quasiquotes wirklich benötigt -- diese Problematik wird
  in MagicL allerdings auf anderem Weg behoben, wie in Kürze erläutert
  wird.}, so dass einheitlich der Quote-Operator \icode{'} benutzt
wird. Die Funktion \icode{genSlide} schreibt sich in der Compiler-DSL wie
folgt:
\begin{DIFnomarkup}\begin{code}
(= (genSlide title content)
   (' (slide (title (, title)) ,content)))
\end{code}\end{DIFnomarkup}
Splicing einer Liste erfolgt entsprechend mit \icode{(,@)}:
\begin{DIFnomarkup}\begin{code}
(' (list 1 2 (,@ xs) 5))

ergibt (list 1 2 3 4 5) bei xs = (List (Symbol (Str 3))
                                       (Symbol (Str 4)))
\end{code}\end{DIFnomarkup}
Wie \sref{reqs:template} erläutert, sollen MagicL-Makros beliebig viele
\sexps{} zurückgeben können, die per Splicing an die Stelle des
Makro-Aufrufs gesetzt werden. Dies passt auch gut zu einer Definition
von Makros als Parser auf \sexps{}, da Parser immer Streams und damit
Listen als Eingaben haben, so dass Ein- und Ausgabetyp übereinstimmen:
\begin{DIFnomarkup}\begin{code}
type LispMacro = SexpParser [Sexp]

-- Typ eines kompilierten Makros
myMac        :: LispMacro
(toIO myMac) :: IOArrow [Sexp] [Sexp]
\end{code}\end{DIFnomarkup}
Damit sind Lisp-Makros, nachdem sie mittels \icode{toIO} aus der Typklasse
\icode{Executable} umgewandelt wurden, IO-Arrows von \icode{[Sexp]} nach
\icode{[Sexp]}, wodurch auch die Hintereinanderschaltung mehrerer
Makros reibungslos funktioniert. Um vernünftig mit diesen Makros
verwendet werden zu können, muss der Quasiquote-Operator immer eine
Liste von \sexps{} zurückgeben, wodurch mehrere Rückgaben ermöglicht
werden:
\begin{DIFnomarkup}\begin{code}
(' 1 2 3)     =>   [Symbol "1", Symbol "2", Symbol "3"]
(' (1 2 3))   =>   [Node [Symbol "1", Symbol "2", Symbol "3"]]
\end{code}\end{DIFnomarkup}

Ein weiteres Problem aller Lisp-Dialekte ist der Umgang mit
verschachtelten Quasiquotes, welche typischerweise entstehen, wenn aus
Makros wieder Makros generiert werden. Beispielsweise könnten zwei
verschachtelte Makros in Common Lisp durch
\begin{code}
(defmacro x ()
  `(defmacro y (a)
      `(foo ,a)))
\end{code}
gegeben sein. Hier ist \icode{a} ein Parameter des inneren Makros und es
wird mit \icode{,a} das innere Quasiquote aufgehoben. Soll \icode{a}
stattdessen ein Parameter des äußeren Makros sein, muss das äußere
Unquote aufgehoben werden:
\begin{code}
(defmacro x (a)
  `(defmacro y ()
      `(foo ,',a)))
\end{code}
Aufgrund der Lisp-Evaluationsregeln muss \icode{,',a} verwendet werden
-- dies ist auch die einzige Verwendung, für die Common Lisp den
(Nicht-Quasi-)Quote-Operator wirklich benötigt. Es gibt noch weitere
Fälle dieser Art, und nur die wenigsten Lisp-Programmierer beherrschen
all diese Konstrukte vollständig.

MagicL geht hier einen einfacheren Weg: Es werden neben den normalen
Quote-Operatoren \icode{' , ,@} anders benannte Operatoren \icode{'1 ,1
  ,@1} etc. angeboten, so dass die Quote-Unquote-Zuordnung immer
eindeutig ist. Damit wird das erste Beispiel durch
\begin{code}
(defmacro x ()
  (' (defmacro y (a)
       ('1 (foo (,1 a))))))
\end{code}
und das zweite durch
\begin{code}
(defmacro x (a)
  (' (defmacro y ()
       ('1 (foo (, a))))))
\end{code}
ausgedrückt, was deutlich intuitiver ist. Für den Vergleich mit Common
Lisp wurde hier ebenfalls \icode{defmacro} verwendet, obwohl es 
diesen Operator in MagicL nicht gibt\footnote{Es ist allerdings vorstellbar,
  zukünftig zur Vereinfachung wieder ein \icode{defmacro}
  bereitzustellen, was in den entsprechenden MagicL-Code übersetzt
  werden kann.}. Stattdessen werden die Operatoren \icode{mac} und
\icode{automac} angeboten, welche im nächsten Abschnitt erläutert
werden.

\lsubsection[sexpcomp:spec:comp]{Makro-Definition}

Die Definition von Lisp-Makros (vom Typ \icode{LispMacro = SexpParser [Sexp]}) ist mit
den bisherigen Mitteln bereits möglich:
\begin{DIFnomarkup}\begin{code}
(hasType compPredefine LispMacro)
(= compPredefine (macro (Str predefine)
                     (liftA1 gen compSymbol)
                   (where (= (gen name)
                             (' (= (, name) undefined))))))

\end{code}\end{DIFnomarkup}
Dieses Beispielmakro ermöglicht es, \icode{(predefine myVar)} statt
\icode{(= myVar undefined)} zu verwenden. Das Makro \icode{mac} bietet
für die Definition von Lisp-Makros etwas ``syntaktischen Zucker'' und
beinhaltet bereits die Typdefinition:
\begin{DIFnomarkup}\begin{code}
(mac compPredefine predefine
     (liftA1 ...)
   (where ...))
\end{code}\end{DIFnomarkup}
Hier muss zwischen dem Compiler-Namen \icode{compPredefine} und dem
Symbolnamen \icode{predefine} für den Makroaufruf unterschieden werden,
da ersterer eine Haskell-Variable erzeugt und damit Sonderzeichen wie
\icode{-} ausschließt.

Diese Makros müssen immer explizit aufgerufen werden und unterscheiden
sich damit von Lisp-Makros, die in einer globalen Liste verwaltet und
automatisch gegen jeden zu expandierenden Ausdruck geprüft und bei
Namensgleichheit angewendet wird \sees{template:lisp}. Beide Ansätze
haben Vor- und Nachteile: Der direkte Aufruf bringt eine höhere
Flexibilität und ermöglicht die in \sref{reqs:template} geforderderten
lokalen Makros. Lisp-Makros sparen dafür in Fällen, wo globale Makros
unproblematisch sind, unnötige Schreibarbeit. Aus diesem Grund stellt
MagicL zusätzlich den Operator \icode{autoMac} bereit, mit dem (für
einen Compiler) globale und automatisch expandierte Makros definiert
werden können:
\begin{DIFnomarkup}\begin{code}
(autoMac compSomething something
    (compileSomething)
  (where ...))
\end{code}\end{DIFnomarkup}
\icode{autoMac} erwartet an erster Stelle weiterhin einen Haskell-Namen
, obwohl dieser im Normalfall aufgrund der automatischen Anwendung nicht
benötigt wird. Es gibt allerdings besondere Situationen, in denen ein
direkter Aufruf dennoch erforderlich ist. Allgemein ist die Definition
mittels \icode{mac} sowie \icode{autoMac}, verglichen mit
\icode{defmacro} in Common Lisp, etwas umständlicher, da neben dem
Haskell-Namen der Parser explizit aufgeschrieben werden muss, selbst
wenn nur eine feste Anzahl von Ausdrücken mittels \icode{take}
unverändert eingelesen werden muss. Auf der anderen Seite sind die
MagicL-Operatoren allgemeiner, da nicht nur benannte Knoten, sondern
beliebige Listen von Ausdrücken verarbeitet werden können. Darüber
hinaus ist MagicL durch Makros einfach erweiterbar, so dass -- wenn
gewünscht -- noch immer ein \icode{defmacro} definiert werden kann,
welches den einfachsten Fall mit wenig Aufwand abdeckt. Dafür könnte
beispielsweise der Ausdruck
\begin{DIFnomarkup}\begin{code}
(defmacro (addThree x y z)
  (' (+ (,x) (,y) (,z))))
\end{code}\end{DIFnomarkup}
übersetzt werden in
\begin{DIFnomarkup}\begin{code}
(autoMac generatedSymbol156 addThree
   (liftA3 gen take take take)
  (where (= (gen x y z)
            (' (+ (,x) (,y) (,z))))))
\end{code}\end{DIFnomarkup}
Bisher wird \icode{defmacro} nicht bereitgestellt, da noch nicht klar
ist, welches die beste Art für MagicL ist, kurz und prägnant Makros zu
definieren. Es ist beispielsweise vorstellbar, dass sich ein Konstrukt
finden lässt, der die Eleganz und Knappheit von \icode{defmacro} mit der
Ausdrucksmächtigkeit von \icode{autoMac} kombiniert -- dies wird in
\sref{disc:sexp} weiter diskutiert.

Für die einfachere Moduldefinition von Compilern steht der Operator
\icode{compiler} bereit, welches alle benötigten MagicL-Imports
automatisch einbindet. Beispielsweise wird
\begin{DIFnomarkup}\begin{code}
(compiler Comp2Haskell (imports Data.Maybe Data.List)  
\end{code}\end{DIFnomarkup}
in folgenden Haskell-DSL-Code übersetzt:
\begin{DIFnomarkup}\begin{code}
(module
  Comp2Haskell
  (Prelude (hiding id lines words take))
  Data.IORef
  (Control.Category (only id))
  Control.Arrow
  System.IO.Unsafe
  Util
  Arrows
  Sexp
  Parser
  Model
  Data.Maybe
  Data.List)
\end{code}\end{DIFnomarkup}

\lsection[sexpcomp:impl]{Implementation des Compiler-Compilers}

Der Compiler für die Compiler-DSL sollte selbst möglichst einfach
formuliert werden. Da \sexps{} verarbeitet werden, macht eine
Implementation als \icode{SexpParser} Sinn. Darüber hinaus werden aber
auch \sexps{} erzeugt, so dass hier auch Quasiquote-Notation und
Lisp-Makros bereits nützlich wären. Es wird sich daher um einen
metarekursiven Compiler handeln, d.h. einen Compiler, der sich selbst
übersetzt. Um hier das Henne-Ei-Problem zu lösen, wird wie im
Compilerbau üblich später ein Bootstrapping\footnote{Der Begriff
  Bootstrapping ist eine Anspielung auf Baron Münchhausen, der sich an
  seinen Schnürsenkeln aus dem Sumpf gezogen haben will.} erforderlich
sein. Metarekursive Programme sind in der Lisp-Welt nicht unüblich --
bereits der erste LISP\footnote{LISP ist der erste Dialekt der
  Sprachfamilie Lisp.}-Interpreter wurde als \icode{eval}-Funktion in
LISP selbst implementiert und dann manuell in Maschinensprache übersetzt
\cite{LispHistory}. Ein anderes prominentes Beispiel ist das Common Lisp
Object System (CLOS) \cite{MetaobjectProtocol}, welches selbst
objektorientiert mit CLOS implementiert ist und über Makros in ein
``objektfreies Common Lisp'' übersetzt werden kann.

Gehen wir also zunächst davon aus, solch ein Compiler wäre bereits
vorhanden und könnte für die Implementation genutzt werden. Die
Verarbeitung des Quasiquote-Operators lässt sich dann durch ein komplexes
Auto-Makro realisieren:
\begin{DIFnomarkup}\begin{code}
(autoMac compQuote ' inners
  (where
    ...
\end{code}\end{DIFnomarkup}
\icode{inners} muss beliebig viele \sexps{} verarbeiten und daraus einen
Haskell-Ausdruck erzeugen, der eine Liste von \sexps{}
repräsentiert:
\begin{DIFnomarkup}\begin{code}
    (hasType inners LispMacro)
    (= inners
       (>>^ (many (<+> unquoteAll 
                       (>>^ inner quoteList)))
            (>>> concat quoteAppend)))
\end{code}\end{DIFnomarkup}
\icode{inners} erwartet jeweils entweder ein Unquote-All oder einen
einzelnen Ausdruck, welcher mit \icode{inner} verarbeitet wird. Alle
normalen Ausdrücke werden mit \icode{quoteList} in eine Liste
eingebettet und anschließend durch \icode{quoteAppend} mit \icode{++}
verknüpft, um die Semantik vom Unquote-All zu erreichen. Beispielsweise
wird \icode{inners} die Ausdrücke 
\begin{DIFnomarkup}\begin{code}
1 2 (,@ xs) 6  
\end{code}\end{DIFnomarkup}
wie folgt in die Haskell-DSL übersetzen:
\begin{DIFnomarkup}\begin{code}
(++ (List (Symbol (Str 1)))
    (List (Symbol (Str 2)))
    xs    
    (List (Symbol (Str 6))))
\end{code}\end{DIFnomarkup}
\icode{inner} verarbeitet einen einzelnen Ausdruck und gibt als Ergebnis
Haskell-DSL-Code für einen \sexp{} zurück:
\begin{DIFnomarkup}\begin{code}
    (hasType inner LispMacro)
    (= inner (<+> unquote    
                  (>>^ takeSymbol quoteSymbol)     
                  (>>^ (compNode inners) quoteNode)))
\end{code}\end{DIFnomarkup}
\icode{inner} erwartet entweder ein Unquote, ein Symbol oder einen
Knoten. Symbole werden durch die Funktion \icode{quoteSymbol} quotiert,
Knoten rekursiv mit \icode{inners} verarbeitet und anschließend als
Knoten quotiert. \icode{unquote} und \icode{unquoteAll} sind bis auf die
verschiedenen Matcher-Symbole identisch und verarbeiten einen einzigen
\sexp{}, den sie mit der Funktion \icode{single x = [x]} in eine Liste
einbetten um dem Rückgabetyp \icode{[Sexp]} für Lisp-Macros zu
entsprechen:
\begin{DIFnomarkup}\begin{code}
    (mac unquote    ,  (>>^ take single))
    (mac unquoteAll ,@ (>>^ take single))
\end{code}\end{DIFnomarkup}
Alle vier Funktionen zur Quotierung von Haskell-DSL-Ausdrücken
können selbst mit einem Quote implementiert werden:
\begin{DIFnomarkup}\begin{code}
    (= (quoteSymbol sym)
       (' (Symbol (Str (, (Symbol sym))))))
    (= (quoteNode sexps)
       (' (Node (,@ sexps))))
    (= (quoteList sexps)
       (' (List (,@ sexps))))
    (= (quoteAppend sexps)
       (' (++ (,@ sexps))))))
\end{code}\end{DIFnomarkup}
\icode{quoteSymbol} erzeugt die Repräsentation eines Symbols, indem es
Aufrufe von \icode{Symbol} und \icode{Str} auf Haskell-DSL-Ebene
ineinander verschachtelt. Auf der Ebene der Metasprache wird ein
weiterer Aufruf von \icode{Symbol} benötigt, um den String \icode{sym}
in einen \sexp{} umzuwandeln. Generell muss jedes Argument eines Unquote
vom Typ \icode{Sexp} und jedes Argument eines Unquote-All vom Typ
\icode{[Sexp]} sein. Die anderen drei Quote-Funktionen erzeugen jeweils
einen benannten Knoten, in den sie alle als Liste übergebenen Ausdrücke
einfügen, und unterscheiden sich nur im erzeugten Knotennamen.

Damit ist die Implementation vom Quasiquote abgeschlossen. Die
Definitionen der benannten Varianten wie \icode{'1} sind bis auf
die benutzten Makro-Matcher \icode{'1 ,1 ,@1} etc. statt \icode{' , ,@}
identisch. Um Code-Duplikation zu vermeiden, benutzt MagicL hier
ebenfalls ein Makro, welches alle Operatoren \icode{'}
bis \icode{'3} aus einem einzigen Template definiert.

Der Operator \icode{mac} lässt sich einfach implementieren:
\begin{DIFnomarkup}\begin{code}
(autoMac compMac mac
  (liftA4 gen take take take (many take))
  (where (= (gen fun sym cmd cmds)
            (' (hasType (, fun) LispMacro)
               (= (, fun) (macro (Str (, sym)) (, cmd)) (,@ cmds))))))  
\end{code}\end{DIFnomarkup}
Damit wird beispielsweise 
\begin{DIFnomarkup}\begin{code}
(mac compSomething macroName 
    (doSomething ...) 
  (where ..))
\end{code}\end{DIFnomarkup}
nach
\begin{DIFnomarkup}\begin{code}
(hasType compSomething LispMacro)
(= compSomething (macro (Str macroName)
                   (do-something ...))
  (where ...))
\end{code}\end{DIFnomarkup}
übersetzt. Die Implementation von \icode{autoMac} ist
schwieriger. Zunächst muss dafür die Makroexpansion-Funktionsweise von
Common Lisp nachgebildet werden, welche versucht, eine (in Lisp globale)
Liste von Makros verodert auf den Eingabe-Stream anzuwenden. Ist die
Anwendung eines der Makros erfolgreich, wird dessen Rückgabe erneut als
Eingabe der Makro-Liste verarbeitet. Kann keines der Makros auf einen
Knoten angewendet werden, wird versucht, dessen Kinder zu
expandieren. Symbole werden in diesem Fall unverändert
zurückgegeben. Dieses Verhalten wurde in MagicL in der Haskell-Funktion
\icode{lispTraverse}\footnote{\icode{lispTraverse} ist eigentlich Teil
  der \sexp{}-Bibliothek, wird allerdings erst hier vorgestellt da dies
  thematisch besser passt.} implementiert:
\begin{DIFnomarkup}\begin{code}
lispTraverse :: [LispMacro] -> LispMacro
lispTraverse macs = combinedMacs
  where combinedMacs = many (foldr (<+>) defaultMac recMacs) >>^ concat
        recMacs      = map (\ m -> applyParser m combinedMacs) macs
        defaultMac   = ((compSymbol >>^ single) <+> 
                        (compNode combinedMacs >>^ (Node >>> single)))  
\end{code}\end{DIFnomarkup}
Die Eingabeliste \icode{macs :: [LispMacro]} wird in das Ausgabemakro
\icode{combinedMacs} umgewandelt, indem alle Makros aus \icode{recMacs}
und zuletzt \icode{defaultMac} verodert werden. \icode{recMacs} entsteht
aus \icode{macs}, indem jedes darin enthaltene Makro \icode{m} mittels
\icode{applyParser} derart modifiziert wird, dass seine Ausgabe im
Erfolgsfall wieder als Eingabe für \icode{combinedMacs} benutzt
wird. \icode{defaultMac} lasst Symbole unverändert und steigt rekursiv
in Knoten hinab. Alle Aufrufe von \icode{concat} und \icode{single} in
\icode{lispTraverse} werden benötigt, um den Ausgabetyp \icode{[Sexp]}
zu bekommen.

Auto-Makros können nun mit Hilfe von \icode{lispTraverse} realisiert
werden. Dafür müssen zunächst alle in einem Compiler verwendeten
\icode{autoMac}-Deklarationen gefunden und deren Haskell-Name gemerkt
werden. Anschließend wird ein Makro namens \icode{compAuto} erzeugt,
welches alle gefundenen Namen an \icode{lispTraverse}
übergibt. Da das Scannen von Auto-Makros bereits vor der
normalen Makroexpansion von \icode{autoMac} geschieht, kann
\icode{autoMac} selbst sich genau wie \icode{mac} verhalten.

Auf die konkrete Implementation des Toplevel-Compiler-Compilers wird an
dieser Stelle nicht weiter eingegangen -- sie kann dem MagicL-Code
für das Modul \icode{Comp2Haskell} entnommen werden.

\lsection[sexpcomp:example]{Beispiel: Ein Slide-Compiler}

Als Beispiel wird ein primitiver, aber vollständiger Compiler angegeben,
der eine Slide-DSL in eine Latex-DSL übersetzt. Beispielsweise
soll der Slide-Code
\begin{code}
(presentation (text My Presentation)
  (slide First
     (list one two three))
  (slide (text Second Slide)
     (list foo
           bar
           (text Hello World))))
\end{code}
in den Latex-DSL-Code
\begin{code}
(cmd documentclass beamer)
(cmd title (text My Presentation))
(env document
  (cmd maketitle)
  (env (frame First)
    (env itemize
       (cmd item) one
       (cmd item) two
       (cmd item) three))
  (env (frame (text Second Slide))
    (env itemize
       (cmd item) foo
       (cmd item) bar
       (cmd item) (text Hello World))))
\end{code}
übersetzt werden, woraus ein fiktiver Latex-DSL-Compiler den Latex-Ausgabecode
\begin{code}
\documentclass{beamer}
\title{My Presentation}
\begin{document}
  \maketitle
  \begin{frame}{First}
    \begin{itemize}
    \item one
    \item two
    \item three
    \end{itemize}
  \end{frame}
  \begin{frame}{Second Slide}
    \begin{itemize}
    \item foo
    \item bar
    \item Hello World
    \end{itemize}
  \end{frame}
\end{document}
\end{code}
generieren könnte, aus dem schließlich die in \abb{pres_pdf} gezeigte
Präsentation erzeugt wird.
\begin{figure}[h]
  \fbox{\includegraphics[scale=0.385]{images/testPres}}
  \fbox{\includegraphics[scale=0.385, page=2]{images/testPres}}
  \fbox{\includegraphics[scale=0.385, page=3]{images/testPres}}
  \caption{Die fertige Beispielpräsentation}
  \label{magicl:fig:pres_pdf}
\end{figure}
Der Slide-Compiler kann mit MagicL wie folgt implementiert werden:
\begin{DIFnomarkup}\begin{code}
(compiler SlideCompiler)

(mac compPres presentation
  (liftA2 genPres take (>>^ (many slide) concat)
  (where (= (genPres title slides)
            (' (cmd documentclass beamer)
               (cmd title (, title))
               (env document
                 (cmd maketitle)
                 (,@ slides)))))))

(mac compSlide slide
  (liftA2 genSlide take compAuto)
  (where (= (genSlide title contents)
            (' (env (frame (, title))
                 (,@ contents))))))

(autoMac compList list
  (>>^ compAuto genList)
  (where 
    (= (genList items)
       (' (env itemize
            (,@ (concat (map genItem Items))))))
    (= (genItem text)
       (' (cmd item)
          (, text)))))

(= slideCompiler compPres)  
\end{code}\end{DIFnomarkup}
Hierbei werden sowohl normale als auch Auto-Makros verwendet. An
äußerster Stelle darf nur ein \icode{presentation}-Knoten vorkommen, der
daher als Makro realisiert wurde und einen Präsentationstitel sowie
beliebig viele \icode{slide}-Knoten enthält. Dieses Makro erzeugt eine
Dokumentklassendeklaration, setzt den Titel und bettet die Folien in
eine \icode{document}-Umgebung ein wie in Latex erforderlich. Da Folien
nur direkt im \icode{presentation}-Knoten vorkommen dürfen, werden diese
ebenfalls mit einem gewöhnlichen Makro verarbeitet, welches einen Titel
und beliebig viel Inhalt erwartet und daraus eine \icode{frame}-Umgebung
erzeugt. Alle Folieninhalte werden mit Auto-Makros kompiliert, da hier
normalerweise beliebige Verschachtelungen zugelassen werden
sollen. Zudem können so später weitere Makros wie z.B. \icode{image}
hinzugefügt werden, ohne das \icode{slide}-Makro anpassen zu
müssen. Diese primitive Version die Slide-DSL enthält mit \icode{list}
nur einen einzigen Befehl für Folieninhalte, welcher in eine
entsprechende \icode{itemize}-Umgebung übersetzt wird. Allerdings kann
im Folieninneren bereits beliebiger Latex-DSL-Code integriert werden, so
dass auch hiermit bereits sinnvolle Präsentationen möglich sind.  Die
Definition von \icode{slideCompiler} als \icode{compPres} dient
lediglich der Klarheit beim Aufruf aus externen Modulen.

\lsection[sexpcomp:sum]{Zusammenfassung}

Für benutzerdefinierte Compiler bietet MagicL die Compiler-DSL an, die
eine Erweiterung der Haskell-DSL ist, so dass eine Haskell-Variante in
\sexp{}-Syntax als Metaprogrammiersprache verwendet werden kann. Darüber
hinaus beinhaltet die Compiler-DSL für die Verarbeitung von \sexps{}
einen Quasiquote-Operator \icode{'} sowie ein Lisp ähnliches
Makrosystem. Der Quote-Operator unterscheidet sich in einer Reihe von
Punkten von bestehenden Lisps: Zunächst wird nicht zwischen Quote und
Quasiquote unterschieden, da der einzige Fall, in dem beispielsweise
Common Lisp ein gewöhnliches Quote benötigt, die komplizierte Auflösung
von Unquotes in verschachtelten Quasiquotes ist. Dieses Problem wird in
MagicL jedoch einfach durch die Existenz verschieden benannter
Quote/Unquote/Unquote-All Tripel wie \icode{'1 ,1 ,@1} gelöst. Ein
weiterer Unterschied ist, dass Makros und Quotes nicht einen einzelnen
Ausdruck, sondern immer eine Liste von \sexps{} zurückliefern, die vom
Makrosystem mittels Splicing in die Ausgabe eingefügt wird. Auf diese
Weise können Makros auch mehrere oder gar keine Ausdrücke zurückliefern,
was die Ausdrucksmächtigkeit erhöht. Während normale Makros in MagicL
gezielt über ihren Haskell-Namen aufgerufen werden, erlauben Auto-Makros
die für Lisp typische automatische Auswertung an beliebiger Tiefe sowie
die wiederholte Makroexpansion von Rückgabeausdrücken anderer Makros.

\lchapter[disc]{Diskussion}

Dieses Kapitel diskutiert MagicL in Hinblick auf die Anforderungen aus
\cref{reqs} und seine Vor- und Nachteile gegenüber bestehenden
Werkzeugen. Gegliedert ist die Diskussion nach den drei unterstützten
Modelltypen, deren Verwendung jeweils erörtert wird. Anschließend wird
auf die allgemeine Schnittstelle für Compiler eingegangen.

\lsection[disc:string]{Zeichenketten}

Zeichenketten können mit Hilfe der Parser-Bibliothek eingelesen
werden. Parserdefinitionen sind syntaktisch etwas aufwändiger als eine
EBNF-Grammatik. Beispielsweise würde die EBNF-Definition
\begin{code}
Zahl = [ '-' ] ZifferAusserNull { Ziffer }  | '0' 
\end{code}
durch den Parser
\begin{code}
(= zahl (<+>
          (>>> (optional (eq '-'))
               zifferAusserNull
               (many ziffer))
          (eq '0')))            
\end{code}
abgebildet werden. Andererseits sind Parser deutlich mächtiger als
Grammatiken, da hier nicht nur zwischen akzeptiert und nicht akzeptiert
unterschieden wird, sondern gleichzeitig eine Verarbeitung zu einer
Ausgabe erfolgt. Zudem ermöglichen Parser die Definition eigener
Kombinatoren wie \icode{commaSep} für Komma-separierte Listen, welche
komplexe Definitionen deutlich vereinfachen können. 

Ähnlich verhält es sich mit der Erzeugung von Zeichenketten, die statt
durch Templates rein funktional geschieht. Auf der einen Seite ist dies
bei einfachen Beispielen umständlicher und auch weniger lesbarer als
beispielsweise die Verwendung von StringTemplate
\sees{template:stringtemplate}. Ein Generator, der aus einem Namen und
einer Liste von Methoden eine Java-Klasse erzeugt, kann mit StringTemplate
durch
\begin{code}
genClass = new StringTemplate("public class $name$ {
  $methods; separator=\"\n\n\"$
}");
\end{code}
in einem Java-Programm beschrieben werden. Mit MagicL müsste derselbe
Generator als
\begin{code}
(= (genClass name methods)
   (words (List (text (Str public class))
                name
                (braces (paragraphs methods)))))
\end{code}
spezifiziert werden, was deutlich aufwändiger wirkt. Auf der anderen
Seite sind Generatoren in MagicL gewöhnliche Haskell-Funktionen, wodurch
der Aufruf mit
\begin{code}
layout 80 (genClass className classMethods)  
\end{code}
einfacher als in StringTemplate, wo die Befehle
\begin{code}
genClass.setAttribute("name", className);
genClass.setAttribute("methods", classMethods);
genClass.toString();
\end{code}
benötigt werden. So können MagicL-Generatoren einfacher in viele kleine,
wiederverwendbare Komponenten aufgeteilt werden und entsprechend dem
funktionalen Paradigma mit Funktionen höherer Ordnung kombiniert
werden. Eine genauere Bewertung kann erst vorgenommen werden, wenn beide
Systeme für die Definition von komplexen Code-Generatoren
vewendet wurden. Auf jeden Fall aber wäre es möglich, Code-Generierung
in MagicL durch eine Code-DSL noch weiter zu vereinfachen.

Die Zeichenketten-Ebene muss vom Meta-Programmierer allerdings nur für
die Unterstützung neuer externer Ein- und Ausgabeformate betreten
werden. Im Idealfall, d.h. wenn ausschließlich \sexp{}-DSLs verwendet
werden, alle Backends für zu generierende Zielsprachen bereits vorhanden
sind und die Verarbeitungsalgorithmen nicht so komplex sind, dass
getypte Objekte benötigt werden, können Compiler komplett auf der
einfachen \sexp{}-Ebene spezifiziert werden.

\lsection[disc:sexp]{\sexps{}}

\sexps{} werden ebenfalls durch Parser verarbeitet, welche allgemeiner
und mächtiger sind als gewöhnliche Lisp-Makros, letztere aber dennoch
als Spezialfall einschließen. Dies ermöglicht beispielsweise lokale
Makros oder Übersetzer, die nicht auf genau einen Knotennamen
anspringen, sondern beispielsweise alle binären Operatoren einer
Sprache. Die größere Allgemeinheit und Kontrolle geht allerdings derzeit
mit etwas erhöhtem Aufwand für die einfachen, in bestehenden Lisps
unterstützen Fälle einher. Beispielsweise könnte ein Makro, welches eine
Foliendefinition der Slide-DSL in die Latex-DSL übersetzt, die
Eingabe
\begin{code}
(slide MySlideTitle
  (image image.png)
  (list one two three))
\end{code}
in die Ausgabe
\begin{code}
(env (frame MySlideTitle)
  (image image.png)
  (list one two three))
\end{code}
überführen\footnote{Im Gegensatz zum Beispiel in \sref{sexpcomp:example}
  wird hier angenommen, dass die Latex-DSL bereits einen
  \icode{list}-Befehl enthält, so dass dieser nicht übersetzt werden
  muss.}. Ein derartiges Makro wäre in Common Lisp durch
\begin{code}
(defmacro slide (title &rest contents)
  `(env (frame ,title)
     ,@contents))
\end{code}
gegeben. Hier wurden die Variablen \icode{title} und \icode{contents}
von Lisp an den ersten bzw. alle weiteren Parameter gebunden. Mit der
Compiler-DSL hingegen würde das Makro als 
\begin{code}
(mac compSlide slide
  (liftA2 genSlide take (many take))
  (where (= (genSlide title contents)
            (' (env (frame (, title))
                 (,@ contents))))))
\end{code}
definiert werden, wo explizite Aufrufe von \icode{take} bzw. \icode{many
  take} benötigt werden und per \icode{liftA2} an eine Funktion
übergeben werden müssen, um den selben Effekt zu erzielen. Es wäre daher
durchaus wünschenswert, die Compiler-DSL noch weiter zu vereinfachen,
allerdings ist nicht klar wie genau dies aussehen soll. Es könnte
beispielsweise ein komplett mit Common Lisp übereinstimmendes
\icode{defmacro} angeboten werden, welches kurze Definitionen
ermöglicht, im Gegenzug aber an Allgemeinheit verliert. Welche Sprache
wirklich den besten Kompromiss zwischen Allgemeinheit und Programmkürze
ermöglicht bleibt daher eine offene Frage, die sich vermutlich erst nach
häufiger Verwendung näher beantworten lassen wird.

Generierung von \sexps{} erfolgt mit dem Quasiquote-Operator, der im
Gegensatz zu Lisp keine eigene Syntax benutzt, sondern an gewöhnliche
\sexp{}-Notation angepasst wurde. Dieser Operator enthält zwei
Verbesserungen gegenüber Lisp. Zum einen ist es damit möglich, aus einem
Makro mehrere Ausdrücke zu erzeugen, die alle per Splicing an der
ursprünglichen Stelle eingefügt werden. Beispielsweise wäre es
praktisch, in der Slide-DSL mehrere gleichbenannte, automatisch nummerierte
Folien mit dem Befehl \icode{multi-slide} definieren zu können, so dass
\begin{code}
(multi-slide Title
  (s (items one two three))
  (s (image diagram.png)
     (text This is a diagram)))    
\end{code}
übersetzt würde nach
\begin{code}
(slide (text Title 1)
  (items one two three))

(slide (text Title 2)
  (image diagram.png)
  (text This is a diagram))      
\end{code}
Ein derartiges Makro ist in MagicL möglich, in Lisp hingegen nicht. Dort
müsste die Slide-DSL wie Lisp selbst einen \icode{progn}-Befehl
enthalten, der es ermöglicht, mehrerere Ausdrücke zu einem
zusammenzufassen, so dass die Ausgabe nun von der Form
\begin{code}
(progn
  (slide ...)
  (slide ...))
\end{code}
wäre. Manchmal ist es auch erforderlich, aus einem Makro überhaupt keine
Ausgabe zu erzeugen. Beispielsweise könnte eine DSL Kommentare der Form
\icode{(comment ...)} an beliebigen Stellen zulassen, die vom Compiler
ignoriert werden sollen. Dies kann in MagicL durch ein simples Makro mit
einem leeren Quasiquote erreicht werden:
\begin{code}
(autoMac compComment comment
  (liftA1 genComment (many take))
  (where (= (genComment comments)
            ('))))
\end{code}
In Lisp ist derartiges selbst mit \icode{progn} nicht möglich, da ein
leeres \icode{progn} gleichbedeutend mit \icode{nil} ist, welches von
Lisp an vielen, aber nicht allen Stellen ignoriert wird, so dass auf
diese Weise z.B. keine Kommentare in Parameterlisten vorkommen dürften.

Der andere Vorteil des MagicL-Quasiquotes zeigt sich, falls mittels
Quasiquote Code generiert werden soll, der selbst Quasiquotes
enthält. Dies wäre beispielsweise dann der Fall, wenn Benutzer selbst
Erweiterungen für die Compiler-DSL implementieren wollen. In Common Lisp
sind verschachtelte Quasiquotes teilweise sehr schwierig zu verstehen
\sees{sexpcomp:spec:comp}. MagicL löst dieses Problem hingegen einfach
durch die Bereitstellung verschieden benannter Quote/Unquote-Paare.

\lsection[disc:object]{Objekte}

Mit der in die Compiler-DSL integrierte Haskell-DSL bietet MagicL eine
statisch typisierte Programmiersprache an, mit der komplexere
Algorithmen elegant im funktionalen Paradigma realisiert werden
können.

Programme in der Haskell-DSL sind aufgrund der Umsetzung auf reine
\sexps{} ohne weitere Syntax etwas länger als Haskell-Programme selbst,
so dass beispielsweise der Haskell-Ausdruck \icode{["a" "b" "c"]} in der
DSL als \icode{(List (Str a) (Str b) (Str c))} geschrieben wird. Dies
ist der Nachteil, der mit der leichteren Generierbarkeit von Code sowie
der reibungslosen Integrierbarkeit mit anderen DSLs einhergeht. Es wäre
durchaus möglich, die \sexp{}-Syntax um Notationen für Strings und
Arrays erweitern. Damit die Modellkomplexität dabei nicht zunimmt,
könnte diese Syntax von einem Präprozessor wieder auf \sexps{}
abgebildet werden, so dass beispielsweise \icode{[a b]} denselben
\sexp{} ergibt wie \icode{(List a b)} -- einen derartigen Präprozessow
können MagicL-Nutzer auch selbst implementieren. Es ist allerdings nicht
einfach zu entscheiden, welche zusätzliche Syntax für alle DSLs
gleichzeitig optimal ist. DSL-spezifische Zusatzsyntax hingegen würde
die Integration verschiedener DSLs erschweren und gewissermaßen die
Grundidee von MagicL ad absurdum führen. Ein alternativer Ansatz wäre
die Beibehaltung der puren \sexps{} und die Bereitstellung einer
Entwicklungsumgebung, die DSL-spezifische Anzeige- und Bearbeitungsmodi
anbietet, die bestimmte Ausdrücke benutzerfreundlich visualisieren
können. Auf diesen Gedanken wird in \sref{end:disc:ide} weiter
eingegangen.

\lsection[disc:compinterface]{Compiler-Schnittstelle}

MagicL's modellspezifische Hilfsmittel sind frei miteinander
kombinierbar. Beispielsweise können Parser auf \sexps{} oder Strings
beliebige Haskell-Objekte zurückliefern, oder Haskell-Funktionen
\sexps{} mittels Quasiquote und Strings mittels Generator-Bibliothek
erzeugen. Alle mit MagicL definierbaren Compilertypen lassen sich
hintereinanderschalten, indem sie zunächst mit \icode{toIO} in Arrows
der Kategorie von Funktionen mit Nebeneffekten umgewandelt und
anschließend mittels \icode{>>>} verknüpft werden. Dies führt gemeinsam
mit dem Ansatz vieler, teilweise ineinander übersetzbarer
\sexp{}-basierter DSLs zu einer starken Komponententrennung, bei der
Compiler und DSLs häufit wiederverwendet werden können. 

Ein experimentelles Feature von MagicL's generischer
Compilerschnittstelle ist die Möglichkeit, spezielle Compiler fest als
Standardcompiler zwischen zwei Typen zu verdrahten.  Damit ist es unter
anderem möglich, Parser für ein zusammengesetztes Modell mit vielen
Untertypen auf eine Weise zu konstruieren, bei der Aufrufe von
Sub-Parsern nicht explizit, sondern implizit durch Typinferenz erfolgen,
was das Schreiben derartiger Parser erleichtern kann. Außerdem können
automatisch Standardparser für Listen und optionale Werte aus normalen
Parsern abgeleitet werden, wobei die abgeleiteten Standardparser durch
die Parserkombinatoren \icode{many} und \icode{optional} aus den
Ursprünglichen entstehen. Die Notation für derartige Standardcompiler
ist allerdings noch etwas umständlich, wie die Umsetzung des
Haskell-DSL-Compilers in \cref{sexphs} zeigt -- hier könnte eine
Erweiterung der Compiler-DSL helfen. Ein größeres Problem ist, dass die
-- recht komplizierte -- Realisierung dieses Features mit der Typklasse
\icode{Compilable} bereits an die Grenzen von Haskells Typsystem stößt,
so dass bereits nicht-standardisierte Erweiterungen des
Haskell-Compilers GHC \cite{Ghc} benötigt werden. Auch ist es aufgrund
von Einschänkungen im Typsystem nicht möglich, automatisch erzeugte
Listen-Standardcompiler mit eigenen Listen-Compilern zu
überschreiben. Eine Nachfolgeimplementierung von MagicL sollte daher
entweder auf ein derartiges Feature verzichten oder statt Haskell eine
dynamisch typisierte Programmiersprache verwenden.

\lsection{Zusammenfassung}

MagicL erfüllt alle in \cref{reqs} gestellten Anforderungen, wie
\abb{disc_reqs} zeigt. Als einziger Kritikpunkt bleibt die Länge von
Metaprogrammen, die noch nicht ganz mit Lisp konkurrieren kann. Daher
könnte die Compiler-DSL künftig um Konstrukte erweitert werden, die
bisher aufwändige Aufgaben vereinfacht. Da aber MagicL deutlich
allgemeiner ist als Lisp-Makrosysteme, können nicht einfach die dort
bestehenden Mechanismen eins zu eins übernommen werden - vielmehr kann
erst die Erfahrung mit mehr Anwendungsbeispielen zeigen, welche genauen
Ergänzungen sinnvoll sind. Diese Erweiterungen können MagicL-Nutzer auch
selbst implementieren, denn wie jedes Lisp ist MagicL selbst durch
Makros erweiterbar. Hierfür müsste lediglich ein Compiler definiert
werden, der die erweiterte Compiler-DSL in die bestehende übersetzt.

\begin{figure}[h]
\begin{tabular}{|l|l|l|} \hline
\bf Werkzeug                 & \bf MagicL                    & \bf erfüllt?  \\\hline\hline    
\bf Eingabemodell            & \sexp{} / beliebig            &     ja        \\\hline           
\bf Eingabevalidierung       & beliebig                      &     ja        \\\hline      
\bf Ausgabemodell            & \sexp{} / beliebig            &     ja        \\\hline      
\bf Ausgabevalidierung       & beliebig                      &     ja        \\\hline      
\bf Zielsprache              & beliebig                      &     ja        \\\hline      
\bf vollständiges Quasiquote & ja                            &     ja        \\\hline      
\bf Code-Objekt verfügbar    & ja                            &     ja        \\\hline      
\bf Sprachmächtigkeit        & maximal                       &     ja        \\\hline      
\bf Metaprogrammlänge        & kurz                          & ja, aber noch nicht optimal \\\hline
\bf Template-Aufruf          & verallgemeinertes Makro       &     ja        \\\hline      
\bf Komponententrennung      & unterstützt                   &     ja        \\\hline      
\bf Template-Generierung     & einfach durch \icode{'1} etc. &     ja        \\\hline      
\end{tabular}
\caption{Erfüllung der Anforderungen an MagicL}
\label{magicl:fig:disc_reqs}
\end{figure}

\lchapter[end]{Schluss}

Zum Abschluss wird die vorliegende Arbeit noch einmal
zusammengefasst. Anschließend werden im Ausblick weitere Ideen und
Ansatzpunkte für Fortsetzungsarbeiten vorgestellt.

\lsection[end:sum]{Zusammenfassung der Arbeit}

Ziel dieser Diplomarbeit ist die prototypische Entwicklung eines
universellen Frameworks namens MagicL zur \cgen{}, welches möglichst
viele Vorteile bestehender Technologien im Rahmen eines klaren,
einheitlichen Formalismus in sich vereint. Insbesondere die mächtigen
und praktischen Metaprogrammierungskonzepte der Lisp-Sprachfamilie haben
diese Arbeit inspiriert und sollten in einer verallgemeinerten Form
aufgegriffen werden.

Zunächst wurden hierfür in \cref{model} die Modelltypisierungsgrade
String, Objekt und Baumstruktur für die Repräsentation von Quelltext
behandelt mit dem Ergebnis, dass alle drei für spezielle Aufgaben
nützlich sind und daher gemeinsam verwendbar sein sollten: Während
Strings am Anfang und Ende der Verarbeitungskette benötigt werden,
ansonsten aber eine häufig zu niedrige, fehleranfällige Arbeitsebene
bedeuten, sind typisierte Objekte aufgrund ihrer Sicherheit und
Performanz für komplexere Verarbeitungsschritte geeignet, bringen
allerdings den Overhead der Deklaration sowie eine
Programmiersprachenabhängigkeit mit sich. Baumstrukturen bieten oft
einen Kompromiss aus Flexibilität und Strukturierung und sind daher für
einfache Verarbeitungsschritte geeignet, bei denen ein typisiertes
Modell übertrieben erscheint. Als konkrete Baumrepräsentation wurden
\sexps{} aufgrund ihrer Einfachheit und Redundanzfreiheit insbesondere
gegenüber XML vorgezogen.

In \cref{template} wurde eine Reihe von \cgen{}swerkzeugen vorgestellt
und verglichen. Gemein ist all diesen Werkzeugen die Benutzung des
Template-Konzepts, ansonsten sind die strukturellen Unterschiede
allerdings groß. Manche Frameworks können Code in beliebigen Sprachen
generieren, andere beschränken sich auf eine einzelne Sprache oder
Sprachfamilie. Alle drei Modelltypen aus \cref{model} werden in
verschiedenen Systemen verwendet, allerdings bietet keines diese
gleichzeitig an. Die Bandbreite der einzelnen Metasprachen reicht von
kaum mehr als dem bloßen Template-Formalismus aus Quasiquote und Unquote
bis hin zu vollständigen Programmiersprachen. Werkzeugen, in denen Meta- und
Zielsprache übereinstimmen oder übereinstimmen können, erlauben
prinzipiell auch die Generierung von Meta-Code selbst, woraus sich
interessante Möglichkeiten ergeben. Hier kann es allerdings zu einer
Mehrdeutigkeit bei der Auswertung von Unquotes kommen, die meist nur
umständlich umgangen werden kann. Das Aufrufen von Templates verläuft
meist explizit wie bei einem Funktionsaufruf. Alternativ treten auch
Makros auf, die implizit über den Namen des zu verarbeitenden Ausdrucks
zugeordnet werden. XSLT unterstützt hier sogar ein Pfad-basiertes
Matching.

Von den untersuchten Werkzeugen konnten Lisp-Makros aufgrund ihrer
Flexibilität, Mächtigkeit, Modularisierbarkeit und Einfachheit am
stärksten überzeugen. Lisp-Dialekte stellen jedoch noch kein
universelles \cgen{}swerkzeug da, da diese ausschließlich Lisp-Code
generieren können. Die Übertragung auf beliebige Zielsprachen ist daher
die wichtigste der in \cref{reqs} besprochenen Anforderungen. Auch
externe Eingabeformate sollten durch die Konstruktierbarkeit
spezifischer Parser unterstützt werden können. Darüber hinaus wurden
gegenüber Lisp weitere Verallgemeinerungen gefordert: So sollten neben
\sexps{} auch Strings und Objekte als Modelle verwendet werden können,
obwohl der Focus auf \sexps{} bleibt. Makros sollen sowohl explizit
aufrufbar sein als auch über ein Pattern-Matching auf dem zu
verarbeitenden Ausdruck, welches über einen Vergleich mit dem
Knotennamen hinausgeht. Auch ``lokale Makros'', welche nur im Kontext
anderer Makros ausgewertet werden, sollten realisierbar sein, um auf ein
komplexes ``Code-Walking'' -- wie in Lisp nötig -- möglichst verzichten zu
können.

Eine weitere Forderung war die Möglichkeit, Verarbeitungseinheiten wie
Makros, Parser und andere Compiler nach dem Baukastenprinzip auf
verschiedene Weisen und in einer Semantik kombinieren zu können. Die
theoretische Fundierung dieser Semantik liefert die Kategorientheorie,
deren Grundzüge in \cref{cats} vorgestellt wurden. Kategorien bestehen
aus Morphismen zwischen Objekten -- wobei beide Begriffe axiomatisch
definiert und somit zunächst bedeutungsneutral sind. Die häufigste
Interpretation für Morphismen und Objekte in der Mathematik sind
Funktionen und Mengen, im Rahmen dieser Arbeit kommen jedoch
ausschließlich Verarbeitungsprozesse und Typen vor. Kategorien können
anschaulich als Diagramme visualisiert werden. Innerhalb einer Kategorie
können neben der Komposition Produkte und Coprodukte verwendet werden,
um einfache Einheiten zu komplexeren zusammenzusetzen. Auch ganze
Kategorien können über Funktoren aufeinander abgebildet werden. Monaden
sind spezielle Funktoren auf einer Kategorie, die eine spezielle, durch
natürlichen Transformationen beschriebene Struktur besitzen.

Die funktionale Sprache Haskell, welche in \cref{haskell} präsentiert
wurde, bietet in ihren Bibliotheken mit den Typklassen \icode{Arrow} und
\icode{Monad} programmiersprachliche, auf Verarbeitungsprozesse
eingeschränkte Umsetzungen von Morphismen und Monaden. Dies ist einer
der Gründe, weshalb MagicL in Haskell implementiert wurde. Monaden und
Arrows sind aufgrund der Kleisli-Kategorie generell gegeneinander
austauschbar, wobei Arrows allerdings allgemeiner sind. Haskell selbst
verwendet häufig Monaden, mit denen die Verarbeitung bestimmter
parametrisierter Typen einheitlich beschrieben werden kann. Beispiele
hierfür sind Listen sowie Variablen, die Null-Pointer enthalten dürfen
sowie das Weiterreichen von Zuständen. Die \icode{IO}-Monade lässt sich
als versteckter, hypothetischer Welt-Zustand verstehen und wird in
Haskell verwendet, um Operationen mit Seiteneffekten in die ansonsten
pur funktionale Sprache integrieren zu können.

Die grundlegende Architektur von MagicL wurde in \cref{arch}
erläutert. Alle Compiler zwischen den drei unterstützten Modelltypen
lassen sind Arrows -- oder lassen sich in Arrows konvertieren -- und
können daher mit dem Kompositionsoperator \icode{>>>}
hintereinandergeschaltet werden, so dass Compiler oft in mehrere
wiederverwertbare Komponenten aufgeteilt werden
können. Benutzerdefinierte Compiler werden in einer Compiler-DSL
geschrieben, die mit der Haskell-DSL eine komplette funktionale
Programmiersprache enthält. Für die Verarbeitung von Zeichenketten
stehen eine Parser- sowie eine Generator-Bibliothek bereit. \sexps{}
werden ebenfalls durch Parser verarbeitet, was MagicL's Antwort auf die
Forderung verallgemeinerter Makros ist. Die Erzeugung von \sexps{}
erfolgt mit dem Quasiquote-Operator, dessen Syntax und Semantik sich
leicht von Lisp unterscheidet. Die Verarbeitung von getypten Objekten
geschieht durch gewöhnliche Haskell-Funktionen.

In \cref{arrowparser} wurde gezeigt, wie Parser-Arrows durch eine
Verschachtelung der einfachen Typen \icode{FailFunctor} und
\icode{StateFunctor} konstruiert werden können. \icode{FailFunctor}
kapselt hierbei die Möglichkeit, mit der Rückgabe einer Fehlermeldung zu
scheitern, während \icode{StateFunctor} die Weitergabe eines Zustandes
analog zur \icode{IO}-Monade beschreibt und für den Eingabe-Stream
verwendet wird. Darüber hinaus wurde eine mit EBNF vergleichbare, jedoch
allgemeinere und erweiterbare Kombinatorbibliothek entwickelt, mit der
Parser-Arrows auf funktionale Weise zusammengesetzt werden können.

In \cref{magicl} wurde zunächst die Generator-Bibliothek vorgestellt,
mit dem zu erzeugender Quelltext durch ein strukturiertes Code-Modell
repräsentiert wird, was unter anderem hilft, Syntaxfehler oder Probleme
mit der Einrückung zu vermeiden. Wie die Parser-Bibliothek kann auch die
Generator-Bibliothek vom Benutzer einfach um allgemeine oder
sprachspezifische Abstraktionen erweitert werden. Eine
\sexp{}-Bibliothek enthält neben einem Parser und einem Generator für
\sexp{}-Syntax \sexp{}-spezifische Erweiterungen der Parser-Bibliothek
wie das von Lisp-Makros bekannte Matching von Knotennamen. Darüber
hinaus wurde eine universelle Compiler-Schnittstelle spezifiziert, mit
der verschiedene Compiler-Typen in den allgemeinsten Compiler-Typ
\icode{IOArrow} überführt und so miteinander kombiniert werden
können. Außerdem können Verarbeitungseinheiten fest verdrahtet und so
implizit über ihre Ein- und Ausgabetypen angesprochen werden können.

Mit den vorangehenden Werkzeugen ist es bereits möglich, eigene Parser,
Makros etc. in Haskell zu definieren und zu benutzen. In \cref{sexphs}
wurde damit eine \sexp{}-Syntax für Haskell konstruiert, die als
Meta-Programmiersprache für Compilerdefinitionen gedacht ist und darüber
hinaus die \sexp{}-basierte Generierung von Haskell-Code aus anderen
DSLs ermöglicht. Die Implementation des Haskell-DSL-Compilers dient
gleichzeitig als Anwendungsbeispiel für Compiler in MagicL, die mit
typisierten Objekten als Zwischenmodellen arbeiten. Hierfür wandelt ein
Parser die \sexps{} zunächst in ein Haskell-Modell um, woraus ein
funktionaler Compiler schließlich Haskell-Quelltext generiert. Beide
Compiler-Teile benutzen die universelle Compiler-Schnittstelle aus
\cref{magicl}.

Aufbauend auf \sexp{}-Haskell wurde in \cref{sexpcomp} die Compiler-DSL
entwickelt, die die Haskell-DSL um einige syntaktische Konstrukte für
die \sexp{}-Verarbeitung erweitert. Hierfür wurde zunächst ein
Quasiquote-Operator für \sexp{}-Templates wie in Lisp üblich entwickelt,
der sich allerdings -- neben der etwas anderen Syntax -- in zwei Punkten
unterscheidet: Er ist allgemeiner, da auch mehrere oder überhaupt keine
Rückgaben ermöglicht werden, und löst Namensprobleme bei der Generierung
von weiteren Templates einfach durch verschieden benannte
Quasiquote-Operatoren. Darüber hinaus wurden sogenannte Auto-Makros
bereitgestellt, welche die Lisp-Semantik einer globalen Makro-Liste, die
automatisch rekursiv von außen nach innen auf eines Syntaxbaum
angewendet wird, wiederspiegelt.

Eine Diskussion des entwickelten Frameworks in Hinblick auf Erfüllung
der Anforderungen und praktische Verwendbarkeit wurde in \cref{disc}
geführt. Alle Anforderungen wurden erfüllt, so dass MagicL allgemeiner
und flexibler ist als alle bekannten bestehenden Werkzeuge. Potential
für Verbesserungen besteht hauptsächlich bei der Compiler-DSL, mit der
Meta-Programme noch nicht so kurz formuliert werden können wie in
Lisp. Es sind daher weitere Abstraktionen wünschenswert, die allerdings
nicht einfach die Lisp-Konstrukte nachbauen sollten, da dies die
Allgemeinheit wieder einschänken würde. Welche Konstrukte die beste
Erweiterung der Compiler-DSL wären, bleibt daher eine offene Frage, die
erst nach dem Sammeln von mehr Erfahrung bei der Implementation von
MagicL-Compilern beantwortet werden kann.

\lsection[end:disc]{Ausblick}

Dieser Abschnitt soll einen Überblick geben über all das, was
derzeit in MagicL nicht oder nicht gut möglich ist. Dabei wird
diskutiert, welche fundamentalen Design-Entscheidungen in einem möglichen
Nachfolger anders getroffen werden könnten und an welchen Stellen noch
Nachbesserungen oder Erweiterungen möglich sind. Darüber hinaus sollen
Ideen für \sexp{}-gestützte Modellierung und Verarbeitung aufgezählt
werden, die hier nicht weiter verfolgt wurden, aber interessante
Forschungsrichtungen für die Zukunft darstellen könnten.

\lsubsection[end:disc:realworld]{Nutzung in der realen Welt}

Generell lag bei der Implementation von MagicL die Priorität auf
theoretischer Korrektheit und klarer Semantik, jedoch weniger auf
konkreten Anwendungen. Dies spiegelt sich in der Wahl von Haskell und
Kategorientheorie als Basistechnologien wieder, welche zwar mathematisch
elegant sind, sicherlich jedoch die meisten Anwender abschrecken
würden. Hierfür könnte eine einfachere Compiler-DSL nützlich sein, die
ohne mathematisches Hintergrundwissen benutzbar ist. Diese DSL könnte
dann entweder in die bestehende Arrow-Implementation überführt oder
komplett anders realisiert werden -- und dabei eventuell effizienter als
die verschachtelten Parser-Funktoren, die vergleichsweise langsam
laufen.

Ein weiterer Aspekt der Realweltnutzung besteht in der Integrierbarkeit
in bestehende Systeme. MagicL-Compiler können mit einem installierten
Haskell-System interpretiert oder mit dem Glasgow Haskell Compiler
(GHC) \cite{Ghc} in native Programme übersetzt werden, welche von
beliebigen Build-Skripten aufgerufen werden können. Dennoch wären
Interoperabilität und Portabilität bei einer Umsetzungssprache wie
Java deutlich höher.

Auch fehlen bis auf Haskell noch jegliche Backends für Programmier- und
Auszeichnungssprachen -- derzeit müssen diese komplett vom Benutzer
selbst erstellt werden.

\lsubsection[end:disc:generalize]{Theoretische Verallgemeinerungen}

Es gibt auch einige Ideen, wie die grundlegende Architektur von MagicL
noch universeller und mächtiger angelegt werden könnte.

Ein Beispiel hierfür ist der Umstieg von \sexps{}, deren Blätter immer
Strings sind, auf beliebige Bäume:
\begin{DIFnomarkup}\begin{code}
data Tree a = Node [Tree a]
            | Leaf a
\end{code}\end{DIFnomarkup}
Damit könnten Parser, Makros etc. unabhängig von der Frage nach dem
Blatttyp konstruiert werden. Die bisherigen \sexps{} entsprechen dann
\icode{Tree String}, eventuell ist allerdings auch eine Repräsentation
als \icode{Tree Char} sinnvoll, bei der Symbole selbst als Stream von
Buchstaben aufgefasst werden und daher ohne zusätzlichen Aufwand auch
mit String-Parsern gelesen werden könnten. Dies würde allerdings nicht
zur Konvention passen, das erste Element einer Liste immer als
Knotennamen zu verstehen.

Erweiterungspotenzial gibt es ebenfalls bei der generischen
Compiler-Schnittstelle, welche zwar das automatische Finden von
Compilern über Typen, nicht aber die selbstständige Suche von Pfaden
über mehrere Stationen ermöglicht. Dies würde nur funktionieren, wenn
das Haskell-Typsystem eine Prolog-artige Tiefensuche \cite{Prolog}
unterstützen würde oder eine künftige Implementation nicht über
Haskell-Typen, sondern eigene Datenstrukturen erfolgt. Eine Umsetzung
mit in einer dynamisch typisierten Sprache wie Clojure \cite{Clojure}
könnte hilfreich sein.

Elemente von Prolog ergeben auch an anderen Stellen interessante
Möglichkeiten. Beispielsweise könnte versucht werden, Makros oder
allgemein Parser als Relationen zu definieren, wodurch diese
bidirektional verwendbar würden. Ein Parser könnte daher gleichzeitig
als Generator dienen, und Sprach-Backends könnten ein gewisses Maß an
Roundtrip-Engeneering \cite{Roundtrip} ermöglichen. Bei Mehrdeutigkeiten
oder überhaupt keinen Lösungen sollte ein solches System
Benutzerinteraktionen zur Auflösung oder Fehlersuche ermöglichen.

\lsubsection[end:disc:ide]{\sexp{}-Entwicklungsumgebung}

Generell könnte eine ``\sexp{}-orientierte'' Form der
Softwareentwicklung sehr stark von darauf zugeschnittenen, integrierten
Entwicklungsumgebungen profitieren. Es gibt keinen Grund, weshalb
\sexps{} weiterhin altmodisch als Textdateien bearbeitet werden
müssen. Vielmehr wäre ein struktureller Baumeditor zu bevorzugen --
analog zur Präferenz von \sexp{}-Templates gegenüber Strings. Der
ParEdit-Mode \cite{Paredit} für Emacs \cite{Emacs} ist ein Schritt in
diese Richtung, da dieser zwar weiterhin Text anzeigt, seine Steuerung
allerdings fast komplett Baum-basiert ist. Damit wird es beispielsweise
unmöglich, unbalancierte Klammern zu erzeugen.

Noch besser wäre allerdings der komplette Umstieg auf Bäume im Editor,
womit beispielsweise gezieltes Ausblenden von Sub-Ausdrücken erleichtert
würde. Vor allem aber würde dies eine Model-View-Trennung für
Programmiersprachen bedeuten, in denen das Modell aus \sexps{} besteht,
die graphische Visualisierung aber komplett überschreibbar ist, was
nahezu unbegrenzte Möglichkeiten nach sich zieht. Beispielsweise könnten
Wurzeln, Brüche etc. in mathematischen Programmen graphisch ansprechend
visualisiert oder programmiererspezifische Themes angeboten werden,
welche die syntaktischen Strukturen gewohnter Programmiersprachen für
bessere Lesbarkeit simulieren.

\lsubsection[end:disc:db]{Datenbanken und Vernetzung}

\sexps{} müssen genauso wenig als Text gespeichert wie visualisiert
werden. Vielmehr können sie auch direkt persistent und effizient in
geeigneten lokalen oder entfernten Datenbanken abgelegt werden. Als
Backend hierfür könnten sowohl schemafreie Systeme wie
CouchDB \cite{CouchDB} als auch klassische SQL-Datenbanken zum Einsatz
kommen, wobei letztere mit einem allgemeinen \sexp{}-Schema oder
modellspezifischen, generierten Schemas verwendet werden könnten.

Auch für das Problem der Versionierung in verteilten
Entwicklungsszenarios könnten \sexps{} Vorteile gegenüber textbasierten
Versionierungssystemen wie Subversion \cite{Svn} oder Git \cite{Git} mit
sich bringen, wenn man beispielsweise an die immer wieder auftretenden
Probleme mit Whitespace denkt. Auch dies ist weiter untersuchenswert.

Ein weiteres Arbeitsgebiet könnte die Möglichkeit von
Echtzeitkollaboration durch Netzwerktransparenz von \sexps{}
oder kommunizierende Datenbanken darstellen, vor allem im Zusammenhang
mit der skizzierten Entwicklungsumgebung.

\medskip{} 

Generell erscheinen die Möglichkeiten, die sich aus der Idee einer
Vereinheitlichung existierender neuer Programmier- und
Auszeichnungssprachen in eine einfache Struktur wie \sexps{} ergeben,
nahezu grenzenlos. Neue DSLs, die in die Bestehenden übersetzt werden,
können so immer abstraktere und einfachere Notationen für Domänen
anbieten und so das Erstellen von Programmen, Webseiten und beliebigen
anderen Daten vereinfachen. Auch wenn die Vision einer großen,
einheitlichen und redundanzfreien Sammlung von \sexp{}-DSLs für jegliche
Anwendungsdomäne noch in weiter Ferne scheint, geht diese Arbeit durch
die Diskussion und prototypische Umsetzung eines geeigneten Rahmenwerks
für derartige DSL-Compiler einen ersten Schritt in die Richtung.

\todo{Literatur: Verlag/Ort bei Büchern, bei Web zuletzt zugegriffen}

\cleardoublepage

\bibliographystyle{gerplain}
\bibliography{diplomarbeit}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}


\listoffigures
\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}

\chapter*{Selbstständigkeitserklärung}
\addcontentsline{toc}{chapter}{Selbstständigkeitserklärung}

Ich versichere, dass ich die vorstehende Arbeit selbstständig und ohne fremde Hilfe angefertigt
und mich anderer als der im beigefügten Verzeichnis angegebenen Hilfsmittel nicht bedient
habe. Alle Stellen, die wörtlich oder sinngemäß aus Veröffentlichungen entnommen wurden,
sind als solche kenntlich gemacht.

Ich bin mit einer Einstellung in den Bestand der Bibliothek des Departments Informatik einverstanden.

\vskip 2cm
\begin{flushright}
Hamburg, \today
\vskip 1cm
Benjamin Teuber
\end{flushright}

\end{document}

